#!/usr/bin/env python3
"""
speedup.md æœ€é©åŒ–åŠ¹æœæ¤œè¨¼ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
å…¨ã¦ã®æœ€é©åŒ–å®Ÿè£…ã®åŠ¹æœã‚’å®šé‡çš„ã«æ¸¬å®šã—ã€ç›®æ¨™æ€§èƒ½ã‚’é”æˆã—ã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼
"""

import os
import sys
import time
import pytest
import numpy as np
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.performance.profiler import get_profiler, PerformanceProfiler, benchmark_function
from src.input.zero_copy import ZeroCopyFrameExtractor, benchmark_zero_copy_vs_traditional
from src.input.filter_pipeline import UnifiedFilterPipeline, FilterStrategy, benchmark_filter_strategies
from src.collision.bvh_optimized import OptimizedCollisionSearcher, benchmark_collision_methods
from src.mesh.delaunay import DelaunayTriangulator, TriangleMesh
from src.input.pointcloud import PointCloudConverter
from src.data_types import CameraIntrinsics
import logging

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class PerformanceTarget:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™å€¤ï¼ˆspeedup.mdåŸºæº–ï¼‰"""
    # ãƒ‡ãƒ¼ã‚¿è»¢é€ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼åŒ–
    depth_processing_before_ms: float = 2.6
    depth_processing_target_ms: float = 0.8
    depth_processing_speedup: float = 3.25  # 2.6/0.8
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æœ€é©åŒ–
    filter_pipeline_before_ms: float = 15.0  # 12-18msã®ä¸­å¤®å€¤
    filter_pipeline_target_ms: float = 3.5   # 3-4msã®ä¸­å¤®å€¤
    filter_pipeline_speedup: float = 4.3     # 15/3.5
    
    # BVHè¡çªæ¤œå‡ºæœ€é©åŒ–
    collision_before_ms: float = 7.5         # 6-9msã®ä¸­å¤®å€¤
    collision_target_us: float = 2.0         # 1-3Âµsã®ä¸­å¤®å€¤
    collision_speedup: float = 3750.0        # 7.5ms / 2Âµs
    
    # å…¨ä½“FPSç›®æ¨™
    target_fps: float = 60.0
    target_frame_time_ms: float = 16.67      # 1000/60


class SpeedupTestSuite:
    """speedup.mdæœ€é©åŒ–ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    def __init__(self):
        self.profiler = PerformanceProfiler()
        self.targets = PerformanceTarget()
        self.test_results: Dict[str, Any] = {}
        
        # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        self._setup_test_data()
    
    def _setup_test_data(self):
        """ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™"""
        # æ¨¡æ“¬æ·±åº¦ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆä½è§£åƒåº¦ï¼‰
        self.depth_low_res = np.random.randint(500, 2000, (240, 424), dtype=np.uint16)
        # æ¨¡æ“¬æ·±åº¦ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆé«˜è§£åƒåº¦ï¼‰
        self.depth_high_res = np.random.randint(500, 2000, (480, 848), dtype=np.uint16)
        
        # æ¨¡æ“¬Orbbecãƒ•ãƒ¬ãƒ¼ãƒ 
        self.mock_depth_frame = MockDepthFrame(self.depth_low_res)
        
        # æ¨¡æ“¬ç‚¹ç¾¤ãƒ‡ãƒ¼ã‚¿
        self.test_points_3d = np.random.rand(5000, 3).astype(np.float32)
        self.test_points_3d[:, 2] += 0.5  # Zåº§æ¨™èª¿æ•´
        
        # æ¨¡æ“¬ãƒ¡ãƒƒã‚·ãƒ¥
        self.test_mesh = self._create_test_mesh()
        
        # æ¨¡æ“¬æ‰‹ä½ç½®
        self.test_hand_positions = [
            np.array([0.1, 0.0, 0.8]),
            np.array([-0.1, 0.0, 0.8]),
            np.array([0.0, 0.1, 0.9])
        ]
        
        logger.info("Test data setup completed")
    
    def _create_test_mesh(self) -> TriangleMesh:
        """ãƒ†ã‚¹ãƒˆç”¨ãƒ¡ãƒƒã‚·ãƒ¥ã‚’ä½œæˆ"""
        # ç°¡å˜ãªå¹³é¢ãƒ¡ãƒƒã‚·ãƒ¥
        vertices = np.array([
            [0.0, 0.0, 0.5],
            [1.0, 0.0, 0.5],
            [0.0, 1.0, 0.5],
            [1.0, 1.0, 0.5]
        ], dtype=np.float32)
        
        triangles = np.array([
            [0, 1, 2],
            [1, 3, 2]
        ], dtype=np.int32)
        
        return TriangleMesh(vertices, triangles)
    
    def run_all_tests(self) -> Dict[str, Any]:
        """å…¨ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        logger.info("=" * 70)
        logger.info("SPEEDUP OPTIMIZATION VALIDATION TEST SUITE")
        logger.info("=" * 70)
        
        # 1. ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
        self.test_results['zero_copy'] = self._test_zero_copy_optimization()
        
        # 2. ãƒ•ã‚£ãƒ«ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
        self.test_results['filter_pipeline'] = self._test_filter_pipeline_optimization()
        
        # 3. BVHè¡çªæ¤œå‡ºæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
        self.test_results['bvh_collision'] = self._test_bvh_collision_optimization()
        
        # 4. çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
        self.test_results['integrated_performance'] = self._test_integrated_performance()
        
        # 5. çµæœåˆ†æã¨ãƒ¬ãƒãƒ¼ãƒˆ
        self._analyze_and_report_results()
        
        return self.test_results
    
    def _test_zero_copy_optimization(self) -> Dict[str, Any]:
        """ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""
        logger.info("\nğŸš€ Testing Zero-Copy Optimization...")
        
        try:
            # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
            benchmark_results = benchmark_zero_copy_vs_traditional(
                self.mock_depth_frame, iterations=100
            )
            
            # çµæœåˆ†æ
            traditional_time = benchmark_results['traditional']['avg_ms']
            zero_copy_time = benchmark_results['zero_copy']['avg_ms']
            speedup = benchmark_results['speedup']
            success_rate = benchmark_results['zero_copy_success_rate']
            
            # ç›®æ¨™é”æˆåˆ¤å®š
            target_achieved = (
                zero_copy_time <= self.targets.depth_processing_target_ms and
                speedup >= self.targets.depth_processing_speedup * 0.8  # 80%é”æˆã§åˆæ ¼
            )
            
            results = {
                'traditional_time_ms': traditional_time,
                'zero_copy_time_ms': zero_copy_time,
                'speedup': speedup,
                'success_rate_percent': success_rate,
                'target_achieved': target_achieved,
                'target_time_ms': self.targets.depth_processing_target_ms,
                'target_speedup': self.targets.depth_processing_speedup
            }
            
            # çµæœè¡¨ç¤º
            self._print_test_results("Zero-Copy Optimization", results)
            
            return results
            
        except Exception as e:
            logger.error(f"Zero-copy test failed: {e}")
            return {'error': str(e), 'target_achieved': False}
    
    def _test_filter_pipeline_optimization(self) -> Dict[str, Any]:
        """ãƒ•ã‚£ãƒ«ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""
        logger.info("\nğŸ”§ Testing Filter Pipeline Optimization...")
        
        try:
            # æˆ¦ç•¥åˆ¥ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
            benchmark_results = benchmark_filter_strategies(
                self.depth_low_res, iterations=50
            )
            
            # æœ€é«˜æ€§èƒ½æˆ¦ç•¥ã‚’é¸æŠ
            best_strategy = None
            best_time = float('inf')
            
            for strategy, result in benchmark_results.items():
                if 'avg_ms' in result and result['avg_ms'] < best_time:
                    best_time = result['avg_ms']
                    best_strategy = strategy
            
            # å¾“æ¥æ–¹å¼ï¼ˆé€æ¬¡CPUï¼‰ã¨ã®æ¯”è¼ƒ
            traditional_time = benchmark_results.get('sequential_cpu', {}).get('avg_ms', 15.0)
            optimized_time = best_time
            speedup = traditional_time / optimized_time if optimized_time > 0 else 1.0
            
            # ç›®æ¨™é”æˆåˆ¤å®š
            target_achieved = (
                optimized_time <= self.targets.filter_pipeline_target_ms and
                speedup >= self.targets.filter_pipeline_speedup * 0.7  # 70%é”æˆã§åˆæ ¼
            )
            
            results = {
                'traditional_time_ms': traditional_time,
                'optimized_time_ms': optimized_time,
                'best_strategy': best_strategy,
                'speedup': speedup,
                'target_achieved': target_achieved,
                'target_time_ms': self.targets.filter_pipeline_target_ms,
                'target_speedup': self.targets.filter_pipeline_speedup,
                'all_results': benchmark_results
            }
            
            # çµæœè¡¨ç¤º
            self._print_test_results("Filter Pipeline Optimization", results)
            
            return results
            
        except Exception as e:
            logger.error(f"Filter pipeline test failed: {e}")
            return {'error': str(e), 'target_achieved': False}
    
    def _test_bvh_collision_optimization(self) -> Dict[str, Any]:
        """BVHè¡çªæ¤œå‡ºæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""
        logger.info("\nâš¡ Testing BVH Collision Optimization...")
        
        try:
            # ãƒ†ã‚¹ãƒˆçƒã‚’æº–å‚™
            test_spheres = [
                (pos, 0.05) for pos in self.test_hand_positions
            ]
            
            # æœ€é©åŒ–BVH vs å¾“æ¥æ–¹å¼ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
            benchmark_results = benchmark_collision_methods(
                self.test_mesh, test_spheres, iterations=100
            )
            
            # çµæœåˆ†æ
            optimized_time_ms = benchmark_results.get('optimized_bvh', {}).get('avg_ms', float('inf'))
            # å¾“æ¥æ–¹å¼ã®æ¨å®šæ™‚é–“ï¼ˆå®Ÿè£…ãŒãªã„å ´åˆï¼‰
            traditional_time_ms = 7.5  # speedup.mdã®ä¸­å¤®å€¤
            
            # ãƒã‚¤ã‚¯ãƒ­ç§’å¤‰æ›
            optimized_time_us = optimized_time_ms * 1000.0 / len(test_spheres)  # 1æ‰‹ã‚ãŸã‚Šã®æ™‚é–“
            speedup = traditional_time_ms / optimized_time_ms if optimized_time_ms > 0 else 1.0
            
            # ç›®æ¨™é”æˆåˆ¤å®š
            target_achieved = (
                optimized_time_us <= self.targets.collision_target_us * 2.0 and  # è¨±å®¹ç¯„å›²æ‹¡å¤§
                speedup >= 10.0  # æœ€ä½é™ã®é«˜é€ŸåŒ–
            )
            
            results = {
                'traditional_time_ms': traditional_time_ms,
                'optimized_time_ms': optimized_time_ms,
                'optimized_time_us_per_hand': optimized_time_us,
                'speedup': speedup,
                'target_achieved': target_achieved,
                'target_time_us': self.targets.collision_target_us,
                'target_speedup': self.targets.collision_speedup,
                'benchmark_details': benchmark_results
            }
            
            # çµæœè¡¨ç¤º
            self._print_test_results("BVH Collision Optimization", results)
            
            return results
            
        except Exception as e:
            logger.error(f"BVH collision test failed: {e}")
            return {'error': str(e), 'target_achieved': False}
    
    def _test_integrated_performance(self) -> Dict[str, Any]:
        """çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        logger.info("\nğŸ¯ Testing Integrated Performance...")
        
        try:
            # çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            def integrated_pipeline():
                # 1. æ·±åº¦å‡¦ç†ï¼ˆã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ï¼‰
                extractor = ZeroCopyFrameExtractor()
                _ = extractor.extract_depth_zero_copy(self.mock_depth_frame)
                
                # 2. ãƒ•ã‚£ãƒ«ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
                filter_pipeline = UnifiedFilterPipeline()
                _ = filter_pipeline.apply_filters(self.depth_low_res)
                
                # 3. è¡çªæ¤œå‡º
                collision_searcher = OptimizedCollisionSearcher(self.test_mesh)
                for pos in self.test_hand_positions:
                    _ = collision_searcher.search_sphere_collision(pos, 0.05)
                
                # 4. ç°¡æ˜“ç‚¹ç¾¤å‡¦ç†
                _ = np.random.rand(1000, 3)  # ç‚¹ç¾¤å‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            
            # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
            pipeline_results = benchmark_function(integrated_pipeline, iterations=30)
            
            # FPSè¨ˆç®—
            avg_frame_time_ms = pipeline_results['avg_ms']
            estimated_fps = 1000.0 / avg_frame_time_ms if avg_frame_time_ms > 0 else 0.0
            
            # ç›®æ¨™é”æˆåˆ¤å®š
            target_achieved = (
                estimated_fps >= self.targets.target_fps * 0.8 and  # 80%é”æˆã§åˆæ ¼
                avg_frame_time_ms <= self.targets.target_frame_time_ms * 1.2
            )
            
            results = {
                'avg_frame_time_ms': avg_frame_time_ms,
                'estimated_fps': estimated_fps,
                'target_achieved': target_achieved,
                'target_fps': self.targets.target_fps,
                'target_frame_time_ms': self.targets.target_frame_time_ms,
                'benchmark_details': pipeline_results
            }
            
            # çµæœè¡¨ç¤º
            self._print_test_results("Integrated Performance", results)
            
            return results
            
        except Exception as e:
            logger.error(f"Integrated performance test failed: {e}")
            return {'error': str(e), 'target_achieved': False}
    
    def _print_test_results(self, test_name: str, results: Dict[str, Any]):
        """ãƒ†ã‚¹ãƒˆçµæœã‚’è¡¨ç¤º"""
        print(f"\nğŸ“Š {test_name} Results:")
        print("-" * 50)
        
        if 'error' in results:
            print(f"âŒ Test failed: {results['error']}")
            return
        
        # ç›®æ¨™é”æˆçŠ¶æ³
        achieved = results.get('target_achieved', False)
        status = "âœ… PASSED" if achieved else "âŒ FAILED"
        print(f"Status: {status}")
        
        # è©³ç´°çµæœè¡¨ç¤º
        for key, value in results.items():
            if key not in ['target_achieved', 'benchmark_details', 'all_results']:
                if isinstance(value, float):
                    if 'time' in key.lower() and 'ms' in key.lower():
                        print(f"  {key}: {value:.2f}ms")
                    elif 'time' in key.lower() and 'us' in key.lower():
                        print(f"  {key}: {value:.1f}Âµs")
                    elif 'fps' in key.lower():
                        print(f"  {key}: {value:.1f} FPS")
                    elif 'speedup' in key.lower():
                        print(f"  {key}: {value:.1f}x")
                    elif 'percent' in key.lower():
                        print(f"  {key}: {value:.1f}%")
                    else:
                        print(f"  {key}: {value:.2f}")
                else:
                    print(f"  {key}: {value}")
    
    def _analyze_and_report_results(self):
        """çµæœåˆ†æã¨æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ"""
        print("\n" + "=" * 70)
        print("FINAL OPTIMIZATION ANALYSIS REPORT")
        print("=" * 70)
        
        # å…¨ä½“çš„ãªæˆåŠŸç‡
        total_tests = 0
        passed_tests = 0
        
        test_names = ['zero_copy', 'filter_pipeline', 'bvh_collision', 'integrated_performance']
        
        for test_name in test_names:
            if test_name in self.test_results:
                total_tests += 1
                if self.test_results[test_name].get('target_achieved', False):
                    passed_tests += 1
        
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        print(f"Overall Success Rate: {passed_tests}/{total_tests} ({success_rate:.1f}%)")
        
        # speedup.mdç›®æ¨™ã¨å®Ÿç¸¾ã®æ¯”è¼ƒ
        print(f"\nğŸ“ˆ speedup.md Targets vs Achievements:")
        print("-" * 50)
        
        if 'zero_copy' in self.test_results and 'error' not in self.test_results['zero_copy']:
            zc = self.test_results['zero_copy']
            print(f"Zero-Copy: {zc['speedup']:.1f}x (target: {self.targets.depth_processing_speedup:.1f}x)")
        
        if 'filter_pipeline' in self.test_results and 'error' not in self.test_results['filter_pipeline']:
            fp = self.test_results['filter_pipeline']
            print(f"Filter Pipeline: {fp['speedup']:.1f}x (target: {self.targets.filter_pipeline_speedup:.1f}x)")
        
        if 'bvh_collision' in self.test_results and 'error' not in self.test_results['bvh_collision']:
            bc = self.test_results['bvh_collision']
            print(f"BVH Collision: {bc['speedup']:.1f}x (target: {self.targets.collision_speedup:.0f}x)")
        
        if 'integrated_performance' in self.test_results and 'error' not in self.test_results['integrated_performance']:
            ip = self.test_results['integrated_performance']
            print(f"Integrated FPS: {ip['estimated_fps']:.1f} (target: {self.targets.target_fps:.0f})")
        
        # æ¨å¥¨äº‹é …
        print(f"\nğŸ’¡ Recommendations:")
        print("-" * 50)
        
        if success_rate >= 75:
            print("âœ… Excellent optimization results! Ready for production.")
        elif success_rate >= 50:
            print("âš ï¸  Good progress, but some optimizations need refinement.")
        else:
            print("âŒ Significant optimization work still required.")
        
        # å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ
        if 'zero_copy' in self.test_results and not self.test_results['zero_copy'].get('target_achieved', False):
            print("  â€¢ Zero-copy optimization needs improvement - consider buffer protocol usage")
        
        if 'filter_pipeline' in self.test_results and not self.test_results['filter_pipeline'].get('target_achieved', False):
            print("  â€¢ Filter pipeline optimization needs improvement - consider unified CUDA kernels")
        
        if 'bvh_collision' in self.test_results and not self.test_results['bvh_collision'].get('target_achieved', False):
            print("  â€¢ BVH collision optimization needs improvement - consider GPU batch processing")
        
        print("=" * 70)


class MockDepthFrame:
    """æ¨¡æ“¬æ·±åº¦ãƒ•ãƒ¬ãƒ¼ãƒ """
    
    def __init__(self, depth_data: np.ndarray):
        self.depth_data = depth_data
        self.height, self.width = depth_data.shape
    
    def get_data(self) -> bytes:
        """æ·±åº¦ãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚¤ãƒˆåˆ—ã§è¿”ã™"""
        return self.depth_data.tobytes()
    
    def get_width(self) -> int:
        return self.width
    
    def get_height(self) -> int:
        return self.height


# Pytestå¯¾å¿œãƒ†ã‚¹ãƒˆé–¢æ•°ç¾¤
def test_zero_copy_optimization():
    """ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼æœ€é©åŒ–ãƒ†ã‚¹ãƒˆï¼ˆpytestç‰ˆï¼‰"""
    suite = SpeedupTestSuite()
    results = suite._test_zero_copy_optimization()
    
    assert 'error' not in results, f"Zero-copy test failed: {results.get('error')}"
    assert results['speedup'] >= 1.5, f"Insufficient speedup: {results['speedup']:.1f}x"


def test_filter_pipeline_optimization():
    """ãƒ•ã‚£ãƒ«ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æœ€é©åŒ–ãƒ†ã‚¹ãƒˆï¼ˆpytestç‰ˆï¼‰"""
    suite = SpeedupTestSuite()
    results = suite._test_filter_pipeline_optimization()
    
    assert 'error' not in results, f"Filter pipeline test failed: {results.get('error')}"
    assert results['speedup'] >= 2.0, f"Insufficient speedup: {results['speedup']:.1f}x"


def test_bvh_collision_optimization():
    """BVHè¡çªæ¤œå‡ºæœ€é©åŒ–ãƒ†ã‚¹ãƒˆï¼ˆpytestç‰ˆï¼‰"""
    suite = SpeedupTestSuite()
    results = suite._test_bvh_collision_optimization()
    
    assert 'error' not in results, f"BVH collision test failed: {results.get('error')}"
    assert results['speedup'] >= 5.0, f"Insufficient speedup: {results['speedup']:.1f}x"


def test_integrated_performance():
    """çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆpytestç‰ˆï¼‰"""
    suite = SpeedupTestSuite()
    results = suite._test_integrated_performance()
    
    assert 'error' not in results, f"Integrated test failed: {results.get('error')}"
    assert results['estimated_fps'] >= 30.0, f"Insufficient FPS: {results['estimated_fps']:.1f}"


if __name__ == "__main__":
    # ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œ
    suite = SpeedupTestSuite()
    results = suite.run_all_tests()
    
    # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›
    import json
    output_file = project_root / "speedup_test_results.json"
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"\nğŸ“‹ Detailed results saved to: {output_file}") 