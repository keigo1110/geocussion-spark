#!/usr/bin/env python3
"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©

Geocussion-SP ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å„ãƒ•ã‚§ãƒ¼ã‚ºã‚’ç›£è¦–ã—ã€
ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®è‡ªå‹•ç‰¹å®šã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–ææ¡ˆã‚’è¡Œã„ã¾ã™ã€‚

ä¸»è¦æ©Ÿèƒ½:
- ãƒ•ãƒ¬ãƒ¼ãƒ æ¯ã®å‡¦ç†æ™‚é–“æ¸¬å®š
- CPU/GPU/ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ç›£è¦–
- ãƒœãƒˆãƒ«ãƒãƒƒã‚¯è‡ªå‹•æ¤œå‡º
- æœ€é©åŒ–ææ¡ˆã‚·ã‚¹ãƒ†ãƒ 
- JSON ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
"""

import time
import json
import threading
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, asdict
from collections import deque
import numpy as np
import psutil

try:
    import GPUtil
    GPU_AVAILABLE = True
except ImportError:
    GPU_AVAILABLE = False

from .. import get_logger

logger = get_logger(__name__)


@dataclass
class PhaseMetrics:
    """ãƒ•ã‚§ãƒ¼ã‚ºè¨ˆæ¸¬çµæœ"""
    name: str
    execution_time_ms: float
    cpu_usage_percent: float
    memory_usage_mb: float
    gpu_usage_percent: float = 0.0
    gpu_memory_mb: float = 0.0
    timestamp: float = 0.0
    frame_number: int = 0


@dataclass 
class BottleneckAnalysis:
    """ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æçµæœ"""
    phase_name: str
    severity: str  # "CRITICAL", "HIGH", "MEDIUM", "LOW"
    issue_type: str  # "CPU", "GPU", "MEMORY", "TIME"
    description: str
    recommendation: str
    impact_score: float  # 0-100


@dataclass
class PerformanceReport:
    """æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆ"""
    timestamp: float
    total_fps: float
    target_fps: float
    total_frame_time_ms: float
    phase_metrics: List[PhaseMetrics]
    bottlenecks: List[BottleneckAnalysis]
    optimization_suggestions: List[str]
    system_info: Dict[str, Any]


class PerformanceProfiler:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©"""
    
    def __init__(
        self,
        target_fps: float = 30.0,
        history_size: int = 60,
        analysis_interval: float = 2.0,
        enable_real_time_display: bool = True,
        enable_json_logging: bool = True
    ):
        """
        åˆæœŸåŒ–
        
        Args:
            target_fps: ç›®æ¨™FPS
            history_size: å±¥æ­´ä¿æŒãƒ•ãƒ¬ãƒ¼ãƒ æ•°
            analysis_interval: åˆ†æå®Ÿè¡Œé–“éš” (ç§’)
            enable_real_time_display: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºã®æœ‰åŠ¹åŒ–
            enable_json_logging: JSON ãƒ­ã‚°ã®æœ‰åŠ¹åŒ–
        """
        self.target_fps = target_fps
        self.history_size = history_size
        self.analysis_interval = analysis_interval
        self.enable_real_time_display = enable_real_time_display
        self.enable_json_logging = enable_json_logging
        
        # è¨ˆæ¸¬çŠ¶æ…‹
        self.is_profiling = False
        self.current_frame = 0
        self.frame_start_time = 0.0
        self.current_phase = None
        self.phase_start_time = 0.0
        
        # ãƒ‡ãƒ¼ã‚¿è“„ç©
        self.frame_history: deque = deque(maxlen=history_size)
        self.phase_history: Dict[str, deque] = {}
        self.current_frame_phases: List[PhaseMetrics] = []
        
        # ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–
        self.system_monitor = SystemMonitor()
        
        # åˆ†æã‚·ã‚¹ãƒ†ãƒ 
        self.bottleneck_analyzer = BottleneckAnalyzer(target_fps)
        
        # è¡¨ç¤ºã‚¹ãƒ¬ãƒƒãƒ‰
        self.display_thread: Optional[threading.Thread] = None
        self.stop_display = threading.Event()
        
        # ãƒ¬ãƒãƒ¼ãƒˆ
        self.latest_report: Optional[PerformanceReport] = None
    
    def start_profiling(self):
        """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°é–‹å§‹"""
        if self.is_profiling:
            return
        
        self.is_profiling = True
        self.current_frame = 0
        logger.info("Performance profiling started")
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        if self.enable_real_time_display:
            self.stop_display.clear()
            self.display_thread = threading.Thread(
                target=self._display_loop, 
                daemon=True
            )
            self.display_thread.start()
    
    def stop_profiling(self) -> Optional[PerformanceReport]:
        """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°åœæ­¢"""
        if not self.is_profiling:
            return None
        
        self.is_profiling = False
        
        # è¡¨ç¤ºã‚¹ãƒ¬ãƒƒãƒ‰åœæ­¢
        if self.display_thread:
            self.stop_display.set()
            self.display_thread.join(timeout=1.0)
        
        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        final_report = self.generate_report()
        
        logger.info("Performance profiling stopped")
        
        if self.enable_json_logging and final_report:
            self._save_json_report(final_report)
        
        return final_report
    
    def start_frame(self):
        """ãƒ•ãƒ¬ãƒ¼ãƒ è¨ˆæ¸¬é–‹å§‹"""
        if not self.is_profiling:
            return
        
        self.frame_start_time = time.perf_counter()
        self.current_frame += 1
        self.current_frame_phases.clear()
    
    def end_frame(self):
        """ãƒ•ãƒ¬ãƒ¼ãƒ è¨ˆæ¸¬çµ‚äº†"""
        if not self.is_profiling:
            return
        
        frame_time = (time.perf_counter() - self.frame_start_time) * 1000
        current_fps = 1000.0 / max(frame_time, 1.0)
        
        # ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ç‡å–å¾—
        cpu_usage = self.system_monitor.get_cpu_usage()
        memory_usage = self.system_monitor.get_memory_usage()
        gpu_usage, gpu_memory = self.system_monitor.get_gpu_usage()
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ è¨˜éŒ²
        frame_data = {
            "frame_number": self.current_frame,
            "frame_time_ms": frame_time,
            "fps": current_fps,
            "cpu_usage": cpu_usage,
            "memory_usage": memory_usage,
            "gpu_usage": gpu_usage,
            "gpu_memory": gpu_memory,
            "timestamp": time.time(),
            "phases": self.current_frame_phases.copy()
        }
        
        self.frame_history.append(frame_data)
        
        # å®šæœŸçš„åˆ†æå®Ÿè¡Œ
        if len(self.frame_history) >= 30:  # æœ€ä½30ãƒ•ãƒ¬ãƒ¼ãƒ è“„ç©å¾Œ
            self._perform_analysis()
    
    def start_phase(self, phase_name: str):
        """ãƒ•ã‚§ãƒ¼ã‚ºè¨ˆæ¸¬é–‹å§‹"""
        if not self.is_profiling:
            return
        
        self.current_phase = phase_name
        self.phase_start_time = time.perf_counter()
        
        if phase_name not in self.phase_history:
            self.phase_history[phase_name] = deque(maxlen=self.history_size)
    
    def end_phase(self):
        """ãƒ•ã‚§ãƒ¼ã‚ºè¨ˆæ¸¬çµ‚äº†"""
        if not self.is_profiling or not self.current_phase:
            return
        
        phase_time = (time.perf_counter() - self.phase_start_time) * 1000
        
        # ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ç‡å–å¾—
        cpu_usage = self.system_monitor.get_cpu_usage()
        memory_usage = self.system_monitor.get_memory_usage()
        gpu_usage, gpu_memory = self.system_monitor.get_gpu_usage()
        
        # ãƒ•ã‚§ãƒ¼ã‚ºè¨˜éŒ²
        phase_metrics = PhaseMetrics(
            name=self.current_phase,
            execution_time_ms=phase_time,
            cpu_usage_percent=cpu_usage,
            memory_usage_mb=memory_usage,
            gpu_usage_percent=gpu_usage,
            gpu_memory_mb=gpu_memory,
            timestamp=time.time(),
            frame_number=self.current_frame
        )
        
        self.current_frame_phases.append(phase_metrics)
        self.phase_history[self.current_phase].append(phase_metrics)
        
        self.current_phase = None
    
    def _perform_analysis(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æå®Ÿè¡Œ"""
        if len(self.frame_history) < 10:
            return
        
        # æœ€æ–°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.latest_report = self.generate_report()
    
    def generate_report(self) -> PerformanceReport:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not self.frame_history:
            return PerformanceReport(
                timestamp=time.time(),
                total_fps=0.0,
                target_fps=self.target_fps,
                total_frame_time_ms=0.0,
                phase_metrics=[],
                bottlenecks=[],
                optimization_suggestions=[],
                system_info=self.system_monitor.get_system_info()
            )
        
        # çµ±è¨ˆè¨ˆç®—
        recent_frames = list(self.frame_history)[-30:]  # æœ€æ–°30ãƒ•ãƒ¬ãƒ¼ãƒ 
        
        avg_fps = np.mean([f["fps"] for f in recent_frames])
        avg_frame_time = np.mean([f["frame_time_ms"] for f in recent_frames])
        
        # ãƒ•ã‚§ãƒ¼ã‚ºçµ±è¨ˆ
        phase_stats = []
        for phase_name, phase_data in self.phase_history.items():
            if phase_data:
                recent_phase_data = list(phase_data)[-10:]  # æœ€æ–°10ã‚¨ãƒ³ãƒˆãƒª
                avg_phase_time = np.mean([p.execution_time_ms for p in recent_phase_data])
                
                avg_metrics = PhaseMetrics(
                    name=phase_name,
                    execution_time_ms=avg_phase_time,
                    cpu_usage_percent=np.mean([p.cpu_usage_percent for p in recent_phase_data]),
                    memory_usage_mb=np.mean([p.memory_usage_mb for p in recent_phase_data]),
                    gpu_usage_percent=np.mean([p.gpu_usage_percent for p in recent_phase_data]),
                    gpu_memory_mb=np.mean([p.gpu_memory_mb for p in recent_phase_data]),
                    timestamp=time.time(),
                    frame_number=self.current_frame
                )
                phase_stats.append(avg_metrics)
        
        # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æ
        bottlenecks = self.bottleneck_analyzer.analyze(recent_frames, phase_stats)
        
        # æœ€é©åŒ–ææ¡ˆç”Ÿæˆ
        suggestions = self._generate_optimization_suggestions(bottlenecks, phase_stats)
        
        return PerformanceReport(
            timestamp=time.time(),
            total_fps=avg_fps,
            target_fps=self.target_fps,
            total_frame_time_ms=avg_frame_time,
            phase_metrics=phase_stats,
            bottlenecks=bottlenecks,
            optimization_suggestions=suggestions,
            system_info=self.system_monitor.get_system_info()
        )
    
    def _generate_optimization_suggestions(
        self, 
        bottlenecks: List[BottleneckAnalysis],
        phase_stats: List[PhaseMetrics]
    ) -> List[str]:
        """æœ€é©åŒ–ææ¡ˆç”Ÿæˆ"""
        suggestions = []
        
        # FPSä¸è¶³ã®å ´åˆ
        if hasattr(self, 'latest_report') and self.latest_report:
            if self.latest_report.total_fps < self.target_fps * 0.8:  # 80%æœªæº€
                suggestions.append(f"FPSç›®æ¨™æœªé”æˆ: {self.latest_report.total_fps:.1f}/{self.target_fps} FPS")
        
        # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åŸºç›¤ææ¡ˆ
        for bottleneck in bottlenecks:
            if bottleneck.severity in ["CRITICAL", "HIGH"]:
                suggestions.append(f"{bottleneck.phase_name}: {bottleneck.recommendation}")
        
        # ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥ææ¡ˆ
        for phase in phase_stats:
            if phase.execution_time_ms > 20:  # 20msè¶…é
                suggestions.append(f"{phase.name}ãƒ•ã‚§ãƒ¼ã‚ºãŒé…ã„ ({phase.execution_time_ms:.1f}ms)")
            
            if phase.cpu_usage_percent > 80:
                suggestions.append(f"{phase.name}ã§CPUé«˜è² è· ({phase.cpu_usage_percent:.1f}%)")
            
            if phase.gpu_usage_percent > 90:
                suggestions.append(f"{phase.name}ã§GPUé«˜è² è· ({phase.gpu_usage_percent:.1f}%)")
        
        return suggestions
    
    def _display_loop(self):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºãƒ«ãƒ¼ãƒ—"""
        while not self.stop_display.wait(self.analysis_interval):
            if self.latest_report:
                self._display_real_time_stats(self.latest_report)
    
    def _display_real_time_stats(self, report: PerformanceReport):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çµ±è¨ˆè¡¨ç¤º"""
        print(f"\n==== Performance Stats (Frame {self.current_frame}) ====")
        print(f"FPS: {report.total_fps:.1f}/{report.target_fps} ({report.total_frame_time_ms:.1f}ms)")
        
        if report.phase_metrics:
            print("Phase Times:")
            for phase in sorted(report.phase_metrics, key=lambda p: p.execution_time_ms, reverse=True):
                print(f"  {phase.name}: {phase.execution_time_ms:.1f}ms")
        
        if report.bottlenecks:
            critical_bottlenecks = [b for b in report.bottlenecks if b.severity in ["CRITICAL", "HIGH"]]
            if critical_bottlenecks:
                print("Critical Issues:")
                for bottleneck in critical_bottlenecks:
                    print(f"  {bottleneck.phase_name}: {bottleneck.description}")
        
        print("=" * 50)
    
    def _save_json_report(self, report: PerformanceReport):
        """JSON ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""
        timestamp_str = time.strftime("%Y%m%d_%H%M%S")
        filename = f"performance_report_{timestamp_str}.json"
        
        try:
            with open(filename, 'w') as f:
                json.dump(asdict(report), f, indent=2, default=str)
            logger.info(f"Performance report saved: {filename}")
        except Exception as e:
            logger.error(f"Failed to save report: {e}")


class SystemMonitor:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–"""
    
    def __init__(self):
        self.process = psutil.Process()
    
    def get_cpu_usage(self) -> float:
        """CPUä½¿ç”¨ç‡å–å¾—"""
        return self.process.cpu_percent()
    
    def get_memory_usage(self) -> float:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å–å¾— (MB)"""
        return self.process.memory_info().rss / 1024 / 1024
    
    def get_gpu_usage(self) -> tuple[float, float]:
        """GPUä½¿ç”¨ç‡ã¨ãƒ¡ãƒ¢ãƒªå–å¾—"""
        if not GPU_AVAILABLE:
            return 0.0, 0.0
        
        try:
            gpus = GPUtil.getGPUs()
            if gpus:
                gpu = gpus[0]  # æœ€åˆã®GPU
                return gpu.load * 100, gpu.memoryUsed
        except:
            pass
        
        return 0.0, 0.0
    
    def get_system_info(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å–å¾—"""
        return {
            "cpu_count": psutil.cpu_count(),
            "memory_total_gb": psutil.virtual_memory().total / 1024 / 1024 / 1024,
            "gpu_available": GPU_AVAILABLE,
            "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
        }


class BottleneckAnalyzer:
    """ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æå™¨"""
    
    def __init__(self, target_fps: float):
        self.target_fps = target_fps
        self.target_frame_time = 1000.0 / target_fps
    
    def analyze(
        self, 
        frame_data: List[Dict], 
        phase_stats: List[PhaseMetrics]
    ) -> List[BottleneckAnalysis]:
        """ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æå®Ÿè¡Œ"""
        bottlenecks = []
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ æ™‚é–“åˆ†æ
        avg_frame_time = np.mean([f["frame_time_ms"] for f in frame_data])
        if avg_frame_time > self.target_frame_time * 1.2:  # 20%è¶…é
            severity = "CRITICAL" if avg_frame_time > self.target_frame_time * 1.5 else "HIGH"
            bottlenecks.append(BottleneckAnalysis(
                phase_name="Overall",
                severity=severity,
                issue_type="TIME",
                description=f"Frame time {avg_frame_time:.1f}ms exceeds target {self.target_frame_time:.1f}ms",
                recommendation="Optimize slowest phases or reduce quality settings",
                impact_score=min(100, (avg_frame_time / self.target_frame_time - 1) * 100)
            ))
        
        # ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥åˆ†æ
        for phase in phase_stats:
            # æ™‚é–“ãƒœãƒˆãƒ«ãƒãƒƒã‚¯
            if phase.execution_time_ms > 15:  # 15msé–¾å€¤
                severity = "CRITICAL" if phase.execution_time_ms > 25 else "HIGH"
                bottlenecks.append(BottleneckAnalysis(
                    phase_name=phase.name,
                    severity=severity,
                    issue_type="TIME", 
                    description=f"Phase takes {phase.execution_time_ms:.1f}ms",
                    recommendation=self._get_phase_recommendation(phase.name, "TIME"),
                    impact_score=min(100, phase.execution_time_ms * 2)
                ))
            
            # CPU ãƒœãƒˆãƒ«ãƒãƒƒã‚¯
            if phase.cpu_usage_percent > 80:
                bottlenecks.append(BottleneckAnalysis(
                    phase_name=phase.name,
                    severity="HIGH",
                    issue_type="CPU",
                    description=f"High CPU usage {phase.cpu_usage_percent:.1f}%",
                    recommendation=self._get_phase_recommendation(phase.name, "CPU"),
                    impact_score=phase.cpu_usage_percent - 50
                ))
            
            # GPU ãƒœãƒˆãƒ«ãƒãƒƒã‚¯
            if phase.gpu_usage_percent > 90:
                bottlenecks.append(BottleneckAnalysis(
                    phase_name=phase.name,
                    severity="HIGH",
                    issue_type="GPU",
                    description=f"High GPU usage {phase.gpu_usage_percent:.1f}%",
                    recommendation=self._get_phase_recommendation(phase.name, "GPU"),
                    impact_score=phase.gpu_usage_percent - 60
                ))
        
        return sorted(bottlenecks, key=lambda b: b.impact_score, reverse=True)
    
    def _get_phase_recommendation(self, phase_name: str, issue_type: str) -> str:
        """ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥æ¨å¥¨äº‹é …"""
        recommendations = {
            ("hand_detection", "TIME"): "MediaPipe confidence threshold increase or skip frames",
            ("hand_detection", "CPU"): "Reduce input resolution or detection frequency",
            ("mesh_generation", "TIME"): "Use incremental mesh updates or simplify",
            ("mesh_generation", "CPU"): "Enable mesh caching or reduce triangle count",
            ("collision_detection", "TIME"): "Use broadphase optimization with KD-Tree",
            ("collision_detection", "CPU"): "Enable GPU acceleration or reduce precision",
            ("distance_calculation", "TIME"): "Enable Numba JIT or GPU calculation",
            ("distance_calculation", "GPU"): "Optimize batch size or use mixed precision"
        }
        
        return recommendations.get((phase_name.lower(), issue_type), 
                                 f"Optimize {phase_name} for {issue_type} usage")


# ä¾¿åˆ©é–¢æ•°ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£

class ProfiledPhase:
    """ãƒ•ã‚§ãƒ¼ã‚ºãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ç”¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£"""
    
    def __init__(self, profiler: PerformanceProfiler, phase_name: str):
        self.profiler = profiler
        self.phase_name = phase_name
    
    def __enter__(self):
        self.profiler.start_phase(self.phase_name)
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.profiler.end_phase()


def profile_function(profiler: PerformanceProfiler, phase_name: str):
    """é–¢æ•°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ç”¨ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            with ProfiledPhase(profiler, phase_name):
                return func(*args, **kwargs)
        return wrapper
    return decorator


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
global_profiler: Optional[PerformanceProfiler] = None

def get_global_profiler() -> PerformanceProfiler:
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©å–å¾—"""
    global global_profiler
    if global_profiler is None:
        global_profiler = PerformanceProfiler()
    return global_profiler

def start_global_profiling():
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°é–‹å§‹"""
    get_global_profiler().start_profiling()

def stop_global_profiling() -> Optional[PerformanceReport]:
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°åœæ­¢"""
    if global_profiler:
        return global_profiler.stop_profiling()
    return None


# ---------------------------------------------------------------------------
# Memory leak diagnostics â€“ tracemalloc logger (T-MEM-001)
# ---------------------------------------------------------------------------

import tracemalloc


def start_tracemalloc_logger(enable: bool = True, interval: int = 1000, top_n: int = 20) -> None:  # noqa: D401
    """Start a background thread that periodically prints the largest memory
    allocations captured by *tracemalloc*.

    Parameters
    ----------
    enable
        Enable or disable the logger (no-op when *False*).
    interval
        Number of **frames** between snapshot comparisons â€“ piggy-back on the
        global `PerformanceProfiler` frame counter. 1000 frames at 30 FPS â‰ˆ 33 s.
    top_n
        How many top allocation statistics to display.
    """

    if not enable:
        logger.debug("Tracemalloc logger disabled by configuration")
        return

    if tracemalloc.is_tracing():
        logger.debug("Tracemalloc logger already running â€“ skipping re-initialisation")
        return

    tracemalloc.start()

    logger.info("ğŸ“ˆ Tracemalloc logger started â€“ interval=%d frames, top=%d", interval, top_n)

    import threading
    import time

    def _worker() -> None:  # pragma: no cover â€“ debug utility
        global_prof = get_global_profiler()
        if global_prof is None:
            logger.warning("No global PerformanceProfiler â€“ tracemalloc logger will poll on wall-clock instead")

        last_snapshot = tracemalloc.take_snapshot()
        last_frame = 0

        while True:
            # Determine whether *interval* frames have elapsed (if profiler available)
            frame_ok = False
            if global_prof and global_prof.current_frame - last_frame >= interval:
                frame_ok = True
                last_frame = global_prof.current_frame
            elif global_prof is None:
                # Fallback: wait fixed seconds (approx 30 FPS)
                time.sleep(interval / 30.0)
                frame_ok = True

            if not frame_ok:
                time.sleep(0.01)
                continue

            try:
                snapshot = tracemalloc.take_snapshot()
                top_stats = snapshot.compare_to(last_snapshot, "lineno")[:top_n]
                logger.info("ğŸ“Š [Tracemalloc] Top %d differences:", top_n)
                for stat in top_stats:
                    logger.info("  %s", stat)
                last_snapshot = snapshot
            except Exception as exc:  # pylint: disable=broad-except
                logger.error("Tracemalloc logger error: %s", exc)
                break

    threading.Thread(target=_worker, daemon=True, name="TracemallocLogger").start() 