#!/usr/bin/env python3
"""
çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ï¼ˆClean Architectureé©ç”¨ï¼‰
è²¬å‹™: å…¥åŠ›â†’æ¤œå‡ºâ†’ãƒ¡ãƒƒã‚·ãƒ¥â†’è¡çªâ†’éŸ³éŸ¿ã®å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆå‡¦ç†
"""

import time
import psutil
from typing import Optional, List, Dict, Any
from dataclasses import dataclass, field
import numpy as np

# åŸºæœ¬å‹ãƒ»è¨­å®š
from ..types import FrameData
from ..sound.mapping import ScaleType, InstrumentType

# å…¥åŠ›ãƒ•ã‚§ãƒ¼ã‚º
from ..input.stream import OrbbecCamera
from ..input.depth_filter import DepthFilter, FilterType
from ..input.pointcloud import PointCloudConverter

# æ¤œå‡ºãƒ•ã‚§ãƒ¼ã‚º
from ..detection.hands2d import MediaPipeHandsWrapper
from ..detection.hands3d import Hand3DProjector, DepthInterpolationMethod
from ..detection.tracker import Hand3DTracker, TrackedHand

# ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆãƒ•ã‚§ãƒ¼ã‚º
from ..mesh.projection import PointCloudProjector, ProjectionMethod
from ..mesh.delaunay import DelaunayTriangulator
from ..mesh.simplify import MeshSimplifier

# LODãƒ¡ãƒƒã‚·ãƒ¥ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
try:
    from ..mesh.lod_mesh import create_lod_mesh_generator
    HAS_LOD_MESH = True
except ImportError:
    HAS_LOD_MESH = False

# è¡çªæ¤œå‡ºãƒ•ã‚§ãƒ¼ã‚º
from ..collision.search import CollisionSearcher
from ..collision.sphere_tri import SphereTriangleCollision
from ..collision.events import CollisionEventQueue
from ..mesh.index import SpatialIndex, IndexType

# éŸ³éŸ¿ç”Ÿæˆãƒ•ã‚§ãƒ¼ã‚º
from ..sound.mapping import AudioMapper
from ..sound.synth import AudioSynthesizer, create_audio_synthesizer
from ..sound.voice_mgr import VoiceManager, create_voice_manager, allocate_and_play, StealStrategy

# GPUåŠ é€Ÿï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
try:
    from ..collision.distance_gpu import create_gpu_distance_calculator
    from ..mesh.delaunay_gpu import create_gpu_triangulator
    HAS_GPU_ACCELERATION = True
except ImportError:
    HAS_GPU_ACCELERATION = False


@dataclass
class PipelineResults:
    """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†çµæœ"""
    frame_data: Optional[FrameData] = None
    hands_2d: List = field(default_factory=list)
    hands_3d: List = field(default_factory=list)
    tracked_hands: List[TrackedHand] = field(default_factory=list)
    mesh: Optional[Any] = None
    collision_events: List = field(default_factory=list)
    audio_events: List = field(default_factory=list)
    performance_stats: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """è¾æ›¸å½¢å¼ã§çµæœã‚’è¿”ã™"""
        return {
            'frame_data': self.frame_data,
            'hands_2d': self.hands_2d,
            'hands_3d': self.hands_3d,
            'tracked_hands': self.tracked_hands,
            'mesh': self.mesh,
            'collision_events': self.collision_events,
            'audio_events': self.audio_events,
            'performance_stats': self.performance_stats
        }


@dataclass
class HandledPipelineConfig:
    """çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®š"""
    # å…¥åŠ›è¨­å®š
    enable_filter: bool = True
    enable_hand_detection: bool = True
    enable_tracking: bool = True
    min_detection_confidence: float = 0.7
    use_gpu_mediapipe: bool = False
    
    # ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆè¨­å®š
    enable_mesh_generation: bool = True
    mesh_update_interval: int = 10
    max_mesh_skip_frames: int = 60
    mesh_resolution: float = 0.01
    mesh_quality_threshold: float = 0.3
    mesh_reduction: float = 0.7
    
    # è¡çªæ¤œå‡ºè¨­å®š
    enable_collision_detection: bool = True
    enable_collision_visualization: bool = True
    sphere_radius: float = 0.05
    
    # éŸ³éŸ¿åˆæˆè¨­å®š
    enable_audio_synthesis: bool = True
    audio_scale: ScaleType = ScaleType.PENTATONIC
    audio_instrument: InstrumentType = InstrumentType.MARIMBA
    audio_polyphony: int = 16
    audio_master_volume: float = 0.7
    
    # ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°è¨­å®š
    enable_voxel_downsampling: bool = True
    voxel_size: float = 0.005
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š
    enable_gpu_acceleration: bool = True
    
    # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰è¨­å®šï¼ˆæ–°è¦è¿½åŠ ï¼‰
    headless_mode: bool = False


class HandledPipeline:
    """
    çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ã‚¯ãƒ©ã‚¹
    è²¬å‹™: å…¥åŠ›â†’æ¤œå‡ºâ†’ãƒ¡ãƒƒã‚·ãƒ¥â†’è¡çªâ†’éŸ³éŸ¿ã®å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆå‡¦ç†
    """
    
    def __init__(self, config: HandledPipelineConfig):
        """çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–"""
        print("çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–ä¸­...")
        
        # è¨­å®šä¿å­˜
        self.config = config
        
        # ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢ï¼‰
        self.color_extraction_errors = 0
        self.max_color_extraction_errors = 10
        self.color_extraction_disabled = False
        
        self.camera: Optional[OrbbecCamera] = None
        
        # åŸºæœ¬ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.depth_filter: Optional[DepthFilter] = None
        self.pointcloud_converter: Optional[PointCloudConverter] = None
        self.hands_2d: Optional[MediaPipeHandsWrapper] = None
        self.projector_3d: Optional[Hand3DProjector] = None
        self.tracker: Optional[Hand3DTracker] = None
        
        # ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.projector: Optional[PointCloudProjector] = None
        self.triangulator: Optional[DelaunayTriangulator] = None
        self.lod_mesh_generator: Optional[Any] = None
        self.simplifier: Optional[MeshSimplifier] = None
        
        # è¡çªæ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.spatial_index: Optional[SpatialIndex] = None
        self.collision_searcher: Optional[CollisionSearcher] = None
        self.collision_tester: Optional[SphereTriangleCollision] = None
        self.event_queue = CollisionEventQueue()
        
        # éŸ³éŸ¿ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.audio_mapper: Optional[AudioMapper] = None
        self.audio_synthesizer: Optional[AudioSynthesizer] = None
        self.voice_manager: Optional[VoiceManager] = None
        self.audio_enabled = False
        
        # GPUåŠ é€Ÿã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.gpu_distance_calc: Optional[Any] = None
        self.gpu_triangulator: Optional[Any] = None
        self.gpu_acceleration_enabled = False
        
        # çŠ¶æ…‹ç®¡ç†
        self.current_mesh = None
        self.current_collision_points = []
        self.current_tracked_hands = []
        self.frame_counter = 0
        self.last_mesh_update = -999
        self.force_mesh_update_requested = False
        
        # éŸ³éŸ¿ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ç®¡ç†
        self.audio_cooldown_time = 0.15
        self.last_audio_trigger_time = {}
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        self.perf_stats = {
            'frame_count': 0,
            'mesh_generation_time': 0.0,
            'collision_detection_time': 0.0,
            'audio_synthesis_time': 0.0,
            'collision_events_count': 0,
            'audio_notes_played': 0,
            'total_pipeline_time': 0.0
        }
        
        # GPUçµ±è¨ˆ
        self.gpu_stats = {
            'distance_calculations': 0,
            'triangulations': 0,
            'gpu_time_total_ms': 0.0,
            'cpu_fallbacks': 0
        }
        
        # åˆæœŸåŒ–å®Œäº†ãƒ•ãƒ©ã‚°
        self._initialized = False
    
    def initialize(self, camera: Optional[OrbbecCamera] = None) -> bool:
        """
        ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
        
        Args:
            camera: ã‚«ãƒ¡ãƒ©ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆNoneã®å ´åˆã¯å†…éƒ¨ã§ä½œæˆï¼‰
        
        Returns:
            åˆæœŸåŒ–æˆåŠŸæ™‚True
        """
        try:
            print("çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–ä¸­...")
            
            # ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–
            if camera:
                self.camera = camera
            else:
                self.camera = OrbbecCamera()
                if not self.camera.initialize():
                    print("Failed to initialize camera")
                    return False
            
            # ã‚«ãƒ¡ãƒ©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—å¾Œã«PointCloudConverteråˆæœŸåŒ–
            depth_intrinsics = self.camera.depth_intrinsics
            if depth_intrinsics:
                self.pointcloud_converter = PointCloudConverter(
                    depth_intrinsics=depth_intrinsics,
                    enable_voxel_downsampling=self.config.enable_voxel_downsampling,
                    voxel_size=self.config.voxel_size
                )
                
                # 3DæŠ•å½±åˆæœŸåŒ–
                if self.config.enable_hand_detection:
                    try:
                        self.projector_3d = Hand3DProjector(
                            camera_intrinsics=depth_intrinsics,
                            interpolation_method=DepthInterpolationMethod.LINEAR,
                            depth_scale=1000.0,
                            min_confidence_3d=0.3
                        )
                    except Exception as e:
                        print(f"3D projector initialization failed: {e}")
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€å°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§åˆæœŸåŒ–
                        try:
                            self.projector_3d = Hand3DProjector(camera_intrinsics=depth_intrinsics)
                        except Exception as e2:
                            print(f"3D projector fallback also failed: {e2}")
                            self.projector_3d = None
            
            # åŸºæœ¬ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
            if not self._initialize_basic_components():
                return False
            
            # ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
            if self.config.enable_mesh_generation:
                if not self._initialize_mesh_components():
                    return False
            
            # è¡çªæ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
            if self.config.enable_collision_detection:
                if not self._initialize_collision_components():
                    return False
            
            # éŸ³éŸ¿ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
            if self.config.enable_audio_synthesis:
                if not self._initialize_audio_components():
                    return False
            
            # GPUåŠ é€ŸåˆæœŸåŒ–
            if self.config.enable_gpu_acceleration and HAS_GPU_ACCELERATION:
                self._initialize_gpu_acceleration()
            
            self._initialized = True
            print("çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–å®Œäº†")
            return True
            
        except Exception as e:
            print(f"Pipeline initialization error: {e}")
            return False
    
    def _initialize_basic_components(self) -> bool:
        """åŸºæœ¬ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–"""
        try:
            # æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿
            if self.config.enable_filter:
                self.depth_filter = DepthFilter(
                    filter_types=[FilterType.TEMPORAL],
                    temporal_history_size=5,
                    temporal_alpha=0.3
                )
            
            # ç‚¹ç¾¤ã‚³ãƒ³ãƒãƒ¼ã‚¿ï¼ˆã‚«ãƒ¡ãƒ©åˆæœŸåŒ–å¾Œã«è¨­å®šï¼‰
            self.pointcloud_converter = None
            
            # æ‰‹æ¤œå‡ºï¼ˆ2Dï¼‰ï¼šãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰æ™‚ã¯ç„¡åŠ¹åŒ–
            if self.config.enable_hand_detection and not self.config.headless_mode:
                try:
                    self.hands_2d = MediaPipeHandsWrapper(
                        min_detection_confidence=self.config.min_detection_confidence,
                        min_tracking_confidence=0.5,
                        max_num_hands=2,
                        enable_roi_tracking=True,
                        tracker_type="KCF",
                        skip_interval=4,
                        roi_confidence_threshold=0.6,
                        max_tracking_age=15
                    )
                    print("âœ… MediaPipeæ‰‹æ¤œå‡ºãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¾ã—ãŸï¼ˆé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼‰")
                except Exception as e:
                    print(f"âš ï¸  MediaPipeæ‰‹æ¤œå‡ºã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
                    self.hands_2d = None
                    
            elif self.config.headless_mode:
                # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰æ™‚ã¯MediaPipeã‚’ç„¡åŠ¹åŒ–ã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Š
                self.hands_2d = None
                print("ğŸ–¥ï¸  ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰: MediaPipeæ‰‹æ¤œå‡ºã‚’ç„¡åŠ¹åŒ–ï¼ˆFPSæœ€é©åŒ–ï¼‰")
            else:
                self.hands_2d = None
                print("ğŸ”§ æ‰‹æ¤œå‡ºãŒè¨­å®šã§ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™")
            
            # 3DæŠ•å½±ï¼ˆã‚«ãƒ¡ãƒ©åˆæœŸåŒ–ãŒå¿…è¦ï¼‰
            self.projector_3d = None
            
            # 3Dãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
            if self.config.enable_tracking:
                try:
                    self.tracker = Hand3DTracker(
                        max_assignment_distance=0.15,
                        max_lost_frames=20,
                        min_track_length=3,
                        dt=1.0/30.0
                    )
                except Exception as e:
                    print(f"3D tracker initialization failed: {e}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§åˆæœŸåŒ–
                    try:
                        self.tracker = Hand3DTracker()
                    except Exception as e2:
                        print(f"3D tracker fallback also failed: {e2}")
                        self.tracker = None
            
            return True
            
        except Exception as e:
            print(f"Basic components initialization error: {e}")
            return False
    
    def _initialize_mesh_components(self) -> bool:
        """ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆãƒ¡ãƒ¢ãƒªåˆ¶é™ä»˜ãï¼‰"""
        try:
            # åœ°å½¢ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ
            self.projector = PointCloudProjector(
                resolution=self.config.mesh_resolution,
                method=ProjectionMethod.MEDIAN_HEIGHT,
                fill_holes=True
            )
            
            # LODãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆå™¨ï¼ˆãƒ¡ãƒ¢ãƒªåˆ¶é™ä»˜ãï¼‰
            if HAS_LOD_MESH:
                try:
                    self.lod_mesh_generator = create_lod_mesh_generator(
                        high_radius=0.15,  # 0.20 -> 0.15 (ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å‰Šæ¸›)
                        medium_radius=0.40,  # 0.50 -> 0.40
                    enable_gpu=self.config.enable_gpu_acceleration
                )
                except Exception as e:
                    print(f"LOD mesh generator initialization failed: {e}")
                    self.lod_mesh_generator = None
            
            # Delaunayä¸‰è§’åˆ†å‰²ï¼ˆåŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ï¼‰
            self.triangulator = DelaunayTriangulator()
            
            # ãƒ¡ãƒƒã‚·ãƒ¥ç°¡ç•¥åŒ–ï¼ˆåŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ï¼‰
            self.simplifier = MeshSimplifier()
            
            return True
            
        except Exception as e:
            print(f"Mesh components initialization error: {e}")
            return False
    
    def _initialize_collision_components(self) -> bool:
        """è¡çªæ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–"""
        try:
            # ç©ºé–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆãƒ¡ãƒƒã‚·ãƒ¥ãŒå¿…è¦ãªå ´åˆã¯å¾Œã§åˆæœŸåŒ–ï¼‰
            self.spatial_index = None
            
            # è¡çªæ¤œç´¢ï¼ˆå¾Œã§åˆæœŸåŒ–ï¼‰
            self.collision_searcher = None
            
            # çƒ-ä¸‰è§’å½¢è¡çªãƒ†ã‚¹ãƒˆï¼ˆå¾Œã§åˆæœŸåŒ–ï¼‰
            self.collision_tester = None
            
            return True
            
        except Exception as e:
            print(f"Collision components initialization error: {e}")
            return False
    
    def _initialize_audio_components(self) -> bool:
        """éŸ³éŸ¿ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–"""
        try:
            # éŸ³éŸ¿ãƒãƒƒãƒ”ãƒ³ã‚°
            self.audio_mapper = AudioMapper(
                scale=self.config.audio_scale,
                default_instrument=self.config.audio_instrument
            )
            
            # éŸ³éŸ¿ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ãƒ¼
            try:
                self.audio_synthesizer = create_audio_synthesizer()
                if not self.audio_synthesizer.initialize():
                    print("Warning: Audio synthesizer initialization failed")
                    return True  # éŸ³éŸ¿ã¯å¿…é ˆã§ã¯ãªã„
            except (ImportError, AttributeError):
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç›´æ¥AudioSynthesizerã‚’ä½¿ç”¨
                self.audio_synthesizer = AudioSynthesizer()
                if not self.audio_synthesizer.initialize():
                    print("Warning: Audio synthesizer initialization failed")
                    return True  # éŸ³éŸ¿ã¯å¿…é ˆã§ã¯ãªã„
            
            # ãƒœã‚¤ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
            try:
                self.voice_manager = create_voice_manager(
                    synthesizer=self.audio_synthesizer,
                    max_polyphony=self.config.audio_polyphony,
                    steal_strategy=StealStrategy.OLDEST
                )
            except (ImportError, AttributeError):
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç›´æ¥VoiceManagerã‚’ä½¿ç”¨
                self.voice_manager = VoiceManager(
                    synthesizer=self.audio_synthesizer,
                    max_polyphony=self.config.audio_polyphony
                )
            
            self.audio_enabled = True
            return True
            
        except Exception as e:
            print(f"Audio components initialization error: {e}")
            return True  # éŸ³éŸ¿ã¯å¿…é ˆã§ã¯ãªã„
    
    def _initialize_gpu_acceleration(self) -> None:
        """GPUåŠ é€ŸåˆæœŸåŒ–"""
        try:
            self.gpu_distance_calc = create_gpu_distance_calculator(
                use_gpu=True,
                batch_size=10000,
                memory_limit_ratio=0.8
            )
            
            self.gpu_triangulator = create_gpu_triangulator(
                use_gpu=True,
                quality_threshold=0.2,
                enable_caching=True
            )
            
            self.gpu_acceleration_enabled = True
            print("GPU acceleration initialized successfully")
            
        except Exception as e:
            print(f"GPU acceleration initialization failed: {e}")
            print("Falling back to CPU-only processing")
    
    def process_frame(self) -> Optional[PipelineResults]:
        """
        ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†å®Ÿè¡Œ
        
        Returns:
            å‡¦ç†çµæœ
        """
        if not self._initialized:
            return None
        
        start_time = time.perf_counter()
        
        try:
            # ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—
            frame_data = self.camera.get_frame()
            if frame_data is None:
                return None
            
            # åŸºæœ¬å‡¦ç†
            results = self._process_basic_pipeline(frame_data)
            if not results:
                return None
            
            # ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ
            if self.config.enable_mesh_generation:
                self._process_mesh_generation(results)
            
            # è¡çªæ¤œå‡º
            if self.config.enable_collision_detection:
                self._process_collision_detection(results)
            
            # éŸ³éŸ¿åˆæˆ
            if self.config.enable_audio_synthesis:
                self._process_audio_synthesis(results)
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆæ›´æ–°
            total_time = time.perf_counter() - start_time
            self._update_performance_stats(total_time)
            results.performance_stats = self.perf_stats.copy()
            
            self.frame_counter += 1
            return results
            
        except Exception as e:
            print(f"Frame processing error: {e}")
            return None
    
    def _process_basic_pipeline(self, frame_data: FrameData) -> Optional[PipelineResults]:
        """åŸºæœ¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†"""
        try:
            results = PipelineResults(frame_data=frame_data)
            
            # æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
            filtered_depth_image = None
            if self.depth_filter and hasattr(frame_data, 'depth_image') and frame_data.depth_image is not None:
                filtered_depth_image = self.depth_filter.apply_filter(frame_data.depth_image)
            else:
                filtered_depth_image = frame_data.depth_image
            
            # ç‚¹ç¾¤å¤‰æ›
            if self.pointcloud_converter and filtered_depth_image is not None:
                points = self.pointcloud_converter.depth_to_pointcloud(filtered_depth_image)
                frame_data.points = points
            
            # æ‰‹æ¤œå‡ºï¼ˆ2Dï¼‰
            if self.hands_2d and frame_data.color_frame is not None:
                # ã‚«ãƒ©ãƒ¼æŠ½å‡ºã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãƒã‚§ãƒƒã‚¯
                if self.color_extraction_disabled:
                    # ã‚¨ãƒ©ãƒ¼ä¸Šé™ã«é”ã—ã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    results.hands_2d = []
                else:
                    # ã‚ªãƒªã‚¸ãƒŠãƒ«ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ã‚«ãƒ©ãƒ¼ç”»åƒå‡¦ç†
                    color_image = self._extract_color_image_for_mediapipe(frame_data)
                    if color_image is not None:
                        # æ­£å¸¸ã«å–å¾—ã§ããŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ
                        self.color_extraction_errors = 0
                        hands_2d = self.hands_2d.detect_hands(color_image)
                        results.hands_2d = hands_2d
                    else:
                        # ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’å¢—åŠ 
                        self.color_extraction_errors += 1
                        results.hands_2d = []
                        
                        # ã‚¨ãƒ©ãƒ¼ä¸Šé™ãƒã‚§ãƒƒã‚¯
                        if self.color_extraction_errors >= self.max_color_extraction_errors:
                            print(f"Color extraction failed {self.max_color_extraction_errors} times, disabling MediaPipe processing")
                            self.color_extraction_disabled = True
            else:
                results.hands_2d = []
            
            # 3DæŠ•å½±
            if self.projector_3d and results.hands_2d and filtered_depth_image is not None:
                hands_3d = []
                for hand_2d in results.hands_2d:
                    hand_3d = self.projector_3d.project_to_3d(
                        hand_2d, filtered_depth_image, self.camera.depth_intrinsics
                    )
                    if hand_3d:
                        hands_3d.append(hand_3d)
                results.hands_3d = hands_3d
            
            # 3Dãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
            if self.tracker and results.hands_3d:
                tracked_hands = self.tracker.update(results.hands_3d)
                results.tracked_hands = tracked_hands
                self.current_tracked_hands = tracked_hands
            
            return results
            
        except Exception as e:
            print(f"Basic pipeline processing error: {e}")
            return None
    
    def _process_mesh_generation(self, results: PipelineResults) -> None:
        """ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆå‡¦ç†ï¼ˆãƒ¡ãƒ¢ãƒªç›£è¦–ä»˜ãï¼‰"""
        try:
            mesh_start = time.perf_counter()
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
            memory_percent = psutil.virtual_memory().percent
            if memory_percent > 85:  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡85%è¶…éã§è­¦å‘Š
                print(f"Warning: High memory usage ({memory_percent:.1f}%), skipping mesh generation")
                results.mesh = self.current_mesh  # æ—¢å­˜ãƒ¡ãƒƒã‚·ãƒ¥ã‚’å†åˆ©ç”¨
                return
            
            # ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°åˆ¤å®š
            should_update_mesh = (
                self.force_mesh_update_requested or
                (self.frame_counter - self.last_mesh_update >= self.config.mesh_update_interval) or
                (len(self.current_tracked_hands) == 0 and 
                 self.frame_counter - self.last_mesh_update >= self.config.max_mesh_skip_frames)
            )
            
            if should_update_mesh and results.frame_data and results.frame_data.points is not None:
                mesh = None
                points = results.frame_data.points
                
                # ç‚¹æ•°åˆ¶é™ï¼ˆãƒ¡ãƒ¢ãƒªä¿è­·ï¼‰
                if len(points) > 100000:  # 10ä¸‡ç‚¹ã‚’è¶…ãˆã‚‹å ´åˆã¯ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                    import random
                    indices = random.sample(range(len(points)), 100000)
                    points = points[indices]
                    print(f"Point cloud downsampled to {len(points)} points for memory protection")
                
                # LODãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚’å„ªå…ˆ
                if self.lod_mesh_generator:
                    try:
                        hand_positions = [h.palm_center for h in self.current_tracked_hands if h.palm_center is not None]
                        mesh = self.lod_mesh_generator.generate_mesh(
                            points,
                            hand_positions=hand_positions
                        )
                    except Exception as e:
                        print(f"LOD mesh generation failed: {e}")
                        # GPU ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å ´åˆã¯æ˜ç¤ºçš„ã«ã‚¯ãƒªã‚¢
                        if "memory" in str(e).lower() or "alloc" in str(e).lower():
                            print("GPU memory issue detected, forcing cleanup")
                            import gc
                            gc.collect()
                            # CUDA ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
                            try:
                                import torch
                                if torch.cuda.is_available():
                                    torch.cuda.empty_cache()
                            except ImportError:
                                pass
                
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®ä¸‰è§’åˆ†å‰²
                if mesh is None and self.triangulator:
                    try:
                        # åœ°å½¢æŠ•å½±
                        if self.projector:
                            projected_points = self.projector.project_points(points)
                            # æŠ•å½±ç‚¹æ•°ã‚‚åˆ¶é™
                            if len(projected_points) > 50000:
                                import random
                                indices = random.sample(range(len(projected_points)), 50000)
                                projected_points = projected_points[indices]
                            
                            mesh = self.triangulator.triangulate(projected_points)
                            
                            # ãƒ¡ãƒƒã‚·ãƒ¥ç°¡ç•¥åŒ–
                            if mesh and self.simplifier:
                                mesh = self.simplifier.simplify(mesh)
                    except Exception as e:
                        print(f"Fallback mesh generation failed: {e}")
                        # ãƒ¡ãƒ¢ãƒªé–¢é€£ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å¼·åˆ¶ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                        if "memory" in str(e).lower() or "alloc" in str(e).lower():
                            print("Memory allocation failed, forcing cleanup")
                            import gc
                            gc.collect()
                
                if mesh:
                    # ãƒ¡ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆãƒ¡ãƒ¢ãƒªä¿è­·ï¼‰
                    if hasattr(mesh, 'vertices') and len(mesh.vertices) > 50000:
                        print(f"Warning: Large mesh ({len(mesh.vertices)} vertices), may cause memory issues")
                    
                    self.current_mesh = mesh
                    results.mesh = mesh
                    self.last_mesh_update = self.frame_counter
                    self.force_mesh_update_requested = False
                else:
                    # ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆå¤±æ•—æ™‚ã¯æ—¢å­˜ãƒ¡ãƒƒã‚·ãƒ¥ã‚’ä¿æŒ
                    results.mesh = self.current_mesh
            else:
                # æ—¢å­˜ãƒ¡ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨
                results.mesh = self.current_mesh
            
            mesh_time = time.perf_counter() - mesh_start
            self.perf_stats['mesh_generation_time'] = mesh_time
            
        except Exception as e:
            print(f"Mesh generation processing error: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚æ—¢å­˜ãƒ¡ãƒƒã‚·ãƒ¥ã‚’ä¿æŒ
            results.mesh = self.current_mesh
            # ãƒ¡ãƒ¢ãƒªé–¢é€£ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç·Šæ€¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if "memory" in str(e).lower() or "alloc" in str(e).lower():
                print("Critical memory error, forcing garbage collection")
                import gc
                gc.collect()
    
    def _process_collision_detection(self, results: PipelineResults) -> None:
        """è¡çªæ¤œå‡ºå‡¦ç†"""
        try:
            collision_start = time.perf_counter()
            
            collision_events = []
            
            if results.mesh:
                
                # ç©ºé–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆæœŸåŒ–ï¼ˆåˆå›ã®ã¿ï¼‰
                if self.spatial_index is None:
                    try:
                        from ..mesh.index import SpatialIndex, IndexType
                        self.spatial_index = SpatialIndex(mesh=results.mesh, index_type=IndexType.OCTREE)
                    except Exception as e:
                        print(f"SpatialIndex initialization failed: {e}")
                        self.spatial_index = None
                
                # è¡çªæ¤œç´¢å™¨åˆæœŸåŒ–ï¼ˆåˆå›ã®ã¿ï¼‰
                if self.collision_searcher is None and self.spatial_index is not None:
                    try:
                        from ..collision.search import CollisionSearcher
                        self.collision_searcher = CollisionSearcher(
                            spatial_index=self.spatial_index,
                            default_radius=self.config.sphere_radius
                        )
                    except Exception as e:
                        print(f"CollisionSearcher initialization failed: {e}")
                        self.collision_searcher = None
                
                # çƒ-ä¸‰è§’å½¢è¡çªãƒ†ã‚¹ãƒˆåˆæœŸåŒ–ï¼ˆåˆå›ã®ã¿ï¼‰
                if self.collision_tester is None:
                    try:
                        from ..collision.sphere_tri import SphereTriangleCollision
                        self.collision_tester = SphereTriangleCollision(
                            mesh=results.mesh
                        )
                    except Exception as e:
                        print(f"SphereTriangleCollision initialization failed: {e}")
                        self.collision_tester = None
                
                # ç©ºé–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°
                if self.spatial_index:
                    self.spatial_index.build_index(results.mesh)
                
                # å„æ‰‹ã«ã¤ã„ã¦è¡çªæ¤œå‡ºï¼ˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã®ã¿ï¼‰
                if self.collision_searcher and self.collision_tester and self.spatial_index:
                    for hand in results.tracked_hands:
                        if hand.palm_center is not None:
                            try:
                                # å€™è£œä¸‰è§’å½¢æ¤œç´¢
                                candidates = self.collision_searcher.search_candidates(
                                    hand.palm_center, self.spatial_index
                                )
                                
                                # è©³ç´°è¡çªåˆ¤å®š
                                for triangle in candidates:
                                    if self.collision_tester.test_collision(hand.palm_center, triangle):
                                        # ç°¡æ˜“ç‰ˆCollisionEventã‚’ä½œæˆ
                                        collision_event = self._create_simple_collision_event(hand, triangle)
                                        collision_events.append(collision_event)
                                        self.event_queue.add_event(collision_event)
                            except Exception as e:
                                print(f"Collision detection error for hand {hand.hand_id}: {e}")
                                continue
            
            results.collision_events = collision_events
            self.current_collision_points = collision_events
            
            collision_time = time.perf_counter() - collision_start
            self.perf_stats['collision_detection_time'] = collision_time
            self.perf_stats['collision_events_count'] = len(collision_events)
            
        except Exception as e:
            print(f"Collision detection processing error: {e}")
    
    def _process_audio_synthesis(self, results: PipelineResults) -> None:
        """éŸ³éŸ¿åˆæˆå‡¦ç†"""
        try:
            audio_start = time.perf_counter()
            
            notes_played = 0
            
            if (self.audio_enabled and self.audio_mapper and 
                self.audio_synthesizer and self.voice_manager):
                
                current_time = time.time()
                
                for event in results.collision_events:
                    hand_id = event.get('hand_id', 'unknown')
                    
                    # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒã‚§ãƒƒã‚¯
                    last_trigger = self.last_audio_trigger_time.get(hand_id, 0)
                    if current_time - last_trigger >= self.audio_cooldown_time:
                        # éŸ³éŸ¿ãƒãƒƒãƒ”ãƒ³ã‚°
                        note_info = self.audio_mapper.map_collision_event(event)
                        
                        if note_info:
                            # éŸ³å£°åˆæˆï¼ˆçµ±ä¸€ã•ã‚ŒãŸAPIä½¿ç”¨ï¼‰
                            try:
                                # allocate_and_playé–¢æ•°ã‚’ä½¿ç”¨
                                success = allocate_and_play(
                                    voice_manager=self.voice_manager,
                                    note_info=note_info
                                )
                                if success:
                                    notes_played += 1
                                    self.last_audio_trigger_time[hand_id] = current_time
                            except (ImportError, AttributeError):
                                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®API
                                voice = self.voice_manager.allocate_voice()
                                if voice is not None:
                                    self.audio_synthesizer.play_note(voice, note_info)
                                    notes_played += 1
                                    self.last_audio_trigger_time[hand_id] = current_time
            
            audio_time = time.perf_counter() - audio_start
            self.perf_stats['audio_synthesis_time'] = audio_time
            self.perf_stats['audio_notes_played'] = notes_played
            
        except Exception as e:
            print(f"Audio synthesis processing error: {e}")
    
    def _update_performance_stats(self, total_time: float) -> None:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆæ›´æ–°"""
        self.perf_stats['frame_count'] = self.frame_counter
        self.perf_stats['total_pipeline_time'] = total_time
    
    def force_mesh_update(self) -> None:
        """ãƒ¡ãƒƒã‚·ãƒ¥å¼·åˆ¶æ›´æ–°è¦æ±‚"""
        self.force_mesh_update_requested = True
    
    def update_config(self, config: HandledPipelineConfig) -> None:
        """è¨­å®šæ›´æ–°"""
        self.config = config
        
        # å‹•çš„è¨­å®šæ›´æ–°
        if self.collision_tester:
            self.collision_tester.radius = config.sphere_radius
        
        if self.audio_mapper:
            self.audio_mapper.scale = config.audio_scale
            self.audio_mapper.default_instrument = config.audio_instrument
        
        if self.voice_manager:
            self.voice_manager.max_polyphony = config.audio_polyphony
            # master_volumeã¯éŸ³éŸ¿ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ãƒ¼å´ã§ç®¡ç†
            if self.audio_synthesizer:
                self.audio_synthesizer.set_master_volume(config.audio_master_volume)
    
    def _extract_color_image_for_mediapipe(self, frame_data):
        """MediaPipeç”¨ã‚«ãƒ©ãƒ¼ç”»åƒæŠ½å‡ºï¼ˆMJPGå¯¾å¿œãƒ»C-contiguouså®Œå…¨å¯¾å¿œç‰ˆï¼‰"""
        try:
            # ã‚¨ãƒ©ãƒ¼åˆ¶é™ãƒã‚§ãƒƒã‚¯ï¼ˆã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
            if self.color_extraction_disabled:
                return None
                
            if frame_data is None:
                return None
                
            if not hasattr(frame_data, 'color_frame') or frame_data.color_frame is None:
                return None
                
            if not hasattr(self, 'camera') or self.camera is None:
                return None
                
            if not hasattr(self.camera, 'has_color') or not self.camera.has_color:
                return None
            
            import cv2
            from ..types import OBFormat
            
            # ã‚«ãƒ©ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰å®‰å…¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            try:
                color_frame = frame_data.color_frame
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ å½¢å¼ã‚’ç¢ºèª
                frame_format = getattr(color_frame, 'get_format', lambda: OBFormat.RGB)()
                

                
                if str(frame_format) == "OBFormat.MJPG" or str(frame_format) == "MJPG":
                    # MJPGå½¢å¼ã®å ´åˆï¼šJPEGãƒ‡ã‚³ãƒ¼ãƒ‰ãŒå¿…è¦
                    try:
                        # get_data()ã§JPEGãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                        jpeg_data = color_frame.get_data()
                        if jpeg_data is None:
                            if not hasattr(self, '_mjpg_no_data_error_shown'):
                                print("MJPG: No data from color frame")
                                self._mjpg_no_data_error_shown = True
                            return None
                        
                        # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’ç¢ºèª
                        data_size = 0
                        jpeg_bytes = None
                        
                        # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’numpyé…åˆ—ã«å¤‰æ›ï¼ˆè¤‡æ•°ã®æ–¹æ³•ã§è©¦è¡Œï¼‰
                        try:
                            if hasattr(jpeg_data, 'tobytes'):
                                jpeg_bytes = jpeg_data.tobytes()
                            elif hasattr(jpeg_data, '__bytes__'):
                                jpeg_bytes = bytes(jpeg_data)
                            elif hasattr(jpeg_data, '__array__'):
                                jpeg_array_raw = np.array(jpeg_data, dtype=np.uint8)
                                jpeg_bytes = jpeg_array_raw.tobytes()
                            else:
                                # æœ€å¾Œã®æ‰‹æ®µï¼šç›´æ¥bytes()ã‚’è©¦è¡Œ
                                jpeg_bytes = bytes(jpeg_data)
                            
                            data_size = len(jpeg_bytes)
                            
                        except Exception as data_convert_error:
                            if not hasattr(self, '_mjpg_data_convert_error_shown'):
                                print(f"MJPG data conversion failed: {data_convert_error}")
                                self._mjpg_data_convert_error_shown = True
                            return None
                        
                        # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå¦¥å½“ã‹ãƒã‚§ãƒƒã‚¯
                        if data_size < 100:  # JPEGã¯æœ€ä½ã§ã‚‚100ãƒã‚¤ãƒˆä»¥ä¸Šå¿…è¦
                            if not hasattr(self, '_mjpg_small_data_error_shown'):
                                print(f"MJPG data too small: {data_size} bytes")
                                self._mjpg_small_data_error_shown = True
                            return None
                        
                        # OpenCVã§JPEGãƒ‡ã‚³ãƒ¼ãƒ‰
                        jpeg_array = np.frombuffer(jpeg_bytes, dtype=np.uint8)
                        bgr_image = cv2.imdecode(jpeg_array, cv2.IMREAD_COLOR)
                        
                        if bgr_image is None:
                            if not hasattr(self, '_mjpg_opencv_decode_error_shown'):
                                print(f"OpenCV MJPG decode failed (data size: {data_size} bytes)")
                                self._mjpg_opencv_decode_error_shown = True
                            return None
                        
                        # ç”»åƒã‚µã‚¤ã‚ºã‚’ç¢ºèª
                        if bgr_image.shape[0] == 0 or bgr_image.shape[1] == 0:
                            if not hasattr(self, '_mjpg_zero_size_error_shown'):
                                print(f"MJPG decoded to zero size image: {bgr_image.shape}")
                                self._mjpg_zero_size_error_shown = True
                            return None
                        
                        # BGRã‹ã‚‰RGBã«å¤‰æ›
                        rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)
                        
                        # C-contiguousé…åˆ—ã¨ã—ã¦ç¢ºå®Ÿã«ä½œæˆ
                        rgb_image = np.ascontiguousarray(rgb_image, dtype=np.uint8)
                        
                        # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯åˆå›ã®ã¿è¡¨ç¤º
                        if not hasattr(self, '_mjpg_success_shown'):
                            print(f"âœ… MJPG processing successful: {rgb_image.shape} ({data_size} bytes)")
                            self._mjpg_success_shown = True
                        
                        return rgb_image
                        
                    except Exception as e:
                        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯åˆå›ã®ã¿è¡¨ç¤º
                        if not hasattr(self, '_mjpg_processing_error_shown'):
                            print(f"MJPG processing error: {e}")
                            self._mjpg_processing_error_shown = True
                        return None
                
                elif str(frame_format) in ["OBFormat.RGB", "RGB", "OBFormat.BGR", "BGR"]:
                    # RGB/BGRå½¢å¼ã®å ´åˆï¼šç›´æ¥ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    try:
                        # get_data()ã§ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                        raw_data = color_frame.get_data()
                        if raw_data is None:
                            return None
                        
                        # ã‚«ãƒ¡ãƒ©ã®è§£åƒåº¦æƒ…å ±ã‚’å–å¾—
                        width = getattr(color_frame, 'get_width', lambda: 640)()
                        height = getattr(color_frame, 'get_height', lambda: 480)()
                        
                        # numpyé…åˆ—ã«å¤‰æ›ï¼ˆC-contiguousä¿è¨¼ï¼‰
                        if hasattr(raw_data, 'tobytes'):
                            data_bytes = raw_data.tobytes()
                        else:
                            data_bytes = bytes(raw_data)
                        
                        # RGB/BGRé…åˆ—ã¨ã—ã¦å†æ§‹ç¯‰
                        color_array = np.frombuffer(data_bytes, dtype=np.uint8)
                        color_array = color_array.reshape((height, width, 3))
                        
                        # C-contiguousé…åˆ—ã¨ã—ã¦ç¢ºå®Ÿã«ä½œæˆ
                        color_array = np.ascontiguousarray(color_array, dtype=np.uint8)
                        
                        # BGRâ†’RGBå¤‰æ›ãŒå¿…è¦ãªå ´åˆ
                        if str(frame_format) in ["OBFormat.BGR", "BGR"]:
                            color_array = cv2.cvtColor(color_array, cv2.COLOR_BGR2RGB)
                            color_array = np.ascontiguousarray(color_array, dtype=np.uint8)
                        
                        return color_array
                        
                    except Exception as e:
                        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯åˆå›ã®ã¿è¡¨ç¤º
                        if not hasattr(self, '_rgb_bgr_processing_error_shown'):
                            print(f"RGB/BGR processing error: {e}")
                            self._rgb_bgr_processing_error_shown = True
                        return None
                
                else:
                    # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„å½¢å¼ï¼ˆåˆå›ã®ã¿è¡¨ç¤ºï¼‰
                    if not hasattr(self, '_unsupported_format_error_shown'):
                        print(f"Unsupported color format: {frame_format}")
                        self._unsupported_format_error_shown = True
                    return None
                    
            except Exception as e:
                # ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã®æ›´æ–°
                self.color_extraction_errors += 1
                
                # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯åˆå›ã®ã¿è¡¨ç¤º
                if not hasattr(self, '_color_frame_access_error_shown'):
                    print(f"Color frame access error: {e}")
                    self._color_frame_access_error_shown = True
                
                # ã‚¨ãƒ©ãƒ¼ãŒå¤šã™ãã‚‹å ´åˆã¯ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ã‚’ä½œå‹•
                if self.color_extraction_errors >= self.max_color_extraction_errors:
                    if not hasattr(self, '_circuit_breaker_triggered'):
                        print(f"âš ï¸  Color extraction circuit breaker triggered after {self.max_color_extraction_errors} errors")
                        self._circuit_breaker_triggered = True
                    self.color_extraction_disabled = True
                
                return None
                
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã®æ›´æ–°
            self.color_extraction_errors += 1
            
            # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯åˆå›ã®ã¿è¡¨ç¤º
            if not hasattr(self, '_color_extraction_error_shown'):
                print(f"Color image extraction error: {e}")
                self._color_extraction_error_shown = True
            
            # ã‚¨ãƒ©ãƒ¼ãŒå¤šã™ãã‚‹å ´åˆã¯ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ã‚’ä½œå‹•
            if self.color_extraction_errors >= self.max_color_extraction_errors:
                if not hasattr(self, '_circuit_breaker_triggered'):
                    print(f"âš ï¸  Color extraction circuit breaker triggered after {self.max_color_extraction_errors} errors")
                    self._circuit_breaker_triggered = True
                self.color_extraction_disabled = True
            
            return None
    
    def _create_simple_collision_event(self, hand, triangle):
        """ç°¡æ˜“ç‰ˆCollisionEventã‚’ä½œæˆ"""
        from ..collision.events import CollisionEvent, CollisionIntensity, EventType
        from ..types import CollisionType
        
        # åŸºæœ¬çš„ãªè¡çªã‚¤ãƒ™ãƒ³ãƒˆã‚’ä½œæˆï¼ˆå¿…è¦æœ€å°é™ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
        return CollisionEvent(
            event_id=f"collision_{int(time.time() * 1000000)}",
            event_type=EventType.COLLISION_START,
            timestamp=time.time(),
            duration_ms=0.0,
            
            contact_position=hand.palm_center.copy(),
            hand_position=hand.palm_center.copy(),
            surface_normal=np.array([0.0, 1.0, 0.0]),  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ³•ç·š
            
            intensity=CollisionIntensity.MEDIUM,
            velocity=hand.speed if hasattr(hand, 'speed') else 0.1,
            penetration_depth=0.01,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            contact_area=0.001,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            
            pitch_hint=max(0.0, min(1.0, hand.palm_center[1])),  # Yåº§æ¨™ã‚’æ­£è¦åŒ–
            timbre_hint=0.5,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            spatial_position=np.array([hand.palm_center[0], 0.0, hand.palm_center[2]]),
            
            triangle_index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            hand_id=hand.hand_id,
            collision_type=CollisionType.FACE_COLLISION if hasattr(CollisionType, 'FACE_COLLISION') else None
        )
    
    def cleanup(self) -> None:
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†"""
        try:
            if self.audio_synthesizer:
                self.audio_synthesizer.cleanup()
            
            if self.camera:
                self.camera.cleanup()
            
            self._initialized = False
            
        except Exception as e:
            print(f"Pipeline cleanup error: {e}")