#!/usr/bin/env python3
"""
Geocussion-SP ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¢ï¼ˆè¡çªæ¤œå‡ºçµ±åˆç‰ˆï¼‰
ç‚¹ç¾¤â†’ãƒ¡ãƒƒã‚·ãƒ¥â†’è¡çªæ¤œå‡ºâ†’éŸ³éŸ¿åˆæˆã®å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè£…

ä½¿ç”¨æ–¹æ³•:
  python3 demo_collision_detection.py                 # é€šå¸¸å®Ÿè¡Œ
  python3 demo_collision_detection.py --no-audio      # éŸ³éŸ¿ç„¡åŠ¹åŒ–
  python3 demo_collision_detection.py --test          # ãƒ—ãƒªãƒ—ãƒ­ã‚»ãƒƒã‚·ãƒ³ã‚°æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
"""

import os
import sys
import time
import argparse
import logging
from typing import Optional, List, Dict, Tuple, Any
from dataclasses import dataclass
from pathlib import Path
import signal
import numpy as np
import cv2

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# OrbbecSDKã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
HAS_ORBBEC_SDK = False
try:
    from pyorbbecsdk import Pipeline, FrameSet, Config, OBSensorType, OBError, OBFormat
    HAS_ORBBEC_SDK = True
    print("OrbbecSDK is available")
except ImportError:
    print("Warning: OrbbecSDK is not available. Using mock implementations.")
    # Mock classes
    class Pipeline:
        def __init__(self): pass
        def start(self, config): pass
        def stop(self): pass
        def wait_for_frames(self, timeout): return None
    
    class FrameSet:
        def get_depth_frame(self): return None
        def get_color_frame(self): return None
    
    class Config:
        def enable_stream(self, stream, width, height, fmt, fps): pass
    
    class OBSensorType:
        DEPTH = "depth"
        COLOR = "color"
    
    class OBError(Exception):
        pass
    
    class OBFormat:
        RGB = "rgb"
        BGR = "bgr"
        MJPG = "mjpg"

# MediaPipeã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
HAS_MEDIAPIPE = False
try:
    import mediapipe as mp
    HAS_MEDIAPIPE = True
    print("MediaPipe is available")
except ImportError:
    print("Warning: MediaPipe is not available. Hand detection will be disabled.")
    # Mock MediaPipe
    class MockMediaPipe:
        class solutions:
            class hands:
                Hands = lambda **kwargs: None
            class drawing_utils:
                @staticmethod
                def draw_landmarks(*args): pass
            class hands_connections:
                HAND_CONNECTIONS = []

# NumPy/SciPy/Open3D
try:
    import open3d as o3d
    HAS_OPEN3D = True
except ImportError:
    print("Warning: Open3D is not available. 3D visualization will be disabled.")
    HAS_OPEN3D = False

# éŸ³éŸ¿ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
HAS_AUDIO = False
try:
    import pyo
    HAS_AUDIO = True
    print("Pyo audio engine is available")
except ImportError:
    print("Warning: Pyo audio engine is not available. Audio synthesis will be disabled.")

# å¿…è¦ãªã‚¯ãƒ©ã‚¹ã®import
from typing import Optional, List
from src.detection.tracker import TrackedHand
from src.sound.mapping import ScaleType, InstrumentType
from src.mesh.projection import PointCloudProjector, ProjectionMethod
from src.mesh.delaunay import DelaunayTriangulator
from src.mesh.simplify import MeshSimplifier
from src.mesh.index import SpatialIndex, IndexType
from src.collision.search import CollisionSearcher
from src.collision.sphere_tri import SphereTriangleCollision
from src.collision.events import CollisionEventQueue
from src.sound.mapping import AudioMapper
from src.detection.hands2d import MediaPipeHandsWrapper
from src.input.stream import OrbbecCamera
from src.detection.hands3d import Hand3DProjector
from src.detection.tracker import Hand3DTracker
from src.sound.synth import AudioSynthesizer, AudioConfig, EngineState, create_audio_synthesizer
from src.sound.voice_mgr import VoiceManager, StealStrategy, SpatialMode, SpatialConfig, create_voice_manager, allocate_and_play

# ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
from src.debug.dual_viewer import DualViewer
from src.input.depth_filter import DepthFilter, FilterType
from src.input.pointcloud import PointCloudConverter
from src.config import get_config, InputConfig

# GPUåŠ é€Ÿã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆCuPyåˆ©ç”¨å¯èƒ½æ™‚ã®ã¿ï¼‰
try:
    from src.collision.distance_gpu import GPUDistanceCalculator, create_gpu_distance_calculator
    from src.mesh.delaunay_gpu import GPUDelaunayTriangulator, create_gpu_triangulator
    HAS_GPU_ACCELERATION = True
    print("ğŸš€ GPU acceleration modules loaded (CuPy available)")
except ImportError:
    HAS_GPU_ACCELERATION = False
    print("âš ï¸ GPU acceleration unavailable (CuPy not installed)")


class FullPipelineViewer(DualViewer):
    """å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆæ‹¡å¼µDualViewerï¼ˆæ‰‹æ¤œå‡º+ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ+è¡çªæ¤œå‡º+éŸ³éŸ¿ç”Ÿæˆï¼‰"""
    
    def __init__(self, **kwargs):
        # éŸ³éŸ¿é–¢é€£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.enable_audio_synthesis = kwargs.pop('enable_audio_synthesis', True)
        self.audio_scale = kwargs.pop('audio_scale', ScaleType.PENTATONIC)
        self.audio_instrument = kwargs.pop('audio_instrument', InstrumentType.MARIMBA)
        self.audio_polyphony = kwargs.pop('audio_polyphony', 16)
        self.audio_master_volume = kwargs.pop('audio_master_volume', 0.7)
        
        # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰è¨­å®š
        self.headless_mode = kwargs.pop('headless_mode', False)
        self.headless_duration = kwargs.pop('headless_duration', 30)
        self.pure_headless_mode = kwargs.pop('pure_headless_mode', False)
        
        # è¡çªæ¤œå‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.enable_mesh_generation = kwargs.pop('enable_mesh_generation', True)
        self.enable_collision_detection = kwargs.pop('enable_collision_detection', True)
        self.enable_collision_visualization = kwargs.pop('enable_collision_visualization', True)
        self.sphere_radius = kwargs.pop('sphere_radius', 0.05)  # 5cm
        
        # ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”åˆ¶å¾¡
        self.mesh_update_interval = kwargs.pop('mesh_update_interval', 10)  # 10ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨
        self.max_mesh_skip_frames = kwargs.pop('max_mesh_skip_frames', 60)  # æœ€å¤§60ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—
        
        # ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆè¦ªã‚¯ãƒ©ã‚¹ã«æ¸¡ã•ãªã„ï¼‰
        self.voxel_downsampling_enabled = kwargs.pop('enable_voxel_downsampling', True)
        self.voxel_size = kwargs.pop('voxel_size', 0.005)  # 5mm ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        # è¦ªã‚¯ãƒ©ã‚¹åˆæœŸåŒ–
        super().__init__(**kwargs)
        
        # åœ°å½¢ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.projector = PointCloudProjector(
            resolution=0.01,  # 1cmè§£åƒåº¦
            method=ProjectionMethod.MEDIAN_HEIGHT,
            fill_holes=True
        )
        
        self.triangulator = DelaunayTriangulator(
            adaptive_sampling=True,
            boundary_points=True,
            quality_threshold=0.3,
            use_gpu=True
        )
        
        self.simplifier = MeshSimplifier(
            target_reduction=0.7,  # 70%å‰Šæ¸›ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ã«è»½é‡åŒ–
            preserve_boundary=True
        )
        
        # è¡çªæ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.spatial_index: Optional[SpatialIndex] = None
        self.collision_searcher: Optional[CollisionSearcher] = None
        self.collision_tester: Optional[SphereTriangleCollision] = None
        self.event_queue = CollisionEventQueue()
        
        # éŸ³éŸ¿ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.audio_mapper: Optional[AudioMapper] = None
        self.audio_synthesizer: Optional[AudioSynthesizer] = None
        self.voice_manager: Optional[VoiceManager] = None
        self.audio_enabled = False  # éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³ã®çŠ¶æ…‹
        
        # éŸ³éŸ¿ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ç®¡ç†ï¼ˆã€Œå©ã„ãŸç¬é–“ã€ã®ã¿éŸ³ã‚’é³´ã‚‰ã™ï¼‰
        self.audio_cooldown_time = 0.15  # 150msé–“éš”ã§ã®éŸ³ç™ºç”Ÿåˆ¶é™
        self.last_audio_trigger_time = {}  # hand_idåˆ¥ã®æœ€å¾Œã®ãƒˆãƒªã‚¬ãƒ¼æ™‚é–“
        
        # çŠ¶æ…‹ç®¡ç†
        self.current_mesh = None
        self.current_collision_points = []
        self.current_tracked_hands = []  # ç›´è¿‘ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°çµæœ
        self.frame_counter = 0
        self.last_mesh_update = -999  # åˆå›ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚’ç¢ºå®Ÿã«ã™ã‚‹ãŸã‚è² ã®å€¤ã§åˆæœŸåŒ–
        self.force_mesh_update_requested = False  # ãƒ¡ãƒƒã‚·ãƒ¥å¼·åˆ¶æ›´æ–°ãƒ•ãƒ©ã‚°
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        self.perf_stats = {
            'frame_count': 0,
            'mesh_generation_time': 0.0,
            'collision_detection_time': 0.0,
            'audio_synthesis_time': 0.0,
            'collision_events_count': 0,
            'audio_notes_played': 0,
            'total_pipeline_time': 0.0
        }
        
        # ãƒ¡ãƒƒã‚·ãƒ¥ã¨ã‚³ãƒªã‚¸ãƒ§ãƒ³ã®å¯è¦–åŒ–ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        self.mesh_geometries = []
        self.collision_geometries = []
        
        # éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        if self.enable_audio_synthesis:
            self._initialize_audio_system()
        
        print("å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
        print(f"  - ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ: {'æœ‰åŠ¹' if self.enable_mesh_generation else 'ç„¡åŠ¹'}")
        print(f"  - è¡çªæ¤œå‡º: {'æœ‰åŠ¹' if self.enable_collision_detection else 'ç„¡åŠ¹'}")
        print(f"  - æ¥è§¦ç‚¹å¯è¦–åŒ–: {'æœ‰åŠ¹' if self.enable_collision_visualization else 'ç„¡åŠ¹'}")
        print(f"  - çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
        print(f"  - éŸ³éŸ¿åˆæˆ: {'æœ‰åŠ¹' if self.enable_audio_synthesis else 'ç„¡åŠ¹'}")
        if self.enable_audio_synthesis:
            print(f"    - éŸ³éš: {self.audio_scale.value}")
            print(f"    - æ¥½å™¨: {self.audio_instrument.value}")
            print(f"    - ãƒãƒªãƒ•ã‚©ãƒ‹ãƒ¼: {self.audio_polyphony}")
            print(f"    - éŸ³é‡: {self.audio_master_volume:.1f}")
            print(f"    - ã‚¨ãƒ³ã‚¸ãƒ³çŠ¶æ…‹: {'å‹•ä½œä¸­' if self.audio_enabled else 'åœæ­¢ä¸­'}")
        
        # ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–ã¯è¦ªã‚¯ãƒ©ã‚¹ã§è¡Œã‚ã‚Œã‚‹ãŸã‚å‰Šé™¤
        self.enable_hand_detection = True
        self.enable_hand_tracking = True  # æ‰‹ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
        self.enable_tracking = True
        self.min_detection_confidence = 0.2  # æ¤œå‡ºæ„Ÿåº¦ã‚’ä¸Šã’ã¦ãƒ†ã‚¹ãƒˆ
        self.hands_2d = MediaPipeHandsWrapper(
            min_detection_confidence=self.min_detection_confidence,
            min_tracking_confidence=0.5,
            max_num_hands=2,
            # ROI ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°è¨­å®šï¼ˆåŠ¹ç‡åŒ–ï¼‰
            enable_roi_tracking=True,
            tracker_type="KCF",           # KCFãƒˆãƒ©ãƒƒã‚«ãƒ¼ã§é«˜é€ŸåŒ–
            skip_interval=4,              # 4ãƒ•ãƒ¬ãƒ¼ãƒ ã«1å›MediaPipeå®Ÿè¡Œ
            roi_confidence_threshold=0.6,
            max_tracking_age=15
        )
        # projector_3dã¨trackerã®åˆæœŸåŒ–ã¯è¦ªã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–å¾Œã«è¡Œã†
        self.projector_3d = None
        self.tracker = None
        
        # åˆæœŸåŒ–å®Œäº†ãƒ•ãƒ©ã‚°
        self._components_initialized = False
    
    def _initialize_audio_system(self):
        """éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–"""
        try:
            print("éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­...")
            
            # éŸ³éŸ¿ãƒãƒƒãƒ‘ãƒ¼åˆæœŸåŒ–
            self.audio_mapper = AudioMapper(
                scale=self.audio_scale,
                default_instrument=self.audio_instrument,
                pitch_range=(48, 84),  # C3-C6
                enable_adaptive_mapping=True
            )
            
            # éŸ³éŸ¿ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
            self.audio_synthesizer = create_audio_synthesizer(
                sample_rate=44100,
                buffer_size=256,
                max_polyphony=self.audio_polyphony
            )
            
            # éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³é–‹å§‹
            if self.audio_synthesizer.start_engine():
                # ãƒœã‚¤ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
                self.voice_manager = create_voice_manager(
                    self.audio_synthesizer,
                    max_polyphony=self.audio_polyphony,
                    steal_strategy=StealStrategy.OLDEST
                )
                
                # ãƒã‚¹ã‚¿ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ è¨­å®š
                self.audio_synthesizer.update_master_volume(self.audio_master_volume)
                
                self.audio_enabled = True
                print("éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            else:
                print("éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ")
                self.audio_enabled = False
        
        except Exception as e:
            print(f"éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.audio_enabled = False
    
    def _shutdown_audio_system(self):
        """éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ï¼ˆå®‰å…¨ç‰ˆï¼‰"""
        try:
            print("[AUDIO-SHUTDOWN] éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ä¸­...")
            self.audio_enabled = False  # æœ€åˆã«ç„¡åŠ¹åŒ–ã—ã¦æ–°ã—ã„éŸ³ç”Ÿæˆã‚’é˜²ã
            
            # ãƒœã‚¤ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åœæ­¢
            if self.voice_manager:
                try:
                    self.voice_manager.stop_all_voices(fade_out_time=0.01)  # çŸ­æ™‚é–“ãƒ•ã‚§ãƒ¼ãƒ‰
                    time.sleep(0.05)  # å°‘ã—å¾…æ©Ÿã—ã¦ãƒœã‚¤ã‚¹åœæ­¢ã‚’ç¢ºå®Ÿã«ã™ã‚‹
                    self.voice_manager = None
                except Exception as e:
                    print(f"[AUDIO-SHUTDOWN] VoiceManageråœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ãƒ¼ã‚¨ãƒ³ã‚¸ãƒ³ã®åœæ­¢
            if self.audio_synthesizer:
                try:
                    self.audio_synthesizer.stop_engine()
                    time.sleep(0.05)  # å°‘ã—å¾…æ©Ÿã—ã¦ã‚¨ãƒ³ã‚¸ãƒ³åœæ­¢ã‚’ç¢ºå®Ÿã«ã™ã‚‹
                    self.audio_synthesizer = None
                except Exception as e:
                    print(f"[AUDIO-SHUTDOWN] Synthesizeråœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            
            # éŸ³éŸ¿ãƒãƒƒãƒ‘ãƒ¼ã‚‚ã‚¯ãƒªã‚¢
            self.audio_mapper = None
            
            print("[AUDIO-SHUTDOWN] éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã—ã¾ã—ãŸ")
        
        except Exception as e:
            print(f"[AUDIO-SHUTDOWN] éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ åœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼ã§ã‚‚çŠ¶æ…‹ã‚’ç„¡åŠ¹ã«ã™ã‚‹
            self.audio_enabled = False
    
    def run(self):
        """ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚’å®Ÿè¡Œ"""
        if self.headless_mode:
            self.run_headless()
        else:
            # è¦ªã‚¯ãƒ©ã‚¹ã®run()ã‚’å‘¼ã³å‡ºã—
            super().run()

    def _process_frame(self) -> bool:
        """
        1ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆè¡çªæ¤œå‡ºç‰ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼‰
        DualViewerã®ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã—ã¦è¡çªæ¤œå‡ºã‚’çµ±åˆ
        """
        frame_start_time = time.perf_counter()
        
        # 3Dæ‰‹æ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®é…å»¶åˆæœŸåŒ–
        if not self._components_initialized and hasattr(self, 'camera') and self.camera is not None:
            try:
                print("Setting up 3D hand detection components...")
                # ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–ç¢ºèª
                if self.camera.depth_intrinsics is not None:
                    # ä¿¡é ¼åº¦é–¾å€¤ã‚’ä¸‹ã’ã¦ãƒ†ã‚¹ãƒˆ
                    self.projector_3d = Hand3DProjector(
                        self.camera.depth_intrinsics,
                        min_confidence_3d=0.1  # 10%ã«ä¸‹ã’ã¦ãƒ†ã‚¹ãƒˆ
                    )
                    self.tracker = Hand3DTracker()
                    self._components_initialized = True
                    print("3D hand detection components initialized with lowered confidence threshold")
                else:
                    print("Camera depth intrinsics not available")
            except Exception as e:
                print(f"3D component initialization error: {e}")
        
        # ã‚«ãƒ¡ãƒ©ãŒãªã„å ´åˆã¯çµ‚äº†
        if self.camera is None:
            print("Camera not available")
            return False
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—
        frame_data = self.camera.get_frame(timeout_ms=100)
        if frame_data is None or frame_data.depth_frame is None:
            return True
        
        # æ·±åº¦ç”»åƒã®æŠ½å‡º
        depth_data = np.frombuffer(frame_data.depth_frame.get_data(), dtype=np.uint16)
        # ã‚«ãƒ¡ãƒ©ã®å†…éƒ¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
        if self.camera.depth_intrinsics is not None:
            depth_image = depth_data.reshape(
                (self.camera.depth_intrinsics.height, self.camera.depth_intrinsics.width)
            )
        else:
            print("Depth intrinsics not available")
            return True
        
        # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
        filter_start_time = time.perf_counter()
        if self.depth_filter is not None and self.enable_filter:
            depth_image = self.depth_filter.apply_filter(depth_image)
        self.performance_stats['filter_time'] = (time.perf_counter() - filter_start_time) * 1000
        
        # ç‚¹ç¾¤ç”Ÿæˆï¼ˆå¿…è¦æ™‚ï¼‰
        points_3d = None
        need_points_for_mesh = (self.enable_mesh_generation and 
                                self.frame_count - self.last_mesh_update >= self.mesh_update_interval)
        
        if self.pointcloud_converter and (self.frame_count % self.update_interval == 0 or need_points_for_mesh):
            pointcloud_start = time.perf_counter()
            # depth_imageã¯æ—¢ã«numpyé…åˆ—ãªã®ã§ã€numpy_to_pointcloudã‚’ä½¿ç”¨
            points_3d, _ = self.pointcloud_converter.numpy_to_pointcloud(depth_image)
            self.performance_stats['pointcloud_time'] = (time.perf_counter() - pointcloud_start) * 1000
            if need_points_for_mesh:
                print(f"[MESH-PREP] Frame {self.frame_count}: Generated points for mesh update: {len(points_3d) if points_3d is not None else 'None'}")
        
        # æ‰‹æ¤œå‡ºå‡¦ç†ï¼ˆä¸€å…ƒåŒ–ï¼šã“ã“ã§1å›ã®ã¿å®Ÿè¡Œï¼‰
        hands_2d, hands_3d, tracked_hands = [], [], []
        
        # å®Ÿéš›ã«æ‰‹æ¤œå‡ºã‚’å®Ÿè¡Œï¼ˆDualViewerã‹ã‚‰ç¶™æ‰¿ã—ãŸãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼‰
        if self.enable_hand_detection and self.hands_2d is not None:
            hand_start_time = time.perf_counter()
            hands_2d, hands_3d, tracked_hands = self._process_hand_detection(depth_image)
            self.performance_stats['hand_detection_time'] = (time.perf_counter() - hand_start_time) * 1000
            print(f"[HAND-OPTIMIZED] Frame {self.frame_count}: Hand detection completed in {self.performance_stats['hand_detection_time']:.1f}ms - 2D:{len(hands_2d)}, 3D:{len(hands_3d)}, Tracked:{len(tracked_hands)}")
        else:
            self.performance_stats['hand_detection_time'] = 0.0
        
        # æ‰‹æ¤œå‡ºçµæœã‚’ã‚¯ãƒ©ã‚¹å¤‰æ•°ã«ä¿å­˜ï¼ˆRGBè¡¨ç¤ºã§ä½¿ã„å›ã™ãŸã‚ï¼‰
        self.current_hands_2d = hands_2d
        self.current_hands_3d = hands_3d
        self.current_tracked_hands = tracked_hands
        
        # æ‰‹ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã®ã¿è©³ç´°ãƒ­ã‚°ã‚’å‡ºåŠ›
        if len(hands_2d) > 0 or len(hands_3d) > 0 or len(tracked_hands) > 0:
            print(f"[HANDS] Frame {self.frame_count}: *** HANDS DETECTED *** 2D:{len(hands_2d)} 3D:{len(hands_3d)} Tracked:{len(tracked_hands)}")
        
        # è¡çªæ¤œå‡ºã¨ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        pipeline_start = time.perf_counter()
        self.frame_counter = self.frame_count  # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’åŒæœŸ
        
        # æ‰‹ãŒå­˜åœ¨ã™ã‚‹ã‹åˆ¤å®š
        hands_present = (len(hands_2d) > 0 or len(hands_3d) > 0 or len(tracked_hands) > 0)
        frame_diff = self.frame_count - self.last_mesh_update

        # åœ°å½¢ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆï¼ˆæ¡ä»¶åˆ¤å®šï¼‰
        mesh_condition_check = (
            self.enable_mesh_generation and (
                # å¼·åˆ¶æ›´æ–°è¦æ±‚ãŒã‚ã‚‹å ´åˆã¯å³æ›´æ–°
                self.force_mesh_update_requested or
                # æ‰‹ãŒå†™ã£ã¦ã„ãªã„ & é€šå¸¸é–“éš”ã‚’è¶…ãˆãŸ
                (not hands_present and frame_diff >= self.mesh_update_interval) or
                # æœ€å¤§ã‚¹ã‚­ãƒƒãƒ—æ™‚é–“ã‚’è¶…ãˆãŸ
                (frame_diff >= self.max_mesh_skip_frames) or
                # ã¾ã ãƒ¡ãƒƒã‚·ãƒ¥ãŒç„¡ã„
                (self.current_mesh is None)
            ) and
            points_3d is not None and len(points_3d) > 100
        )
        
        # ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆæ¡ä»¶ã®è¨ºæ–­ãƒ­ã‚°
        if self.frame_count % 10 == 0:  # 10ãƒ•ãƒ¬ãƒ¼ãƒ æ¯ã«è¨ºæ–­ãƒ­ã‚°
            print(f"[MESH-DIAG] Frame {self.frame_count}: enable_mesh={self.enable_mesh_generation}, "
                  f"frame_diff={frame_diff}, "
                  f"interval={self.mesh_update_interval}, "
                  f"max_skip={self.max_mesh_skip_frames}, "
                  f"points={len(points_3d) if points_3d is not None else 'None'}, "
                  f"condition={mesh_condition_check}")
        
        if mesh_condition_check:
            mesh_start = time.perf_counter()
            points_len = len(points_3d) if points_3d is not None else 0
            print(f"[MESH] Frame {self.frame_count}: *** UPDATING TERRAIN MESH *** with {points_len} points")
            self._update_terrain_mesh(points_3d)
            self.last_mesh_update = self.frame_count
            # å¼·åˆ¶æ›´æ–°ãƒ•ãƒ©ã‚°ã‚’ã‚¯ãƒªã‚¢
            self.force_mesh_update_requested = False
            self.perf_stats['mesh_generation_time'] = (time.perf_counter() - mesh_start) * 1000
            print(f"[MESH] Frame {self.frame_count}: Mesh update completed in {self.perf_stats['mesh_generation_time']:.1f}ms")
        
        # è¡çªæ¤œå‡º
        collision_events = []
        if (self.enable_collision_detection and self.current_mesh is not None and tracked_hands):
            print(f"[COLLISION] Frame {self.frame_count}: *** CHECKING COLLISIONS *** with {len(tracked_hands)} hands and mesh available")
            collision_start = time.perf_counter()
            collision_events = self._detect_collisions(tracked_hands)
            self.perf_stats['collision_detection_time'] = (time.perf_counter() - collision_start) * 1000
            self.perf_stats['collision_events_count'] += len(collision_events)
            if len(collision_events) > 0:
                print(f"[COLLISION] Frame {self.frame_count}: *** COLLISION DETECTED! *** {len(collision_events)} events")
            else:
                print(f"[COLLISION] Frame {self.frame_count}: No collisions detected")
        
        # éŸ³éŸ¿ç”Ÿæˆ
        if (self.enable_audio_synthesis and self.audio_enabled and collision_events):
            audio_start = time.perf_counter()
            print(f"[AUDIO] Frame {self.frame_count}: *** GENERATING AUDIO *** for {len(collision_events)} collision events")
            audio_notes = self._generate_audio(collision_events)
            self.perf_stats['audio_notes_played'] += audio_notes
            self.perf_stats['audio_synthesis_time'] = (time.perf_counter() - audio_start) * 1000
            print(f"[AUDIO] Frame {self.frame_count}: Generated {audio_notes} audio notes in {self.perf_stats['audio_synthesis_time']:.1f}ms")
        
        self.perf_stats['total_pipeline_time'] = (time.perf_counter() - pipeline_start) * 1000
        
        # è¡çªã‚¤ãƒ™ãƒ³ãƒˆã‚’ã‚¯ãƒ©ã‚¹å¤‰æ•°ã«ä¿å­˜ï¼ˆRGBè¡¨ç¤ºã§ä½¿ç”¨ï¼‰
        self.current_collision_events = collision_events
        
        # RGBè¡¨ç¤ºå‡¦ç†ï¼ˆæ—¢å­˜ã®DualViewerãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨ï¼‰
        if not self._process_rgb_display(frame_data):
            return False
        
        # ç‚¹ç¾¤è¡¨ç¤ºå‡¦ç†ï¼ˆé–“éš”åˆ¶å¾¡ï¼‰
        if self.frame_count % self.update_interval == 0:
            if not self._process_pointcloud_display(frame_data):
                return False
        
        self.frame_count += 1
        self.performance_stats['frame_time'] = (time.perf_counter() - frame_start_time) * 1000
        
        return True

    def _update_terrain_mesh(self, points_3d):
        """åœ°å½¢ãƒ¡ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°"""
        if points_3d is None or len(points_3d) < 100:
            return
        
        try:
            import time
            
            # 1. ç‚¹ç¾¤æŠ•å½±
            projection_start = time.perf_counter()
            height_map = self.projector.project_points(points_3d)
            projection_time = (time.perf_counter() - projection_start) * 1000
            
            # 2. Delaunayä¸‰è§’åˆ†å‰²
            triangulation_start = time.perf_counter()
            triangle_mesh = self.triangulator.triangulate_heightmap(height_map)
            triangulation_time = (time.perf_counter() - triangulation_start) * 1000
            
            if triangle_mesh is None or triangle_mesh.num_triangles == 0:
                return
            
            # 3. ãƒ¡ãƒƒã‚·ãƒ¥ç°¡ç•¥åŒ–
            simplification_start = time.perf_counter()
            simplified_mesh = self.simplifier.simplify_mesh(triangle_mesh)
            simplification_time = (time.perf_counter() - simplification_start) * 1000
            
            if simplified_mesh is None:
                simplified_mesh = triangle_mesh
            
            # 4. ç©ºé–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
            self.spatial_index = SpatialIndex(simplified_mesh, index_type=IndexType.BVH)
            
            # 5. è¡çªæ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
            self.collision_searcher = CollisionSearcher(self.spatial_index)
            self.collision_tester = SphereTriangleCollision(simplified_mesh)
            
            # ãƒ¡ãƒƒã‚·ãƒ¥ä¿å­˜
            self.current_mesh = simplified_mesh
            
            # ãƒ‡ãƒãƒƒã‚°ç”¨æ™‚é–“æ¸¬å®šå‡ºåŠ›
            if hasattr(self, 'frame_counter') and self.frame_counter % 50 == 0:
                total_mesh_time = projection_time + triangulation_time + simplification_time
                print(f"[MESH] Projection: {projection_time:.1f}ms, Triangulation: {triangulation_time:.1f}ms, Simplification: {simplification_time:.1f}ms (Total: {total_mesh_time:.1f}ms)")
            
            print(f"ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°å®Œäº†: {simplified_mesh.num_triangles}ä¸‰è§’å½¢")
            
        except Exception as e:
            print(f"ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
    
    def _detect_collisions(self, tracked_hands: List[TrackedHand]) -> list:
        if not self.collision_searcher: 
            print(f"[DEBUG] _detect_collisions: No collision searcher available")
            return []
        events = []
        self.current_collision_points = []
        print(f"[DEBUG] _detect_collisions: Processing {len(tracked_hands)} hands")
        
        for i, hand in enumerate(tracked_hands):
            if hand.position is None: 
                print(f"[DEBUG] _detect_collisions: Hand {i} has no position")
                continue
            hand_pos_np = np.array(hand.position)
            print(f"[DEBUG] _detect_collisions: Hand {i} position: ({hand_pos_np[0]:.3f}, {hand_pos_np[1]:.3f}, {hand_pos_np[2]:.3f})")
            
            try:
                res = self.collision_searcher.search_near_hand(hand, override_radius=self.sphere_radius)
                print(f"[DEBUG] _detect_collisions: Hand {i} found {len(res.triangle_indices)} nearby triangles")
                
                if not res.triangle_indices: continue
                
                # å¾“æ¥ã®CPUè¡çªæ¤œå‡º
                if self.collision_tester is not None:
                    info = self.collision_tester.test_sphere_collision(hand_pos_np, self.sphere_radius, res)
                else:
                    continue
                
                print(f"[DEBUG] _detect_collisions: Hand {i} collision test result: {info.has_collision}")
                
                if info.has_collision:
                    velocity = np.array(hand.velocity) if hasattr(hand, 'velocity') and hand.velocity is not None else np.zeros(3)
                    event = self.event_queue.create_event(info, hand.id, hand_pos_np, velocity)
                    if event:
                        events.append(event)
                        for cp in info.contact_points:
                           self.current_collision_points.append(cp.position)
                        print(f"[DEBUG] _detect_collisions: Hand {i} generated collision event with {len(info.contact_points)} contact points")
            except Exception as e:
                logger.error(f"[DEBUG] _detect_collisions: Error processing hand {i}: {e}")
        
        print(f"[DEBUG] _detect_collisions: Total collision events: {len(events)}")
        return events
    
    def _generate_audio(self, collision_events):
        """è¡çªã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰éŸ³éŸ¿ã‚’ç”Ÿæˆï¼ˆã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æ©Ÿæ§‹ä»˜ãï¼‰"""
        if not self.audio_enabled or not self.audio_mapper or not self.voice_manager:
            return 0
        
        notes_played = 0
        current_time = time.perf_counter()
        
        for event in collision_events:
            try:
                # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒã‚§ãƒƒã‚¯ï¼ˆæ‰‹IDåˆ¥ï¼‰
                hand_id = event.hand_id
                last_trigger = self.last_audio_trigger_time.get(hand_id, 0)
                time_since_last = current_time - last_trigger
                
                if time_since_last < self.audio_cooldown_time:
                    print(f"[AUDIO-COOLDOWN] Hand {hand_id}: {time_since_last*1000:.1f}ms since last trigger, skipping")
                    continue
                
                # è¡çªã‚¤ãƒ™ãƒ³ãƒˆã‚’éŸ³éŸ¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ãƒãƒƒãƒ”ãƒ³ã‚°
                audio_params = self.audio_mapper.map_collision_event(event)
                
                # ç©ºé–“ä½ç½®è¨­å®šï¼ˆnumpy.float64 â†’ Python floatå¤‰æ›ï¼‰
                spatial_position = np.array([
                    float(event.contact_position[0]),
                    0.0,
                    float(event.contact_position[2])
                ], dtype=float)
                
                # éŸ³éŸ¿å†ç”Ÿ
                voice_id = allocate_and_play(
                    self.voice_manager,
                    audio_params,
                    priority=7,
                    spatial_position=spatial_position
                )
                
                if voice_id:
                    notes_played += 1
                    # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒãƒ¼æ›´æ–°
                    self.last_audio_trigger_time[hand_id] = current_time
                    print(f"[AUDIO-TRIGGER] Hand {hand_id}: Note triggered (cooldown reset)")
            
            except Exception as e:
                print(f"éŸ³éŸ¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆ: {event.event_id}ï¼‰: {e}")
        
        # çµ‚äº†ã—ãŸãƒœã‚¤ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ é–“éš”ã‚’ç©ºã‘ã¦è² è·è»½æ¸›ï¼‰
        if self.voice_manager and self.frame_count % 10 == 0:  # 10ãƒ•ãƒ¬ãƒ¼ãƒ ã«1å›ã®ã¿
            try:
                self.voice_manager.cleanup_finished_voices()
            except Exception as e:
                print(f"[AUDIO-CLEANUP] Error during cleanup: {e}")
        
        return notes_played

    def run_headless(self):
        """ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œï¼ˆGUIç„¡åŠ¹åŒ–ã§FPSæ¸¬å®šç‰¹åŒ–ï¼‰"""
        import time
        
        print("\\nğŸ–¥ï¸  ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰é–‹å§‹ - GUIç„¡åŠ¹åŒ–ã«ã‚ˆã‚‹FPSæœ€é©åŒ–")
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {self.headless_duration}ç§’")
        print("=" * 50)
        
        start_time = time.time()
        frame_count = 0
        total_pipeline_time = 0.0
        
        # FPSã®çµ±è¨ˆ
        fps_samples = []
        frame_times = []
        last_report_time = start_time
        
        try:
            while True:
                frame_start = time.time()
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆGUIç„¡ã—ï¼‰
                success = self._process_frame_headless()
                
                frame_end = time.time()
                frame_time = frame_end - frame_start
                frame_times.append(frame_time)
                
                if success:
                    frame_count += 1
                    total_pipeline_time += frame_time
                    
                    # FPSè¨ˆç®—
                    current_fps = 1.0 / frame_time if frame_time > 0 else 0
                    fps_samples.append(current_fps)
                    
                    # 5ç§’é–“éš”ã§çµ±è¨ˆè¡¨ç¤º
                    elapsed = frame_end - start_time
                    if elapsed - (last_report_time - start_time) >= 5.0:
                        avg_fps = sum(fps_samples[-100:]) / len(fps_samples[-100:]) if fps_samples else 0
                        print(f"ğŸ“Š [{elapsed:.1f}s] ãƒ•ãƒ¬ãƒ¼ãƒ : {frame_count}, å¹³å‡FPS: {avg_fps:.1f}, ç¾åœ¨FPS: {current_fps:.1f}")
                        last_report_time = frame_end
                
                # å®Ÿè¡Œæ™‚é–“ãƒã‚§ãƒƒã‚¯
                if time.time() - start_time >= self.headless_duration:
                    break
                    
        except KeyboardInterrupt:
            print("\\nâ¹ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ä¸­æ–­")
        except Exception as e:
            print(f"\\nâŒ ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
        
        # çµ±è¨ˆè¨ˆç®—ã¨è¡¨ç¤º
        execution_time = time.time() - start_time
        avg_fps = frame_count / execution_time if execution_time > 0 else 0
        avg_frame_time = total_pipeline_time / frame_count if frame_count > 0 else 0
        max_fps = max(fps_samples) if fps_samples else 0
        min_fps = min(fps_samples) if fps_samples else 0
        
        # çµæœè¡¨ç¤º
        print("\\n" + "=" * 50)
        print("ğŸ ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ å®Ÿè¡Œçµæœ")
        print("=" * 50)
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {execution_time:.1f}ç§’")
        print(f"ğŸ¬ ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frame_count}")
        print(f"ğŸš€ å¹³å‡FPS: {avg_fps:.1f}")
        print(f"âš¡ å¹³å‡ãƒ•ãƒ¬ãƒ¼ãƒ æ™‚é–“: {avg_frame_time*1000:.1f}ms")
        print(f"ğŸ“ˆ æœ€å¤§FPS: {max_fps:.1f}")
        print(f"ğŸ“‰ æœ€å°FPS: {min_fps:.1f}")
        print(f"âš™ï¸  å¹³å‡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ™‚é–“: {total_pipeline_time/frame_count*1000:.1f}ms" if frame_count > 0 else "âš™ï¸  ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ™‚é–“: N/A")
        print(f"ğŸµ è¡çªã‚¤ãƒ™ãƒ³ãƒˆç·æ•°: {self.perf_stats.get('collision_events_count', 0)}")
        print(f"ğŸ”Š éŸ³éŸ¿ãƒãƒ¼ãƒˆç·æ•°: {getattr(self, 'audio_notes_played', 0)}")
        print()

    def _process_frame_headless(self) -> bool:
        """ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹å°‚ç”¨ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆGUIæç”»ãªã—ï¼‰"""
        # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ç”¨ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        if not self.camera:
            # ãƒ¢ãƒƒã‚¯æ·±åº¦ãƒ»ã‚«ãƒ©ãƒ¼ç”»åƒç”Ÿæˆ
            import numpy as np
            depth_image = np.random.randint(500, 2000, (240, 424), dtype=np.uint16)
            color_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            frame_data = (depth_image, color_image)
            
        else:
            # å®Ÿã‚«ãƒ¡ãƒ©ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—
            try:
                frame_data = self.camera.get_frame()
                if frame_data is None:
                    return False
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰depth_imageã¨color_imageã‚’æŠ½å‡º
                if hasattr(frame_data, 'depth_frame') and hasattr(frame_data, 'color_frame'):
                    depth_frame = frame_data.depth_frame
                    color_frame = frame_data.color_frame
                    
                    depth_data = np.frombuffer(depth_frame.get_data(), dtype=np.uint16)
                    depth_image = depth_data.reshape((depth_frame.get_height(), depth_frame.get_width()))
                    
                    if color_frame is not None:
                        color_data = np.frombuffer(color_frame.get_data(), dtype=np.uint8)
                        color_image = color_data.reshape((color_frame.get_height(), color_frame.get_width(), 3))
                    else:
                        color_image = None
                else:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¿ãƒ—ãƒ«ã¨ã—ã¦æ‰±ã†
                    depth_image, color_image = frame_data, None
                    
                if depth_image is None:
                    return False
                    
            except Exception as e:
                print(f"âŒ ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                return False
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        if hasattr(frame_data, 'depth_frame') and hasattr(frame_data, 'color_frame'):
            depth_frame = frame_data.depth_frame
            color_frame = frame_data.color_frame
            
            if depth_frame is not None:
                depth_data = np.frombuffer(depth_frame.get_data(), dtype=np.uint16)
                depth_image = depth_data.reshape((depth_frame.get_height(), depth_frame.get_width()))
            else:
                depth_image = None
                
            if color_frame is not None:
                color_data = np.frombuffer(color_frame.get_data(), dtype=np.uint8)
                color_image = color_data.reshape((color_frame.get_height(), color_frame.get_width(), 3))
            else:
                color_image = None
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¿ãƒ—ãƒ«ã¨ã—ã¦æ‰±ã†
            depth_image, color_image = frame_data
        
        if depth_image is None:
            return False
            
        self.frame_counter += 1
        collision_events = []
        
        try:
            # æ‰‹æ¤œå‡ºå‡¦ç†ï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ã§ã¯ç°¡æ˜“ç‰ˆï¼‰
            if self.enable_hand_detection and hasattr(self, 'hands_2d') and self.hands_2d and not getattr(self, 'pure_headless_mode', False):
                try:
                    # MediaPipe 2Dæ¤œå‡ºï¼ˆæ­£ã—ã„ãƒ¡ã‚½ãƒƒãƒ‰åã‚’ä½¿ç”¨ï¼‰
                    self.current_hands_2d = self.hands_2d.detect_hands(color_image) if color_image is not None else []
                except Exception as e:
                    # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ã§ã¯æ‰‹æ¤œå‡ºã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
                    self.current_hands_2d = []
                
                # 3DæŠ•å½±ã¯ç„¡åŠ¹åŒ–ï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ï¼‰
                self.current_tracked_hands = []
            else:
                # ç´”ç²‹ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã¾ãŸã¯æ‰‹æ¤œå‡ºç„¡åŠ¹
                self.current_hands_2d = []
                self.current_tracked_hands = []
            
            # ç‚¹ç¾¤ç”Ÿæˆï¼ˆãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ï¼‰
            points_3d = None
            if self.enable_mesh_generation:
                # ãƒ¢ãƒƒã‚¯ç‚¹ç¾¤ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
                import numpy as np
                mock_points = np.random.rand(5000, 3).astype(np.float32)  # 5000ç‚¹ã®ãƒ¢ãƒƒã‚¯ç‚¹ç¾¤
                mock_points[:, 2] += 0.5  # Zåº§æ¨™ã‚’ã‚«ãƒ¡ãƒ©ã‹ã‚‰é›¢ã™
                points_3d = mock_points
                
            # ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°åˆ¤å®šã¨ç”Ÿæˆ
            if self.enable_mesh_generation and points_3d is not None:
                should_update = self._should_update_mesh()
                if should_update:
                    import time
                    mesh_start_time = time.time()
                    self._update_terrain_mesh(points_3d)
                    mesh_time = time.time() - mesh_start_time
                    self.perf_stats['mesh_generation_time'] += mesh_time
                    self.last_mesh_update = self.frame_counter
            
            # è¡çªæ¤œå‡ºï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ã§ã¯ç°¡æ˜“ç‰ˆï¼‰
            if self.enable_collision_detection and self.current_tracked_hands and hasattr(self, 'current_mesh') and self.current_mesh:
                try:
                    import time
                    collision_start_time = time.time()
                    collision_events = self._detect_collisions(self.current_tracked_hands)
                    collision_time = time.time() - collision_start_time
                    self.perf_stats['collision_detection_time'] += collision_time
                    self.perf_stats['collision_events_count'] += len(collision_events)
                except Exception:
                    # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ã§ã¯è¡çªæ¤œå‡ºã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
                    collision_events = []
            
            # éŸ³éŸ¿ç”Ÿæˆï¼ˆéŸ³ã¯å‡ºåŠ›ã•ã‚Œã‚‹ï¼‰
            if self.enable_audio_synthesis and collision_events:
                try:
                    import time
                    audio_start_time = time.time()
                    self._generate_audio(collision_events)
                    audio_time = time.time() - audio_start_time
                    self.perf_stats['audio_synthesis_time'] += audio_time
                except Exception:
                    # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ã§ã¯éŸ³éŸ¿ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
                    pass
            
            self.perf_stats['frame_count'] += 1
            
            # å‡¦ç†æ™‚é–“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒ¢ãƒƒã‚¯ã®å ´åˆï¼‰
            if not self.camera:
                # å®Ÿéš›ã®å‡¦ç†æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                import time as time_module
                processing_delay = 0.015  # 15ms å‡¦ç†æ™‚é–“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                time_module.sleep(processing_delay)
            
            return True
            
        except Exception as e:
            # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ã§ã¯ã‚¨ãƒ©ãƒ¼ã§ã‚‚ç¶™ç¶š
            if self.frame_counter <= 3:
                print(f"âš ï¸  ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†è­¦å‘Š: {e}")
            return True  # ã‚¨ãƒ©ãƒ¼ã§ã‚‚ç¶™ç¶š
    
    def _should_update_mesh(self) -> bool:
        """ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°åˆ¤å®š"""
        frames_since_update = self.frame_counter - self.last_mesh_update
        
        # å¼·åˆ¶æ›´æ–°è¦æ±‚
        if hasattr(self, 'force_mesh_update_requested') and self.force_mesh_update_requested:
            self.force_mesh_update_requested = False
            return True
            
        # æ‰‹ãŒæ¤œå‡ºã•ã‚Œã¦ã„ãªã„å ´åˆã¯é€šå¸¸é–“éš”ã§æ›´æ–°
        if not self.current_tracked_hands:
            return frames_since_update >= self.mesh_update_interval
        
        # æ‰‹ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã‚‹å ´åˆã¯æ›´æ–°é–“éš”ã‚’é•·ãã™ã‚‹
        # ãŸã ã—ã€æœ€å¤§ã‚¹ã‚­ãƒƒãƒ—ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’è¶…ãˆãŸã‚‰å¼·åˆ¶æ›´æ–°
        return frames_since_update >= getattr(self, 'max_mesh_skip_frames', 60)

    def __del__(self):
        """ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ - éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’é©åˆ‡ã«åœæ­¢"""
        try:
            if hasattr(self, 'audio_enabled') and self.audio_enabled:
                print("[DESTRUCTOR] éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
                self._shutdown_audio_system()
        except Exception as e:
            print(f"[DESTRUCTOR] ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã§ã‚¨ãƒ©ãƒ¼: {e}")
            
    def cleanup(self):
        """æ˜ç¤ºçš„ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ¡ã‚½ãƒƒãƒ‰"""
        try:
            if self.audio_enabled:
                self._shutdown_audio_system()
        except Exception as e:
            print(f"[CLEANUP] ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="Geocussion-SP å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆãƒ‡ãƒ¢ï¼ˆComplete Pipelineï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
    python demo_collision_detection.py                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼ˆä½è§£åƒåº¦424x240ï¼‰
    python demo_collision_detection.py --force-high-resolution # é«˜è§£åƒåº¦848x480ï¼ˆä½FPSæ³¨æ„ï¼‰
    python demo_collision_detection.py --depth-width 640 --depth-height 360 # ã‚«ã‚¹ã‚¿ãƒ è§£åƒåº¦
    python demo_collision_detection.py --no-collision     # è¡çªæ¤œå‡ºç„¡åŠ¹
    python demo_collision_detection.py --no-mesh          # ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆç„¡åŠ¹
    python demo_collision_detection.py --no-audio         # éŸ³éŸ¿åˆæˆç„¡åŠ¹
    python demo_collision_detection.py --sphere-radius 0.08 # çƒåŠå¾„8cm
    python demo_collision_detection.py --audio-instrument BELL # ãƒ™ãƒ«æ¥½å™¨

æ“ä½œæ–¹æ³•:
    RGB Window:
        Q/ESC: çµ‚äº†
        F: æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿ ON/OFF
        H: æ‰‹æ¤œå‡º ON/OFF
        T: ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚° ON/OFF
        
        M: ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ ON/OFF
        C: è¡çªæ¤œå‡º ON/OFF
        V: è¡çªå¯è¦–åŒ– ON/OFF
        N: ãƒ¡ãƒƒã‚·ãƒ¥å¼·åˆ¶æ›´æ–°
        +/-: çƒåŠå¾„èª¿æ•´
        P: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆè¡¨ç¤º
        
        A: éŸ³éŸ¿åˆæˆ ON/OFF
        S: éŸ³éšåˆ‡ã‚Šæ›¿ãˆ
        I: æ¥½å™¨åˆ‡ã‚Šæ›¿ãˆ
        1/2: éŸ³é‡èª¿æ•´
        R: éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³å†èµ·å‹•
        Q: å…¨éŸ³å£°åœæ­¢
    
    3D Viewer:
        ãƒã‚¦ã‚¹: å›è»¢/ãƒ‘ãƒ³/ã‚ºãƒ¼ãƒ 
        R: è¦–ç‚¹ãƒªã‚»ãƒƒãƒˆ
        """
    )
    
    # åŸºæœ¬è¨­å®š
    parser.add_argument('--no-filter', action='store_true', help='æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿ã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--no-hand-detection', action='store_true', help='æ‰‹æ¤œå‡ºã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--no-tracking', action='store_true', help='ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--gpu-mediapipe', action='store_true', help='MediaPipeã§GPUã‚’ä½¿ç”¨')
    
    # è¡çªæ¤œå‡ºè¨­å®š
    parser.add_argument('--no-mesh', action='store_true', help='ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--no-collision', action='store_true', help='è¡çªæ¤œå‡ºã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--no-collision-viz', action='store_true', help='è¡çªå¯è¦–åŒ–ã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--mesh-interval', type=int, default=15, help='ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼‰ â€»ä½è§£åƒåº¦æ™‚ã¯15frameæ¨å¥¨')
    parser.add_argument('--sphere-radius', type=float, default=0.05, help='è¡çªæ¤œå‡ºçƒã®åŠå¾„ï¼ˆãƒ¡ãƒ¼ãƒˆãƒ«ï¼‰')
    parser.add_argument('--max-mesh-skip', type=int, default=60, help='æ‰‹ãŒå†™ã£ã¦ã„ã‚‹å ´åˆã§ã‚‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°çµŒéã§å¼·åˆ¶æ›´æ–°')
    
    # éŸ³éŸ¿ç”Ÿæˆè¨­å®š
    parser.add_argument('--no-audio', action='store_true', help='éŸ³éŸ¿åˆæˆã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--audio-scale', type=str, default='PENTATONIC', 
                       choices=['PENTATONIC', 'MAJOR', 'MINOR', 'DORIAN', 'MIXOLYDIAN', 'CHROMATIC', 'BLUES'],
                       help='éŸ³éšã®ç¨®é¡')
    parser.add_argument('--audio-instrument', type=str, default='MARIMBA',
                       choices=['MARIMBA', 'SYNTH_PAD', 'BELL', 'PLUCK', 'BASS', 'LEAD', 'PERCUSSION', 'AMBIENT'],
                       help='æ¥½å™¨ã®ç¨®é¡')
    parser.add_argument('--audio-polyphony', type=int, default=16, help='æœ€å¤§åŒæ™‚ç™ºéŸ³æ•°')
    parser.add_argument('--audio-volume', type=float, default=0.7, help='ãƒã‚¹ã‚¿ãƒ¼éŸ³é‡ (0.0-1.0)')
    
    # æ‰‹æ¤œå‡ºè¨­å®š
    parser.add_argument('--min-confidence', type=float, default=0.7, help='æœ€å°æ¤œå‡ºä¿¡é ¼åº¦ (0.0-1.0)')
    
    # è¡¨ç¤ºè¨­å®š
    parser.add_argument('--update-interval', type=int, default=3, help='ç‚¹ç¾¤æ›´æ–°é–“éš”ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼‰')
    parser.add_argument('--point-size', type=float, default=2.0, help='ç‚¹ç¾¤ã®ç‚¹ã‚µã‚¤ã‚º')
    parser.add_argument('--high-resolution', action='store_true', help='é«˜è§£åƒåº¦è¡¨ç¤º (1280x720)')
    
    # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ï¼ˆFPSå‘ä¸Šã®ãŸã‚ã®GUIç„¡åŠ¹åŒ–ï¼‰
    parser.add_argument('--headless', action='store_true', help='ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ï¼ˆGUIç„¡åŠ¹ï¼‰â€»FPSå¤§å¹…å‘ä¸Š')
    parser.add_argument('--headless-duration', type=int, default=30, help='ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰')
    parser.add_argument('--headless-pure', action='store_true', help='ç´”ç²‹ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ï¼ˆæ‰‹æ¤œå‡ºç„¡åŠ¹ã€æœ€å¤§FPSæ¸¬å®šï¼‰')
    
    # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
    parser.add_argument('--window-width', type=int, default=640, help='RGBã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®å¹…')
    parser.add_argument('--window-height', type=int, default=480, help='RGBã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®é«˜ã•')
    
    args = parser.parse_args()
    
    # è¨­å®šå€¤æ¤œè¨¼
    if args.min_confidence < 0.0 or args.min_confidence > 1.0:
        print("Error: --min-confidence must be between 0.0 and 1.0")
        return 1
    
    if args.sphere_radius <= 0.0 or args.sphere_radius > 0.5:
        print("Error: --sphere-radius must be between 0.0 and 0.5")
        return 1
    
    if args.audio_polyphony < 1 or args.audio_polyphony > 64:
        print("Error: --audio-polyphony must be between 1 and 64")
        return 1
    
    if args.audio_volume < 0.0 or args.audio_volume > 1.0:
        print("Error: --audio-volume must be between 0.0 and 1.0")
        return 1
    
    # éŸ³éšã¨æ¥½å™¨ã®åˆ—æŒ™å€¤å¤‰æ›
    try:
        audio_scale = ScaleType[args.audio_scale]
        audio_instrument = InstrumentType[args.audio_instrument]
    except KeyError as e:
        print(f"Error: Invalid audio parameter: {e}")
        return 1
    
    # æƒ…å ±è¡¨ç¤º
    print("=" * 70)
    print("Geocussion-SP å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆãƒ‡ãƒ¢ï¼ˆComplete Pipelineï¼‰")
    print("=" * 70)
    
    print(f"æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿: {'ç„¡åŠ¹' if args.no_filter else 'æœ‰åŠ¹'}")
    print(f"æ‰‹æ¤œå‡º: {'ç„¡åŠ¹' if args.no_hand_detection else 'æœ‰åŠ¹'}")
    print(f"ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ: {'ç„¡åŠ¹' if args.no_mesh else 'æœ‰åŠ¹'}")
    print(f"è¡çªæ¤œå‡º: {'ç„¡åŠ¹' if args.no_collision else 'æœ‰åŠ¹'}")
    if not args.no_collision:
        print(f"  - çƒåŠå¾„: {args.sphere_radius*100:.1f}cm")
        print(f"  - å¯è¦–åŒ–: {'ç„¡åŠ¹' if args.no_collision_viz else 'ç„¡åŠ¹'}")
    print(f"éŸ³éŸ¿åˆæˆ: {'ç„¡åŠ¹' if args.no_audio else 'æœ‰åŠ¹'}")
    if not args.no_audio:
        print(f"  - éŸ³éš: {audio_scale.value}")
        print(f"  - æ¥½å™¨: {audio_instrument.value}")
        print(f"  - ãƒãƒªãƒ•ã‚©ãƒ‹ãƒ¼: {args.audio_polyphony}")
        print(f"  - éŸ³é‡: {args.audio_volume:.1f}")
    
    # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰æƒ…å ±è¡¨ç¤º
    if args.headless:
        print(f"ğŸ–¥ï¸  ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰: æœ‰åŠ¹ï¼ˆGUIç„¡åŠ¹åŒ–ã§FPSå‘ä¸Šï¼‰")
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {args.headless_duration}ç§’")
        print(f"ğŸš€ äºˆæƒ³FPSå‘ä¸Š: +5-15 FPS (GUIè² è·å‰Šé™¤)")
    else:
        print(f"ğŸ–¥ï¸  è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰: GUIæœ‰åŠ¹")
    
    print("=" * 70)
    
    # FullPipelineViewerå®Ÿè¡Œ
    try:
        viewer = FullPipelineViewer(
            enable_filter=not args.no_filter,
            enable_hand_detection=not args.no_hand_detection,
            enable_tracking=not args.no_tracking,
            enable_mesh_generation=not args.no_mesh,
            enable_collision_detection=not args.no_collision,
            enable_collision_visualization=not args.no_collision_viz,
            enable_audio_synthesis=not args.no_audio,
            update_interval=args.update_interval,
            point_size=args.point_size,
            rgb_window_size=(args.window_width, args.window_height),
            min_detection_confidence=args.min_confidence,
            use_gpu_mediapipe=args.gpu_mediapipe,
            mesh_update_interval=args.mesh_interval,
            sphere_radius=args.sphere_radius,
            audio_scale=audio_scale,
            audio_instrument=audio_instrument,
            audio_polyphony=args.audio_polyphony,
            audio_master_volume=args.audio_volume,
            max_mesh_skip_frames=args.max_mesh_skip,
            headless_mode=args.headless,
            headless_duration=args.headless_duration,
            pure_headless_mode=args.headless_pure
        )
        
        print("\nå…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚’é–‹å§‹ã—ã¾ã™...")
        print("=" * 70)
        
        # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰æ™‚ã¯ç›´æ¥å®Ÿè¡Œ
        if args.headless:
            print("ğŸ–¥ï¸  ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰: ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            print("ğŸ¯ ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹FPSæ¸¬å®šã‚’é–‹å§‹ã—ã¾ã™...")
            viewer.run()
            print("\nãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ãŒæ­£å¸¸ã«çµ‚äº†ã—ã¾ã—ãŸ")
            return 0
        
        print("ã‚«ãƒ¡ãƒ©ã‚’åˆæœŸåŒ–ä¸­...")
        viewer.camera = OrbbecCamera(enable_color=True)
        
        # DualViewerã®åˆæœŸåŒ–ã‚’å®Ÿè¡Œ
        if not viewer.initialize():
            print("Failed to initialize dual viewer")
            return 1
        
        viewer.run()
        
        print("\nãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ãŒæ­£å¸¸ã«çµ‚äº†ã—ã¾ã—ãŸ")
        return 0
        
    except KeyboardInterrupt:
        print("\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        return 0
    except Exception as e:
        print(f"\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)