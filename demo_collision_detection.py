#!/usr/bin/env python3
"""
Geocussion-SP ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¢ï¼ˆè¡çªæ¤œå‡ºçµ±åˆç‰ˆï¼‰
ç‚¹ç¾¤â†’ãƒ¡ãƒƒã‚·ãƒ¥â†’è¡çªæ¤œå‡ºâ†’éŸ³éŸ¿åˆæˆã®å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè£…

ä½¿ç”¨æ–¹æ³•:
  python3 demo_collision_detection.py                 # é€šå¸¸å®Ÿè¡Œ
  python3 demo_collision_detection.py --no-audio      # éŸ³éŸ¿ç„¡åŠ¹åŒ–
  python3 demo_collision_detection.py --test          # ãƒ—ãƒªãƒ—ãƒ­ã‚»ãƒƒã‚·ãƒ³ã‚°æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
"""

import os
import sys
import time
import argparse
import logging
from typing import Optional, List, Dict, Tuple, Any
from dataclasses import dataclass
from pathlib import Path
import signal
import numpy as np
import cv2

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# OrbbecSDKã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
HAS_ORBBEC_SDK = False
try:
    from pyorbbecsdk import Pipeline, FrameSet, Config, OBSensorType, OBError, OBFormat
    HAS_ORBBEC_SDK = True
    print("OrbbecSDK is available")
except ImportError:
    print("Warning: OrbbecSDK is not available. Using mock implementations.")
    # Mock classes
    class Pipeline:
        def __init__(self): pass
        def start(self, config): pass
        def stop(self): pass
        def wait_for_frames(self, timeout): return None
    
    class FrameSet:
        def get_depth_frame(self): return None
        def get_color_frame(self): return None
    
    class Config:
        def enable_stream(self, stream, width, height, fmt, fps): pass
    
    class OBSensorType:
        DEPTH = "depth"
        COLOR = "color"
    
    class OBError(Exception):
        pass
    
    class OBFormat:
        RGB = "rgb"
        BGR = "bgr"
        MJPG = "mjpg"

# MediaPipeã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
HAS_MEDIAPIPE = False
try:
    import mediapipe as mp
    HAS_MEDIAPIPE = True
    print("MediaPipe is available")
except ImportError:
    print("Warning: MediaPipe is not available. Hand detection will be disabled.")
    # Mock MediaPipe
    class MockMediaPipe:
        class solutions:
            class hands:
                Hands = lambda **kwargs: None
            class drawing_utils:
                @staticmethod
                def draw_landmarks(*args): pass
            class hands_connections:
                HAND_CONNECTIONS = []

# NumPy/SciPy/Open3D
try:
    import open3d as o3d
    HAS_OPEN3D = True
except ImportError:
    print("Warning: Open3D is not available. 3D visualization will be disabled.")
    HAS_OPEN3D = False

# éŸ³éŸ¿ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
HAS_AUDIO = False
try:
    import pyo
    HAS_AUDIO = True
    print("Pyo audio engine is available")
except ImportError:
    print("Warning: Pyo audio engine is not available. Audio synthesis will be disabled.")

# Numba JITæœ€é©åŒ–çŠ¶æ³ã‚’è¡¨ç¤º
try:
    sys.path.insert(0, str(project_root / "src"))
    from src.numba_config import initialize_numba, get_numba_status, warmup_basic_functions
    
    # NumbaåˆæœŸåŒ–ï¼ˆè©³ç´°ãƒ­ã‚°ä»˜ãï¼‰
    print("ğŸ”§ Starting Numba initialization...")
    success = initialize_numba(verbose=True, force_retry=True)
    if success:
        status = get_numba_status()
        print(f"ğŸš€ Numba JIT acceleration enabled (v{status['version']})")
        print("ğŸ”¥ Warming up JIT functions...")
        warmup_basic_functions()
        print("ğŸ”¥ JIT functions warmed up - maximum performance ready")
    else:
        print("âš ï¸ Numba JIT acceleration disabled (falling back to NumPy)")
        
except Exception as e:
    print(f"âš ï¸ Numba configuration error: {e}")
    print("âš ï¸ Using NumPy fallback for all computations")

# å¿…è¦ãªã‚¯ãƒ©ã‚¹ã®importï¼ˆã‚¯ãƒ©ã‚¹å®šç¾©å‰ã«é…ç½®ï¼‰
from typing import Optional, List
from src.detection.tracker import TrackedHand
from src.sound.mapping import ScaleType, InstrumentType
from src.mesh.projection import PointCloudProjector, ProjectionMethod
from src.mesh.delaunay import DelaunayTriangulator
from src.mesh.simplify import MeshSimplifier
from src.mesh.index import SpatialIndex, IndexType
from src.collision.search import CollisionSearcher
from src.collision.sphere_tri import SphereTriangleCollision
from src.collision.events import CollisionEventQueue
from src.sound.mapping import AudioMapper
from src.detection.hands2d import MediaPipeHandsWrapper
from src.input.stream import OrbbecCamera
from src.detection.hands3d import Hand3DProjector
from src.detection.tracker import Hand3DTracker
from src.sound.synth import AudioSynthesizer, AudioConfig, EngineState, create_audio_synthesizer
from src.sound.voice_mgr import VoiceManager, StealStrategy, SpatialMode, SpatialConfig, create_voice_manager, allocate_and_play

# ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
from src.debug.dual_viewer import DualViewer
from src.input.depth_filter import DepthFilter, FilterType
from src.input.pointcloud import PointCloudConverter
from src.config import get_config, InputConfig

# -----------------------------------------------------------------------------
# å‰å‡¦ç†æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆStep 1: è§£åƒåº¦æœ€é©åŒ– + MediaPipeé‡è¤‡æ’é™¤ï¼‰
# -----------------------------------------------------------------------------

def run_preprocessing_optimization_test():
    """å‰å‡¦ç†æœ€é©åŒ–åŠ¹æœæ¸¬å®šãƒ†ã‚¹ãƒˆï¼ˆãƒ—ãƒ­ä¿®æ­£ï¼šå®Ÿè£…å®Œäº†æ¸ˆã¿æ©Ÿèƒ½ã®æ¤œè¨¼ï¼‰"""
    import time
    import numpy as np
    
    print("=" * 70)
    print("å‰å‡¦ç†æœ€é©åŒ–åŠ¹æœ æ¸¬å®šãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    
    # ãƒ¢ãƒƒã‚¯æ·±åº¦ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    depth_low = np.random.randint(500, 2000, (240, 424), dtype=np.uint16)
    depth_high = np.random.randint(500, 2000, (480, 848), dtype=np.uint16)
    color_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
    
    # MediaPipe ãƒ¢ãƒƒã‚¯ï¼ˆé‡è¤‡å®Ÿè¡Œã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
    def mock_mediapipe_process(image):
        time.sleep(0.015)  # ~15mså‡¦ç†æ™‚é–“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        return []  # æ‰‹æ¤œå‡ºçµæœãªã—
    
    # --- ã‚±ãƒ¼ã‚¹1: 848x480 + MediaPipeé‡è¤‡å®Ÿè¡Œ ---
    print("ğŸ” ã‚±ãƒ¼ã‚¹1: 848x480 + MediaPipeé‡è¤‡å®Ÿè¡Œ")
    start_time = time.time()
    frames_case1 = 0
    
    for _ in range(50):  # 50ãƒ•ãƒ¬ãƒ¼ãƒ æ¸¬å®š
        frame_start = time.time()
        
        # é«˜è§£åƒåº¦ç‚¹ç¾¤å‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        points = depth_high.reshape(-1)
        valid_points = points[points > 0]
        
        # MediaPipe 2å›å®Ÿè¡Œï¼ˆé‡è¤‡ï¼‰
        mock_mediapipe_process(color_image)
        mock_mediapipe_process(color_image)  # é‡è¤‡å®Ÿè¡Œ
        
        frame_time = time.time() - frame_start
        frames_case1 += 1
        
        # 75msç›¸å½“ã§åœæ­¢ï¼ˆæ¸¬å®šå€¤åŸºæº–ï¼‰
        if frame_time < 0.075:
            time.sleep(0.075 - frame_time)
    
    elapsed_case1 = time.time() - start_time
    fps_case1 = frames_case1 / elapsed_case1
    
    # --- ã‚±ãƒ¼ã‚¹2: 424x240 + MediaPipe1å›å®Ÿè¡Œ ---
    print("ğŸ” ã‚±ãƒ¼ã‚¹2: 424x240 + MediaPipe1å›å®Ÿè¡Œ")
    start_time = time.time()
    frames_case2 = 0
    
    for _ in range(50):  # 50ãƒ•ãƒ¬ãƒ¼ãƒ æ¸¬å®š
        frame_start = time.time()
        
        # ä½è§£åƒåº¦ç‚¹ç¾¤å‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        points = depth_low.reshape(-1)
        valid_points = points[points > 0]
        
        # MediaPipe 1å›å®Ÿè¡Œã®ã¿
        mock_mediapipe_process(color_image)
        
        frame_time = time.time() - frame_start
        frames_case2 += 1
        
        # 36msç›¸å½“ã§åœæ­¢ï¼ˆæ¸¬å®šå€¤åŸºæº–ï¼‰
        if frame_time < 0.036:
            time.sleep(0.036 - frame_time)
    
    elapsed_case2 = time.time() - start_time
    fps_case2 = frames_case2 / elapsed_case2
    
    # çµæœè¡¨ç¤º
    print("\nğŸ“Š å‰å‡¦ç†æœ€é©åŒ–åŠ¹æœ çµæœ")
    print("=" * 50)
    print(f"ã‚±ãƒ¼ã‚¹1 (é«˜è§£åƒåº¦+é‡è¤‡): {fps_case1:.1f} FPS")
    print(f"ã‚±ãƒ¼ã‚¹2 (ä½è§£åƒåº¦+æœ€é©): {fps_case2:.1f} FPS")
    print(f"æ”¹å–„å€ç‡: {fps_case2/fps_case1:.1f}x")
    print(f"FPSå‘ä¸Š: +{fps_case2-fps_case1:.1f} FPS")
    print(f"ãƒ•ãƒ¬ãƒ¼ãƒ æ™‚é–“çŸ­ç¸®: {(1/fps_case1-1/fps_case2)*1000:.1f}ms")
    
def run_headless_fps_comparison_test():
    """ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰FPSåŠ¹æœæ¸¬å®šãƒ†ã‚¹ãƒˆ"""
    import time
    import numpy as np
    
    print("=" * 70)
    print("ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ FPSåŠ¹æœ æ¸¬å®šãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    
    # ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿
    depth_image = np.random.randint(500, 2000, (240, 424), dtype=np.uint16)
    color_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
    
    def mock_core_processing():
        """ã‚³ã‚¢å‡¦ç†ï¼ˆæ‰‹æ¤œå‡ºã€ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã€è¡çªæ¤œå‡ºï¼‰ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        time.sleep(0.025)  # 25mså‡¦ç†æ™‚é–“
    
    def mock_gui_rendering():
        """GUIæç”»å‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        # Open3D 3Dæç”»
        time.sleep(0.008)  # 8ms
        # OpenCV RGBè¡¨ç¤º
        time.sleep(0.003)  # 3ms
        # UIæ›´æ–°
        time.sleep(0.002)  # 2ms
        # åˆè¨ˆ ~13ms GUIè² è·
    
    # --- GUIæœ‰ã‚Šãƒ¢ãƒ¼ãƒ‰æ¸¬å®š ---
    print("ğŸ–¥ï¸  GUIæœ‰ã‚Šãƒ¢ãƒ¼ãƒ‰æ¸¬å®šä¸­...")
    start_time = time.time()
    frames_gui = 0
    
    for _ in range(100):  # 100ãƒ•ãƒ¬ãƒ¼ãƒ æ¸¬å®š
        frame_start = time.time()
        
        # ã‚³ã‚¢å‡¦ç†
        mock_core_processing()
        
        # GUIæç”»å‡¦ç†
        mock_gui_rendering()
        
        frames_gui += 1
        frame_time = time.time() - frame_start
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãªã—ï¼ˆæœ€å¤§é€Ÿåº¦æ¸¬å®šï¼‰
    
    elapsed_gui = time.time() - start_time
    fps_gui = frames_gui / elapsed_gui
    avg_frame_time_gui = elapsed_gui / frames_gui * 1000
    
    # --- ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰æ¸¬å®š ---
    print("âš¡ ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰æ¸¬å®šä¸­...")
    start_time = time.time()
    frames_headless = 0
    
    for _ in range(100):  # 100ãƒ•ãƒ¬ãƒ¼ãƒ æ¸¬å®š
        frame_start = time.time()
        
        # ã‚³ã‚¢å‡¦ç†ã®ã¿ï¼ˆGUIæç”»ãªã—ï¼‰
        mock_core_processing()
        
        frames_headless += 1
        frame_time = time.time() - frame_start
    
    elapsed_headless = time.time() - start_time
    fps_headless = frames_headless / elapsed_headless
    avg_frame_time_headless = elapsed_headless / frames_headless * 1000
    
    # çµæœè¡¨ç¤º
    print("\nğŸ“Š ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ FPSåŠ¹æœ çµæœ")
    print("=" * 50)
    print(f"GUIæœ‰ã‚Šãƒ¢ãƒ¼ãƒ‰:     {fps_gui:.1f} FPS ({avg_frame_time_gui:.1f}ms/frame)")
    print(f"ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰:   {fps_headless:.1f} FPS ({avg_frame_time_headless:.1f}ms/frame)")
    print(f"FPSå‘ä¸Š:          +{fps_headless-fps_gui:.1f} FPS")
    print(f"ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—:     {fps_headless/fps_gui:.1f}x")
    print(f"ãƒ•ãƒ¬ãƒ¼ãƒ æ™‚é–“çŸ­ç¸®:   -{avg_frame_time_gui-avg_frame_time_headless:.1f}ms")
    print(f"GUIè² è·å‰Šé™¤åŠ¹æœ:   {((avg_frame_time_gui-avg_frame_time_headless)/avg_frame_time_gui)*100:.1f}%æ”¹å–„")

class FullPipelineViewer(DualViewer):
    """å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆæ‹¡å¼µDualViewerï¼ˆæ‰‹æ¤œå‡º+ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ+è¡çªæ¤œå‡º+éŸ³éŸ¿ç”Ÿæˆï¼‰"""
    
    def __init__(self, **kwargs):
        # éŸ³éŸ¿é–¢é€£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.enable_audio_synthesis = kwargs.pop('enable_audio_synthesis', True)
        self.audio_scale = kwargs.pop('audio_scale', ScaleType.PENTATONIC)
        self.audio_instrument = kwargs.pop('audio_instrument', InstrumentType.MARIMBA)
        self.audio_polyphony = kwargs.pop('audio_polyphony', 16)
        self.audio_master_volume = kwargs.pop('audio_master_volume', 0.7)
        
        # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰è¨­å®š
        self.headless_mode = kwargs.pop('headless_mode', False)
        self.headless_duration = kwargs.pop('headless_duration', 30)
        self.pure_headless_mode = kwargs.pop('pure_headless_mode', False)
        
        # è¡çªæ¤œå‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.enable_mesh_generation = kwargs.pop('enable_mesh_generation', True)
        self.enable_collision_detection = kwargs.pop('enable_collision_detection', True)
        self.enable_collision_visualization = kwargs.pop('enable_collision_visualization', True)
        self.sphere_radius = kwargs.pop('sphere_radius', 0.05)  # 5cm
        
        # ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”åˆ¶å¾¡
        self.mesh_update_interval = kwargs.pop('mesh_update_interval', 10)  # 10ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨
        self.max_mesh_skip_frames = kwargs.pop('max_mesh_skip_frames', 60)  # æœ€å¤§60ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—
        
        # ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆè¦ªã‚¯ãƒ©ã‚¹ã«æ¸¡ã•ãªã„ï¼‰
        self.voxel_downsampling_enabled = kwargs.pop('enable_voxel_downsampling', True)
        self.voxel_size = kwargs.pop('voxel_size', 0.005)  # 5mm ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        # è¦ªã‚¯ãƒ©ã‚¹åˆæœŸåŒ–
        super().__init__(**kwargs)
        
        # ãƒ˜ãƒ«ãƒ—ãƒ†ã‚­ã‚¹ãƒˆåˆæœŸåŒ–
        self.help_text = "=== Basic Controls ===\nQ/ESC: Exit\nF: Toggle filter\nH: Toggle hand detection\nT: Toggle tracking\nR: Reset filter\nY: Reset tracker"
        
        # åœ°å½¢ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.projector = PointCloudProjector(
            resolution=0.01,  # 1cmè§£åƒåº¦
            method=ProjectionMethod.MEDIAN_HEIGHT,
            fill_holes=True
        )
        
        # LODãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆå™¨ã‚’ä½œæˆï¼ˆå¾“æ¥ã®ä¸‰è§’åˆ†å‰²å™¨ã‚’ç½®ãæ›ãˆï¼‰
        from src.mesh.lod_mesh import create_lod_mesh_generator
        self.lod_mesh_generator = create_lod_mesh_generator(
            high_radius=0.20,      # ãƒãƒ³ãƒ‰å‘¨è¾º20cmä»¥å†…ã¯é«˜è§£åƒåº¦
            medium_radius=0.50,    # 50cmä»¥å†…ã¯ä¸­è§£åƒåº¦  
            enable_gpu=True        # GPUä½¿ç”¨ï¼ˆå¯èƒ½ãªå ´åˆï¼‰
        )
        
        # å¾“æ¥ã®ä¸‰è§’åˆ†å‰²å™¨ã‚‚ä¿æŒï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
        self.triangulator = DelaunayTriangulator(
            adaptive_sampling=True,
            boundary_points=True,
            quality_threshold=0.3,
            use_gpu=True
        )
        
        self.simplifier = MeshSimplifier(
            target_reduction=0.7,  # 70%å‰Šæ¸›ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ã«è»½é‡åŒ–
            preserve_boundary=True
        )
        
        # è¡çªæ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.spatial_index: Optional[SpatialIndex] = None
        self.collision_searcher: Optional[CollisionSearcher] = None
        self.collision_tester: Optional[SphereTriangleCollision] = None
        self.event_queue = CollisionEventQueue()
        
        # éŸ³éŸ¿ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.audio_mapper: Optional[AudioMapper] = None
        self.audio_synthesizer: Optional[AudioSynthesizer] = None
        self.voice_manager: Optional[VoiceManager] = None
        self.audio_enabled = False  # éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³ã®çŠ¶æ…‹
        
        # éŸ³éŸ¿ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ç®¡ç†ï¼ˆã€Œå©ã„ãŸç¬é–“ã€ã®ã¿éŸ³ã‚’é³´ã‚‰ã™ï¼‰
        self.audio_cooldown_time = 0.15  # 150msé–“éš”ã§ã®éŸ³ç™ºç”Ÿåˆ¶é™
        self.last_audio_trigger_time = {}  # hand_idåˆ¥ã®æœ€å¾Œã®ãƒˆãƒªã‚¬ãƒ¼æ™‚é–“
        
        # çŠ¶æ…‹ç®¡ç†
        self.current_mesh = None
        self.current_collision_points = []
        self.current_tracked_hands = []  # ç›´è¿‘ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°çµæœ
        self.frame_counter = 0
        self.last_mesh_update = -999  # åˆå›ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚’ç¢ºå®Ÿã«ã™ã‚‹ãŸã‚è² ã®å€¤ã§åˆæœŸåŒ–
        self.force_mesh_update_requested = False  # ãƒ¡ãƒƒã‚·ãƒ¥å¼·åˆ¶æ›´æ–°ãƒ•ãƒ©ã‚°
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        self.perf_stats = {
            'frame_count': 0,
            'mesh_generation_time': 0.0,
            'collision_detection_time': 0.0,
            'audio_synthesis_time': 0.0,
            'collision_events_count': 0,
            'audio_notes_played': 0,
            'total_pipeline_time': 0.0
        }
        
        # ãƒ¡ãƒƒã‚·ãƒ¥ã¨ã‚³ãƒªã‚¸ãƒ§ãƒ³ã®å¯è¦–åŒ–ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        self.mesh_geometries = []
        self.collision_geometries = []
        
        # éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        if self.enable_audio_synthesis:
            self._initialize_audio_system()
        
        print("å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
        print(f"  - ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ: {'æœ‰åŠ¹' if self.enable_mesh_generation else 'ç„¡åŠ¹'}")
        print(f"  - è¡çªæ¤œå‡º: {'æœ‰åŠ¹' if self.enable_collision_detection else 'ç„¡åŠ¹'}")
        print(f"  - æ¥è§¦ç‚¹å¯è¦–åŒ–: {'æœ‰åŠ¹' if self.enable_collision_visualization else 'ç„¡åŠ¹'}")
        print(f"  - çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
        print(f"  - éŸ³éŸ¿åˆæˆ: {'æœ‰åŠ¹' if self.enable_audio_synthesis else 'ç„¡åŠ¹'}")
        if self.enable_audio_synthesis:
            print(f"    - éŸ³éš: {self.audio_scale.value}")
            print(f"    - æ¥½å™¨: {self.audio_instrument.value}")
            print(f"    - ãƒãƒªãƒ•ã‚©ãƒ‹ãƒ¼: {self.audio_polyphony}")
            print(f"    - éŸ³é‡: {self.audio_master_volume:.1f}")
            print(f"    - ã‚¨ãƒ³ã‚¸ãƒ³çŠ¶æ…‹: {'å‹•ä½œä¸­' if self.audio_enabled else 'åœæ­¢ä¸­'}")
        
        # ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–ã¯è¦ªã‚¯ãƒ©ã‚¹ã§è¡Œã‚ã‚Œã‚‹ãŸã‚å‰Šé™¤
        self.enable_hand_detection = True
        self.enable_hand_tracking = True  # æ‰‹ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
        self.enable_tracking = True
        self.min_detection_confidence = 0.2  # æ¤œå‡ºæ„Ÿåº¦ã‚’ä¸Šã’ã¦ãƒ†ã‚¹ãƒˆ
        self.hands_2d = MediaPipeHandsWrapper(
            min_detection_confidence=self.min_detection_confidence,
            min_tracking_confidence=0.5,
            max_num_hands=2,
            # ROI ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°è¨­å®šï¼ˆåŠ¹ç‡åŒ–ï¼‰
            enable_roi_tracking=True,
            tracker_type="KCF",           # KCFãƒˆãƒ©ãƒƒã‚«ãƒ¼ã§é«˜é€ŸåŒ–
            skip_interval=4,              # 4ãƒ•ãƒ¬ãƒ¼ãƒ ã«1å›MediaPipeå®Ÿè¡Œ
            roi_confidence_threshold=0.6,
            max_tracking_age=15
        )
        # projector_3dã¨trackerã®åˆæœŸåŒ–ã¯è¦ªã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–å¾Œã«è¡Œã†
        self.projector_3d = None
        self.tracker = None
        
        # åˆæœŸåŒ–å®Œäº†ãƒ•ãƒ©ã‚°
        self._components_initialized = False
    
    def update_help_text(self):
        """ãƒ˜ãƒ«ãƒ—ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°ï¼ˆè¡çªæ¤œå‡ºæ©Ÿèƒ½ã‚’è¿½åŠ ï¼‰"""
        self.help_text = "=== Basic Controls ===\n"
        self.help_text += "Q/ESC: Exit\n"
        self.help_text += "F: Toggle filter\n"
        self.help_text += "H: Toggle hand detection\n"
        self.help_text += "T: Toggle tracking\n"
        self.help_text += "R: Reset filter\n"
        self.help_text += "Y: Reset tracker\n"
        
        # ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°åˆ¶å¾¡ã‚’è¿½åŠ 
        self.help_text += "\n=== Point Cloud Optimization ===\n"
        self.help_text += "X: Toggle voxel downsampling\n"
        self.help_text += "Z/Shift+Z: Voxel size -/+ (1mm-10cm)\n"
        self.help_text += "B: Print voxel performance stats\n"
        
        # è¡çªæ¤œå‡ºé–¢é€£ã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒ‰ã‚’è¿½åŠ 
        self.help_text += "\n=== è¡çªæ¤œå‡ºåˆ¶å¾¡ ===\n"
        self.help_text += "M: ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ ON/OFF\n"
        self.help_text += "C: è¡çªæ¤œå‡º ON/OFF\n"
        self.help_text += "V: è¡çªå¯è¦–åŒ– ON/OFF\n"
        self.help_text += "N: ãƒ¡ãƒƒã‚·ãƒ¥å¼·åˆ¶æ›´æ–°\n"
        self.help_text += "+/-: çƒåŠå¾„èª¿æ•´\n"
        self.help_text += "P: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆè¡¨ç¤º\n"
        
        # éŸ³éŸ¿ç”Ÿæˆé–¢é€£ã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒ‰ã‚’è¿½åŠ 
        self.help_text += "\n=== éŸ³éŸ¿ç”Ÿæˆåˆ¶å¾¡ ===\n"
        self.help_text += "A: éŸ³éŸ¿åˆæˆ ON/OFF\n"
        self.help_text += "S: éŸ³éšåˆ‡ã‚Šæ›¿ãˆ\n"
        self.help_text += "I: æ¥½å™¨åˆ‡ã‚Šæ›¿ãˆ\n"
        self.help_text += "1/2: éŸ³é‡èª¿æ•´\n"
        self.help_text += "R: éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³å†èµ·å‹•\n"
        self.help_text += "Q: å…¨éŸ³å£°åœæ­¢\n"
    
    def handle_key_event(self, key):
        """ã‚­ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ï¼ˆè¡çªæ¤œå‡ºæ©Ÿèƒ½ã‚’è¿½åŠ ï¼‰"""
        # åŸºæœ¬çš„ãªã‚­ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†
        if key == ord('q') or key == 27:  # Q or ESC
            return False
        elif key == ord('f'):  # Toggle filter
            self.enable_filter = not self.enable_filter
            print(f"Depth filter: {'Enabled' if self.enable_filter else 'Disabled'}")
            return True
        elif key == ord('h'):  # Toggle hand detection
            self.enable_hand_detection = not self.enable_hand_detection
            print(f"Hand detection: {'Enabled' if self.enable_hand_detection else 'Disabled'}")
            return True
        elif key == ord('t'):  # Toggle tracking
            self.enable_tracking = not self.enable_tracking
            print(f"Hand tracking: {'Enabled' if self.enable_tracking else 'Disabled'}")
            return True
        elif key == ord('r') and self.depth_filter is not None:  # Reset filter
            self.depth_filter.reset_temporal_history()
            print("Filter history reset")
            return True
        elif key == ord('y') and self.tracker is not None:  # Reset tracker
            self.tracker.reset()
            print("Hand tracker reset")
            return True
        
        # ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°åˆ¶å¾¡
        elif key == ord('x') or key == ord('X'):  # Toggle voxel downsampling
            if self.pointcloud_converter:
                self.pointcloud_converter.toggle_voxel_downsampling()
            return True
            
        elif key == ord('z'):  # Decrease voxel size (higher quality)
            if self.pointcloud_converter:
                current_size = self.pointcloud_converter.voxel_size
                new_size = max(0.001, current_size - 0.001)  # Decrease by 1mm
                self.pointcloud_converter.set_voxel_size(new_size)
            return True
            
        elif key == ord('Z'):  # Increase voxel size (higher performance)
            if self.pointcloud_converter:
                current_size = self.pointcloud_converter.voxel_size
                new_size = min(0.05, current_size + 0.001)  # Increase by 1mm
                self.pointcloud_converter.set_voxel_size(new_size)
            return True
            
        elif key == ord('b') or key == ord('B'):  # Print voxel performance stats
            if self.pointcloud_converter:
                self.pointcloud_converter.print_performance_stats()
            return True
        
        # è¡çªæ¤œå‡ºé–¢é€£ã®ã‚­ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ
        elif key == ord('m') or key == ord('M'):
            self.enable_mesh_generation = not self.enable_mesh_generation
            status = "æœ‰åŠ¹" if self.enable_mesh_generation else "ç„¡åŠ¹"
            print(f"ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ: {status}")
            return True
            
        elif key == ord('c') or key == ord('C'):
            self.enable_collision_detection = not self.enable_collision_detection
            status = "æœ‰åŠ¹" if self.enable_collision_detection else "ç„¡åŠ¹"
            print(f"è¡çªæ¤œå‡º: {status}")
            return True
            
        elif key == ord('v') or key == ord('V'):
            self.enable_collision_visualization = not self.enable_collision_visualization
            status = "æœ‰åŠ¹" if self.enable_collision_visualization else "ç„¡åŠ¹"
            print(f"è¡çªå¯è¦–åŒ–: {status}")
            self._update_visualization()
            return True
            
        elif key == ord('n') or key == ord('N'):
            print("ãƒ¡ãƒƒã‚·ãƒ¥ã‚’å¼·åˆ¶æ›´æ–°ä¸­...")
            self._force_mesh_update()
            return True
            
        elif key == ord('+') or key == ord('='):
            self.sphere_radius = min(self.sphere_radius + 0.01, 0.2)
            print(f"çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
            return True
            
        elif key == ord('-') or key == ord('_'):
            self.sphere_radius = max(self.sphere_radius - 0.01, 0.01)
            print(f"çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
            return True
            
        elif key == ord('p') or key == ord('P'):
            self._print_performance_stats()
            return True
        
        # éŸ³éŸ¿ç”Ÿæˆé–¢é€£ã®ã‚­ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ
        elif key == ord('a') or key == ord('A'):
            self.enable_audio_synthesis = not self.enable_audio_synthesis
            if self.enable_audio_synthesis:
                self._initialize_audio_system()
            else:
                self._shutdown_audio_system()
            status = "æœ‰åŠ¹" if self.enable_audio_synthesis else "ç„¡åŠ¹"
            print(f"éŸ³éŸ¿åˆæˆ: {status}")
            return True
            
        elif key == ord('s') or key == ord('S'):
            if self.enable_audio_synthesis:
                self._cycle_audio_scale()
            return True
            
        elif key == ord('i') or key == ord('I'):
            if self.enable_audio_synthesis:
                self._cycle_audio_instrument()
            return True
            
        elif key == ord('1'):
            if self.enable_audio_synthesis and self.audio_synthesizer:
                self.audio_master_volume = max(0.0, self.audio_master_volume - 0.1)
                self.audio_synthesizer.update_master_volume(self.audio_master_volume)
                print(f"éŸ³é‡: {self.audio_master_volume:.1f}")
            return True
            
        elif key == ord('2'):
            if self.enable_audio_synthesis and self.audio_synthesizer:
                self.audio_master_volume = min(1.0, self.audio_master_volume + 0.1)
                self.audio_synthesizer.update_master_volume(self.audio_master_volume)
                print(f"éŸ³é‡: {self.audio_master_volume:.1f}")
            return True
            
        elif key == ord('r') or key == ord('R'):
            if self.enable_audio_synthesis:
                print("éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³ã‚’å†èµ·å‹•ä¸­...")
                self._restart_audio_system()
            return True
            
        elif key == ord('q') or key == ord('Q'):
            if self.enable_audio_synthesis and self.voice_manager:
                self.voice_manager.stop_all_voices()
                print("å…¨éŸ³å£°ã‚’åœæ­¢ã—ã¾ã—ãŸ")
            return True
        
        return False
    
    def _update_terrain_mesh(self, points_3d):
        """åœ°å½¢ãƒ¡ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ï¼ˆLODæœ€é©åŒ–ç‰ˆï¼‰"""
        if points_3d is None or len(points_3d) < 100:
            return
        
        try:
            import time
            
            # LODãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆå™¨ã‚’ä½¿ç”¨ï¼ˆé«˜é€ŸåŒ–ï¼‰
            if hasattr(self, 'lod_mesh_generator') and self.lod_mesh_generator is not None:
                lod_start = time.perf_counter()
                
                # LODãƒ™ãƒ¼ã‚¹ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆï¼ˆæ‰‹ã®ä½ç½®ã‚’è€ƒæ…®ã—ãŸåŠ¹ç‡çš„ãªç”Ÿæˆï¼‰
                triangle_mesh = self.lod_mesh_generator.generate_mesh(
                    points_3d, 
                    self.current_tracked_hands,  # æ‰‹ã®ä½ç½®ã§LODåˆ¶å¾¡
                    force_update=getattr(self, 'force_mesh_update_requested', False)
                )
                
                total_lod_time = (time.perf_counter() - lod_start) * 1000
                
                if triangle_mesh is not None:
                    # LODç”ŸæˆæˆåŠŸæ™‚ã®å‡¦ç†
                    simplified_mesh = triangle_mesh
                    
                    # ãƒ‡ãƒãƒƒã‚°ç”¨æ™‚é–“æ¸¬å®šå‡ºåŠ›
                    if hasattr(self, 'frame_counter') and self.frame_counter % 50 == 0:
                        print(f"[LOD-MESH] {len(points_3d)} points -> {triangle_mesh.num_vertices} vertices, "
                              f"{triangle_mesh.num_triangles} triangles in {total_lod_time:.1f}ms")
                
                else:
                    # LODç”Ÿæˆå¤±æ•—æ™‚ã¯å¾“æ¥æ–¹å¼ã¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    print("[LOD-FALLBACK] Using traditional mesh generation")
                    triangle_mesh = self._generate_traditional_mesh(points_3d)
                    if triangle_mesh is None:
                        return
                    simplified_mesh = triangle_mesh
            
            else:
                # LODãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆå™¨ãŒç„¡åŠ¹ã®å ´åˆã¯å¾“æ¥æ–¹å¼
                triangle_mesh = self._generate_traditional_mesh(points_3d)
                if triangle_mesh is None:
                    return
                simplified_mesh = triangle_mesh
            
            # 4. ç©ºé–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
            self.spatial_index = SpatialIndex(simplified_mesh, index_type=IndexType.BVH)
            
            # 5. è¡çªæ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
            self.collision_searcher = CollisionSearcher(self.spatial_index)
            self.collision_tester = SphereTriangleCollision(simplified_mesh)
            
            # ãƒ¡ãƒƒã‚·ãƒ¥ä¿å­˜
            self.current_mesh = simplified_mesh
            
            # è¨ºæ–­ãƒ­ã‚°: ãƒ¡ãƒƒã‚·ãƒ¥ç¯„å›²ã‚’è¡¨ç¤º
            if simplified_mesh.vertices.size > 0:
                mesh_min = np.min(simplified_mesh.vertices, axis=0)
                mesh_max = np.max(simplified_mesh.vertices, axis=0)
                print(f"[MESH-INFO] Vertex range: X[{mesh_min[0]:.3f}, {mesh_max[0]:.3f}], "
                      f"Y[{mesh_min[1]:.3f}, {mesh_max[1]:.3f}], Z[{mesh_min[2]:.3f}, {mesh_max[2]:.3f}]")
            
            # å¯è¦–åŒ–æ›´æ–°
            self._update_mesh_visualization(simplified_mesh)
            
            # å¼·åˆ¶æ›´æ–°ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
            if hasattr(self, 'force_mesh_update_requested'):
                self.force_mesh_update_requested = False
            
            print(f"ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°å®Œäº†: {simplified_mesh.num_triangles}ä¸‰è§’å½¢")
            
        except Exception as e:
            print(f"ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
    
    def _detect_collisions(self, tracked_hands: List[TrackedHand]) -> list:
        if not self.collision_searcher: 
            print(f"[DEBUG] _detect_collisions: No collision searcher available")
            return []
        events = []
        self.current_collision_points = []
        print(f"[DEBUG] _detect_collisions: Processing {len(tracked_hands)} hands")
        
        for i, hand in enumerate(tracked_hands):
            if hand.position is None: 
                print(f"[DEBUG] _detect_collisions: Hand {i} has no position")
                continue
            hand_pos_np = np.array(hand.position)
            print(f"[DEBUG] _detect_collisions: Hand {i} position: ({hand_pos_np[0]:.3f}, {hand_pos_np[1]:.3f}, {hand_pos_np[2]:.3f})")
            
            try:
                res = self.collision_searcher.search_near_hand(hand, override_radius=self.sphere_radius)
                print(f"[DEBUG] _detect_collisions: Hand {i} found {len(res.triangle_indices)} nearby triangles")
                
                if not res.triangle_indices: continue
                
                # None check for collision_tester
                if self.collision_tester is not None:
                    info = self.collision_tester.test_sphere_collision(hand_pos_np, self.sphere_radius, res)
                    print(f"[DEBUG] _detect_collisions: Hand {i} collision test result: {info.has_collision}")
                    
                    if info.has_collision:
                        velocity = np.array(hand.velocity) if hasattr(hand, 'velocity') and hand.velocity is not None else np.zeros(3)
                        event = self.event_queue.create_event(info, hand.id, hand_pos_np, velocity)
                        if event:
                            events.append(event)
                            for cp in info.contact_points:
                               self.current_collision_points.append(cp.position)
                            print(f"[DEBUG] _detect_collisions: Hand {i} generated collision event with {len(info.contact_points)} contact points")
            except Exception as e:
                logger.error(f"[DEBUG] _detect_collisions: Error processing hand {i}: {e}")
        
        print(f"[DEBUG] _detect_collisions: Total collision events: {len(events)}")
        return events
    
    def _update_mesh_visualization(self, mesh):
        """ãƒ¡ãƒƒã‚·ãƒ¥å¯è¦–åŒ–ã‚’æ›´æ–°"""
        if not hasattr(self, 'vis') or self.vis is None:
            return
        
        # æ—¢å­˜ã®ãƒ¡ãƒƒã‚·ãƒ¥ã‚¸ã‚ªãƒ¡ãƒˆãƒªã‚’å‰Šé™¤
        for geom in self.mesh_geometries:
            self.vis.remove_geometry(geom, reset_bounding_box=False)
        self.mesh_geometries.clear()
        
        try:
            # Open3Dãƒ¡ãƒƒã‚·ãƒ¥ã‚’ä½œæˆ
            o3d_mesh = o3d.geometry.TriangleMesh()
            o3d_mesh.vertices = o3d.utility.Vector3dVector(mesh.vertices)
            o3d_mesh.triangles = o3d.utility.Vector3iVector(mesh.triangles)
            
            # æ³•ç·šè¨ˆç®—
            o3d_mesh.compute_vertex_normals()
            
            # åŠé€æ˜ã®ãƒãƒ†ãƒªã‚¢ãƒ«è¨­å®š
            o3d_mesh.paint_uniform_color([0.8, 0.8, 0.9])  # è–„é’è‰²
            
            # ãƒ¯ã‚¤ãƒ¤ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
            wireframe = o3d.geometry.LineSet.create_from_triangle_mesh(o3d_mesh)
            wireframe.paint_uniform_color([0.3, 0.3, 0.7])  # é’è‰²
            
            # ã‚¸ã‚ªãƒ¡ãƒˆãƒªã‚’è¿½åŠ 
            self.vis.add_geometry(o3d_mesh, reset_bounding_box=False)
            self.vis.add_geometry(wireframe, reset_bounding_box=False)
            
            self.mesh_geometries.extend([o3d_mesh, wireframe])
            
        except Exception as e:
            print(f"ãƒ¡ãƒƒã‚·ãƒ¥å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _update_collision_visualization(self):
        """è¡çªå¯è¦–åŒ–ã‚’æ›´æ–°"""
        if not hasattr(self, 'vis') or self.vis is None:
            return
        
        # æ—¢å­˜ã®è¡çªã‚¸ã‚ªãƒ¡ãƒˆãƒªã‚’å‰Šé™¤
        for geom in self.collision_geometries:
            self.vis.remove_geometry(geom, reset_bounding_box=False)
        self.collision_geometries.clear()
        
        if not self.enable_collision_visualization:
            return
        
        try:
            # æ¥è§¦ç‚¹ã‚’å¯è¦–åŒ–
            for contact in self.current_collision_points:
                # æ¥è§¦ç‚¹ï¼ˆçƒï¼‰
                contact_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.01)
                contact_sphere.translate(contact['position'])
                contact_sphere.paint_uniform_color([1.0, 0.0, 0.0])  # èµ¤è‰²
                
                # æ³•ç·šãƒ™ã‚¯ãƒˆãƒ«ï¼ˆç·šåˆ†ï¼‰
                normal_end = contact['position'] + contact['normal'] * 0.05
                normal_line = o3d.geometry.LineSet()
                normal_line.points = o3d.utility.Vector3dVector([
                    contact['position'], normal_end
                ])
                normal_line.lines = o3d.utility.Vector2iVector([[0, 1]])
                normal_line.paint_uniform_color([1.0, 1.0, 0.0])  # é»„è‰²
                
                self.vis.add_geometry(contact_sphere, reset_bounding_box=False)
                self.vis.add_geometry(normal_line, reset_bounding_box=False)
                
                self.collision_geometries.extend([contact_sphere, normal_line])
            
            # è¡çªçƒã‚’å¯è¦–åŒ–ï¼ˆæ‰‹ã®ä½ç½®ï¼‰
            if self.current_tracked_hands:
                for tracked in self.current_tracked_hands:
                    if tracked.position is not None:
                        hand_sphere = o3d.geometry.TriangleMesh.create_sphere(
                            radius=self.sphere_radius
                        )
                        hand_sphere.translate(tracked.position)
                        hand_sphere.paint_uniform_color([0.0, 1.0, 0.0])  # ç·‘è‰²ï¼ˆåŠé€æ˜ï¼‰
                        
                        # ãƒ¯ã‚¤ãƒ¤ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
                        wireframe = o3d.geometry.LineSet.create_from_triangle_mesh(hand_sphere)
                        wireframe.paint_uniform_color([0.0, 0.8, 0.0])
                        
                        self.vis.add_geometry(wireframe, reset_bounding_box=False)
                        self.collision_geometries.append(wireframe)
        
        except Exception as e:
            print(f"è¡çªå¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _update_visualization(self):
        """å¯è¦–åŒ–å…¨ä½“ã‚’æ›´æ–°"""
        if self.current_mesh and self.enable_collision_visualization:
            self._update_mesh_visualization(self.current_mesh)
        self._update_collision_visualization()
    
    def _force_mesh_update(self):
        """ãƒ¡ãƒƒã‚·ãƒ¥å¼·åˆ¶æ›´æ–°ã‚’æ¬¡ãƒ•ãƒ¬ãƒ¼ãƒ ã§è¡Œã†ã‚ˆã†ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        self.force_mesh_update_requested = True
    
    def _draw_performance_info(self, color_image, collision_events):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’RGBç”»åƒã«æç”»"""
        if color_image is None:
            return
        
        # åŸºæœ¬æƒ…å ±
        info_lines = [
            f"Frame: {self.frame_counter}",
            f"Pipeline: {self.perf_stats['total_pipeline_time']:.1f}ms",
            f"Mesh Gen: {self.perf_stats['mesh_generation_time']:.1f}ms",
            f"Collision: {self.perf_stats['collision_detection_time']:.1f}ms",
            f"Audio: {self.perf_stats['audio_synthesis_time']:.1f}ms",
            f"Events: {len(collision_events)}",
            f"Sphere R: {self.sphere_radius*100:.1f}cm"
        ]
        
        # ãƒ¡ãƒƒã‚·ãƒ¥æƒ…å ±
        if self.current_mesh:
            info_lines.append(f"Triangles: {self.current_mesh.num_triangles}")
        
        # æ¥è§¦ç‚¹æƒ…å ±
        if self.current_collision_points:
            info_lines.append(f"Contacts: {len(self.current_collision_points)}")
        
        # éŸ³éŸ¿æƒ…å ±
        if self.enable_audio_synthesis:
            audio_status = "ON" if self.audio_enabled else "OFF"
            info_lines.append(f"Audio: {audio_status}")
            if self.audio_enabled and self.voice_manager:
                active_voices = len(self.voice_manager.active_voices)
                info_lines.append(f"Voices: {active_voices}/{self.audio_polyphony}")
        
        # æç”»
        y_offset = 30
        for i, line in enumerate(info_lines):
            cv2.putText(color_image, line, (10, y_offset + i * 25), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # è¡çªã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±
        if collision_events:
            cv2.putText(color_image, "COLLISION DETECTED!", 
                       (10, color_image.shape[0] - 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)
        
        # éŸ³éŸ¿å†ç”Ÿæƒ…å ±
        if self.enable_audio_synthesis and self.audio_enabled and collision_events:
            cv2.putText(color_image, f"PLAYING AUDIO ({self.audio_instrument.value})", 
                       (10, color_image.shape[0] - 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
    
    def _print_performance_stats(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’å°åˆ·"""
        print("\n" + "="*50)
        print("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ")
        print("="*50)
        print(f"ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {self.perf_stats['frame_count']}")
        print(f"ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ : {self.frame_counter}")
        print(f"ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ™‚é–“: {self.perf_stats['total_pipeline_time']:.2f}ms")
        print(f"ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆæ™‚é–“: {self.perf_stats['mesh_generation_time']:.2f}ms")
        print(f"è¡çªæ¤œå‡ºæ™‚é–“: {self.perf_stats['collision_detection_time']:.2f}ms")
        print(f"éŸ³éŸ¿ç”Ÿæˆæ™‚é–“: {self.perf_stats['audio_synthesis_time']:.2f}ms")
        print(f"ç·è¡çªã‚¤ãƒ™ãƒ³ãƒˆæ•°: {self.perf_stats['collision_events_count']}")
        print(f"ç·éŸ³éŸ¿ãƒãƒ¼ãƒˆæ•°: {self.perf_stats['audio_notes_played']}")
        
        # ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°çµ±è¨ˆ
        if self.pointcloud_converter:
            voxel_stats = self.pointcloud_converter.get_performance_stats()
            print(f"\n--- Point Cloud Optimization ---")
            print(f"ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: {'æœ‰åŠ¹' if voxel_stats.get('voxel_downsampling_enabled', False) else 'ç„¡åŠ¹'}")
            if voxel_stats.get('voxel_downsampling_enabled', False):
                print(f"  - ãƒœã‚¯ã‚»ãƒ«ã‚µã‚¤ã‚º: {voxel_stats.get('current_voxel_size_mm', 0):.1f}mm")
                print(f"  - æœ€æ–°å…¥åŠ›ç‚¹æ•°: {voxel_stats.get('last_input_points', 0):,}")
                print(f"  - æœ€æ–°å‡ºåŠ›ç‚¹æ•°: {voxel_stats.get('last_output_points', 0):,}")
                print(f"  - ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡: {voxel_stats.get('last_downsampling_ratio', 0)*100:.1f}%")
                avg_time = voxel_stats.get('average_time_ms', 0)
                print(f"  - å¹³å‡å‡¦ç†æ™‚é–“: {avg_time:.2f}ms")
        
        if self.current_mesh:
            print(f"ç¾åœ¨ã®ãƒ¡ãƒƒã‚·ãƒ¥: {self.current_mesh.num_triangles}ä¸‰è§’å½¢")
        
        print(f"çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
        
        # éŸ³éŸ¿çµ±è¨ˆ
        if self.enable_audio_synthesis:
            print(f"éŸ³éŸ¿åˆæˆ: {'æœ‰åŠ¹' if self.audio_enabled else 'ç„¡åŠ¹'}")
            if self.audio_enabled:
                print(f"  - éŸ³éš: {self.audio_scale.value}")
                print(f"  - æ¥½å™¨: {self.audio_instrument.value}")
                print(f"  - éŸ³é‡: {self.audio_master_volume:.1f}")
                if self.voice_manager:
                    voice_stats = self.voice_manager.get_performance_stats()
                    print(f"  - ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒœã‚¤ã‚¹: {voice_stats['current_active_voices']}/{self.audio_polyphony}")
                    print(f"  - ç·ä½œæˆãƒœã‚¤ã‚¹: {voice_stats['total_voices_created']}")
                    print(f"  - ãƒœã‚¤ã‚¹ã‚¹ãƒ†ã‚£ãƒ¼ãƒ«: {voice_stats['total_voices_stolen']}")
        
        print("="*50)
    
    def _process_frame(self) -> bool:
        """
        1ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆè¡çªæ¤œå‡ºç‰ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼‰
        DualViewerã®ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã—ã¦è¡çªæ¤œå‡ºã‚’çµ±åˆ
        """
        frame_start_time = time.perf_counter()
        
        # 3Dæ‰‹æ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®é…å»¶åˆæœŸåŒ–
        if not self._components_initialized and hasattr(self, 'camera') and self.camera is not None:
            try:
                print("Setting up 3D hand detection components...")
                # ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–ç¢ºèª
                if self.camera.depth_intrinsics is not None:
                    # ä¿¡é ¼åº¦é–¾å€¤ã‚’ä¸‹ã’ã¦ãƒ†ã‚¹ãƒˆ
                    self.projector_3d = Hand3DProjector(
                        self.camera.depth_intrinsics,
                        min_confidence_3d=0.1  # 10%ã«ä¸‹ã’ã¦ãƒ†ã‚¹ãƒˆ
                    )
                    self.tracker = Hand3DTracker()
                    self._components_initialized = True
                    print("3D hand detection components initialized with lowered confidence threshold")
                else:
                    print("Camera depth intrinsics not available")
            except Exception as e:
                print(f"3D component initialization error: {e}")
        
        # ã‚«ãƒ¡ãƒ©ãŒãªã„å ´åˆã¯çµ‚äº†
        if self.camera is None:
            print("Camera not available")
            return False
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—
        frame_data = self.camera.get_frame(timeout_ms=100)
        if frame_data is None or frame_data.depth_frame is None:
            return True
        
        # æ·±åº¦ç”»åƒã®æŠ½å‡º
        depth_data = np.frombuffer(frame_data.depth_frame.get_data(), dtype=np.uint16)
        # ã‚«ãƒ¡ãƒ©ã®å†…éƒ¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
        if self.camera.depth_intrinsics is not None:
            depth_image = depth_data.reshape(
                (self.camera.depth_intrinsics.height, self.camera.depth_intrinsics.width)
            )
        else:
            print("Depth intrinsics not available")
            return True
        
        # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
        filter_start_time = time.perf_counter()
        if self.depth_filter is not None and self.enable_filter:
            depth_image = self.depth_filter.apply_filter(depth_image)
        self.performance_stats['filter_time'] = (time.perf_counter() - filter_start_time) * 1000
        
        # ç‚¹ç¾¤ç”Ÿæˆï¼ˆå¿…è¦æ™‚ï¼‰
        points_3d = None
        need_points_for_mesh = (self.enable_mesh_generation and 
                                self.frame_count - self.last_mesh_update >= self.mesh_update_interval)
        
        if self.pointcloud_converter and (self.frame_count % self.update_interval == 0 or need_points_for_mesh):
            pointcloud_start = time.perf_counter()
            # depth_imageã¯æ—¢ã«numpyé…åˆ—ãªã®ã§ã€numpy_to_pointcloudã‚’ä½¿ç”¨
            points_3d, _ = self.pointcloud_converter.numpy_to_pointcloud(depth_image)
            self.performance_stats['pointcloud_time'] = (time.perf_counter() - pointcloud_start) * 1000
            if need_points_for_mesh:
                print(f"[MESH-PREP] Frame {self.frame_count}: Generated points for mesh update: {len(points_3d) if points_3d is not None else 'None'}")
        
        # æ‰‹æ¤œå‡ºå‡¦ç†ï¼ˆä¸€å…ƒåŒ–ï¼šã“ã“ã§1å›ã®ã¿å®Ÿè¡Œï¼‰
        hands_2d, hands_3d, tracked_hands = [], [], []
        
        # å®Ÿéš›ã«æ‰‹æ¤œå‡ºã‚’å®Ÿè¡Œï¼ˆDualViewerã‹ã‚‰ç¶™æ‰¿ã—ãŸãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼‰
        if self.enable_hand_detection and self.hands_2d is not None:
            hand_start_time = time.perf_counter()
            hands_2d, hands_3d, tracked_hands = self._process_hand_detection(depth_image)
            self.performance_stats['hand_detection_time'] = (time.perf_counter() - hand_start_time) * 1000
            print(f"[HAND-OPTIMIZED] Frame {self.frame_count}: Hand detection completed in {self.performance_stats['hand_detection_time']:.1f}ms - 2D:{len(hands_2d)}, 3D:{len(hands_3d)}, Tracked:{len(tracked_hands)}")
        else:
            self.performance_stats['hand_detection_time'] = 0.0
        
        # æ‰‹æ¤œå‡ºçµæœã‚’ã‚¯ãƒ©ã‚¹å¤‰æ•°ã«ä¿å­˜ï¼ˆRGBè¡¨ç¤ºã§ä½¿ã„å›ã™ãŸã‚ï¼‰
        self.current_hands_2d = hands_2d
        self.current_hands_3d = hands_3d
        self.current_tracked_hands = tracked_hands
        
        # æ‰‹ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã®ã¿è©³ç´°ãƒ­ã‚°ã‚’å‡ºåŠ›
        if len(hands_2d) > 0 or len(hands_3d) > 0 or len(tracked_hands) > 0:
            print(f"[HANDS] Frame {self.frame_count}: *** HANDS DETECTED *** 2D:{len(hands_2d)} 3D:{len(hands_3d)} Tracked:{len(tracked_hands)}")
        
        # è¡çªæ¤œå‡ºã¨ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        pipeline_start = time.perf_counter()
        self.frame_counter = self.frame_count  # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’åŒæœŸ
        
        # æ‰‹ãŒå­˜åœ¨ã™ã‚‹ã‹åˆ¤å®š
        hands_present = (len(hands_2d) > 0 or len(hands_3d) > 0 or len(tracked_hands) > 0)
        frame_diff = self.frame_count - self.last_mesh_update

        # åœ°å½¢ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆï¼ˆæ¡ä»¶åˆ¤å®šï¼‰
        mesh_condition_check = (
            self.enable_mesh_generation and (
                # å¼·åˆ¶æ›´æ–°è¦æ±‚ãŒã‚ã‚‹å ´åˆã¯å³æ›´æ–°
                self.force_mesh_update_requested or
                # æ‰‹ãŒå†™ã£ã¦ã„ãªã„ & é€šå¸¸é–“éš”ã‚’è¶…ãˆãŸ
                (not hands_present and frame_diff >= self.mesh_update_interval) or
                # æœ€å¤§ã‚¹ã‚­ãƒƒãƒ—æ™‚é–“ã‚’è¶…ãˆãŸ
                (frame_diff >= self.max_mesh_skip_frames) or
                # ã¾ã ãƒ¡ãƒƒã‚·ãƒ¥ãŒç„¡ã„
                (self.current_mesh is None)
            ) and
            points_3d is not None and len(points_3d) > 100
        )
        
        # ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆæ¡ä»¶ã®è¨ºæ–­ãƒ­ã‚°
        if self.frame_count % 10 == 0:  # 10ãƒ•ãƒ¬ãƒ¼ãƒ æ¯ã«è¨ºæ–­ãƒ­ã‚°
            print(f"[MESH-DIAG] Frame {self.frame_count}: enable_mesh={self.enable_mesh_generation}, "
                  f"frame_diff={frame_diff}, "
                  f"interval={self.mesh_update_interval}, "
                  f"max_skip={self.max_mesh_skip_frames}, "
                  f"points={len(points_3d) if points_3d is not None else 'None'}, "
                  f"condition={mesh_condition_check}")
        
        if mesh_condition_check:
            mesh_start = time.perf_counter()
            points_len = len(points_3d) if points_3d is not None else 0
            print(f"[MESH] Frame {self.frame_count}: *** UPDATING TERRAIN MESH *** with {points_len} points")
            self._update_terrain_mesh(points_3d)
            self.last_mesh_update = self.frame_count
            # å¼·åˆ¶æ›´æ–°ãƒ•ãƒ©ã‚°ã‚’ã‚¯ãƒªã‚¢
            self.force_mesh_update_requested = False
            self.perf_stats['mesh_generation_time'] = (time.perf_counter() - mesh_start) * 1000
            print(f"[MESH] Frame {self.frame_count}: Mesh update completed in {self.perf_stats['mesh_generation_time']:.1f}ms")
        
        # è¡çªæ¤œå‡º
        collision_events = []
        if (self.enable_collision_detection and self.current_mesh is not None and tracked_hands):
            print(f"[COLLISION] Frame {self.frame_count}: *** CHECKING COLLISIONS *** with {len(tracked_hands)} hands and mesh available")
            collision_start = time.perf_counter()
            collision_events = self._detect_collisions(tracked_hands)
            self.perf_stats['collision_detection_time'] = (time.perf_counter() - collision_start) * 1000
            self.perf_stats['collision_events_count'] += len(collision_events)
            if len(collision_events) > 0:
                print(f"[COLLISION] Frame {self.frame_count}: *** COLLISION DETECTED! *** {len(collision_events)} events")
            else:
                print(f"[COLLISION] Frame {self.frame_count}: No collisions detected")
        
        # éŸ³éŸ¿ç”Ÿæˆ
        if (self.enable_audio_synthesis and self.audio_enabled and collision_events):
            audio_start = time.perf_counter()
            print(f"[AUDIO] Frame {self.frame_count}: *** GENERATING AUDIO *** for {len(collision_events)} collision events")
            audio_notes = self._generate_audio(collision_events)
            self.perf_stats['audio_notes_played'] += audio_notes
            self.perf_stats['audio_synthesis_time'] = (time.perf_counter() - audio_start) * 1000
            print(f"[AUDIO] Frame {self.frame_count}: Generated {audio_notes} audio notes in {self.perf_stats['audio_synthesis_time']:.1f}ms")
        
        self.perf_stats['total_pipeline_time'] = (time.perf_counter() - pipeline_start) * 1000
        
        # RGBè¡¨ç¤ºå‡¦ç†ï¼ˆæ—¢å­˜ã®DualViewerãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨ï¼‰
        if not self._process_rgb_display(frame_data, collision_events):
            return False
        
        # ç‚¹ç¾¤è¡¨ç¤ºå‡¦ç†ï¼ˆé–“éš”åˆ¶å¾¡ï¼‰
        if self.frame_count % self.update_interval == 0:
            if not self._process_pointcloud_display(frame_data):
                return False
        
        self.frame_count += 1
        self.performance_stats['frame_time'] = (time.perf_counter() - frame_start_time) * 1000
        
        return True

    def _initialize_audio_system(self):
        """éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–"""
        try:
            print("éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­...")
            
            # éŸ³éŸ¿ãƒãƒƒãƒ‘ãƒ¼åˆæœŸåŒ–
            self.audio_mapper = AudioMapper(
                scale=self.audio_scale,
                default_instrument=self.audio_instrument,
                pitch_range=(48, 84),  # C3-C6
                enable_adaptive_mapping=True
            )
            
            # éŸ³éŸ¿ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
            self.audio_synthesizer = create_audio_synthesizer(
                sample_rate=44100,
                buffer_size=256,
                max_polyphony=self.audio_polyphony
            )
            
            # éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³é–‹å§‹
            if self.audio_synthesizer.start_engine():
                # ãƒœã‚¤ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
                self.voice_manager = create_voice_manager(
                    self.audio_synthesizer,
                    max_polyphony=self.audio_polyphony,
                    steal_strategy=StealStrategy.OLDEST
                )
                
                # ãƒã‚¹ã‚¿ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ è¨­å®š
                self.audio_synthesizer.update_master_volume(self.audio_master_volume)
                
                self.audio_enabled = True
                print("éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            else:
                print("éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ")
                self.audio_enabled = False
        
        except Exception as e:
            print(f"éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.audio_enabled = False
    
    def _shutdown_audio_system(self):
        """éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ï¼ˆå®‰å…¨ç‰ˆï¼‰"""
        try:
            print("[AUDIO-SHUTDOWN] éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ä¸­...")
            self.audio_enabled = False  # æœ€åˆã«ç„¡åŠ¹åŒ–ã—ã¦æ–°ã—ã„éŸ³ç”Ÿæˆã‚’é˜²ã
            
            # ãƒœã‚¤ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åœæ­¢
            if self.voice_manager:
                try:
                    self.voice_manager.stop_all_voices(fade_out_time=0.01)  # çŸ­æ™‚é–“ãƒ•ã‚§ãƒ¼ãƒ‰
                    time.sleep(0.05)  # å°‘ã—å¾…æ©Ÿã—ã¦ãƒœã‚¤ã‚¹åœæ­¢ã‚’ç¢ºå®Ÿã«ã™ã‚‹
                    self.voice_manager = None
                except Exception as e:
                    print(f"[AUDIO-SHUTDOWN] VoiceManageråœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ãƒ¼ã‚¨ãƒ³ã‚¸ãƒ³ã®åœæ­¢
            if self.audio_synthesizer:
                try:
                    self.audio_synthesizer.stop_engine()
                    time.sleep(0.05)  # å°‘ã—å¾…æ©Ÿã—ã¦ã‚¨ãƒ³ã‚¸ãƒ³åœæ­¢ã‚’ç¢ºå®Ÿã«ã™ã‚‹
                    self.audio_synthesizer = None
                except Exception as e:
                    print(f"[AUDIO-SHUTDOWN] Synthesizeråœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            
            # éŸ³éŸ¿ãƒãƒƒãƒ‘ãƒ¼ã‚‚ã‚¯ãƒªã‚¢
            self.audio_mapper = None
            
            print("[AUDIO-SHUTDOWN] éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã—ã¾ã—ãŸ")
        
        except Exception as e:
            print(f"[AUDIO-SHUTDOWN] éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ åœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼ã§ã‚‚çŠ¶æ…‹ã‚’ç„¡åŠ¹ã«ã™ã‚‹
            self.audio_enabled = False
    
    def _restart_audio_system(self):
        """éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’å†èµ·å‹•"""
        self._shutdown_audio_system()
        time.sleep(0.1)  # çŸ­æ™‚é–“å¾…æ©Ÿ
        if self.enable_audio_synthesis:
            self._initialize_audio_system()
    
    def _generate_audio(self, collision_events):
        """è¡çªã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰éŸ³éŸ¿ã‚’ç”Ÿæˆï¼ˆã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æ©Ÿæ§‹ä»˜ãï¼‰"""
        if not self.audio_enabled or not self.audio_mapper or not self.voice_manager:
            return 0
        
        notes_played = 0
        current_time = time.perf_counter()
        
        for event in collision_events:
            try:
                # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒã‚§ãƒƒã‚¯ï¼ˆæ‰‹IDåˆ¥ï¼‰
                hand_id = event.hand_id
                last_trigger = self.last_audio_trigger_time.get(hand_id, 0)
                time_since_last = current_time - last_trigger
                
                if time_since_last < self.audio_cooldown_time:
                    print(f"[AUDIO-COOLDOWN] Hand {hand_id}: {time_since_last*1000:.1f}ms since last trigger, skipping")
                    continue
                
                # è¡çªã‚¤ãƒ™ãƒ³ãƒˆã‚’éŸ³éŸ¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ãƒãƒƒãƒ”ãƒ³ã‚°
                audio_params = self.audio_mapper.map_collision_event(event)
                
                # ç©ºé–“ä½ç½®è¨­å®šï¼ˆnumpy.float64 â†’ Python floatå¤‰æ›ï¼‰
                spatial_position = np.array([
                    float(event.contact_position[0]),
                    0.0,
                    float(event.contact_position[2])
                ], dtype=float)
                
                # éŸ³éŸ¿å†ç”Ÿ
                voice_id = allocate_and_play(
                    self.voice_manager,
                    audio_params,
                    priority=7,
                    spatial_position=spatial_position
                )
                
                if voice_id:
                    notes_played += 1
                    # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒãƒ¼æ›´æ–°
                    self.last_audio_trigger_time[hand_id] = current_time
                    print(f"[AUDIO-TRIGGER] Hand {hand_id}: Note triggered (cooldown reset)")
            
            except Exception as e:
                print(f"éŸ³éŸ¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆ: {event.event_id}ï¼‰: {e}")
        
        # çµ‚äº†ã—ãŸãƒœã‚¤ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ é–“éš”ã‚’ç©ºã‘ã¦è² è·è»½æ¸›ï¼‰
        if self.voice_manager and self.frame_count % 10 == 0:  # 10ãƒ•ãƒ¬ãƒ¼ãƒ ã«1å›ã®ã¿
            try:
                self.voice_manager.cleanup_finished_voices()
            except Exception as e:
                print(f"[AUDIO-CLEANUP] Error during cleanup: {e}")
        
        return notes_played
    
    def _cycle_audio_scale(self):
        """éŸ³éšã‚’å¾ªç’°åˆ‡ã‚Šæ›¿ãˆ"""
        scales = list(ScaleType)
        current_index = scales.index(self.audio_scale)
        next_index = (current_index + 1) % len(scales)
        self.audio_scale = scales[next_index]
        
        if self.audio_mapper:
            self.audio_mapper.set_scale(self.audio_scale)
        
        print(f"éŸ³éšã‚’åˆ‡ã‚Šæ›¿ãˆ: {self.audio_scale.value}")
    
    def _cycle_audio_instrument(self):
        """æ¥½å™¨ã‚’å¾ªç’°åˆ‡ã‚Šæ›¿ãˆ"""
        instruments = list(InstrumentType)
        current_index = instruments.index(self.audio_instrument)
        next_index = (current_index + 1) % len(instruments)
        self.audio_instrument = instruments[next_index]
        
        if self.audio_mapper:
            self.audio_mapper.default_instrument = self.audio_instrument
        
        print(f"æ¥½å™¨ã‚’åˆ‡ã‚Šæ›¿ãˆ: {self.audio_instrument.value}")
    
    def __del__(self):
        """ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ - éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’é©åˆ‡ã«åœæ­¢"""
        try:
            if hasattr(self, 'audio_enabled') and self.audio_enabled:
                print("[DESTRUCTOR] éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
                self._shutdown_audio_system()
        except Exception as e:
            print(f"[DESTRUCTOR] ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã§ã‚¨ãƒ©ãƒ¼: {e}")
            
    def cleanup(self):
        """æ˜ç¤ºçš„ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ¡ã‚½ãƒƒãƒ‰"""
        try:
            if self.audio_enabled:
                self._shutdown_audio_system()
        except Exception as e:
            print(f"[CLEANUP] ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    def _process_rgb_display(self, frame_data, collision_events=None) -> bool:
        """
        RGBè¡¨ç¤ºå‡¦ç†ï¼ˆè¡çªæ¤œå‡ºç‰ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼‰
        
        Args:
            frame_data: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿
            collision_events: è¡çªã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            
        Returns:
            ç¶™ç¶šã™ã‚‹å ´åˆTrue
        """
        try:
            # æ·±åº¦ç”»åƒã‚’ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã§å¯è¦–åŒ–
            depth_data = np.frombuffer(frame_data.depth_frame.get_data(), dtype=np.uint16)
            # ã‚«ãƒ¡ãƒ©ã®å†…éƒ¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
            if self.camera.depth_intrinsics is not None:
                depth_image = depth_data.reshape(
                    (self.camera.depth_intrinsics.height, self.camera.depth_intrinsics.width)
                )
            else:
                print("Depth intrinsics not available for RGB display")
                return True
            
            # æ·±åº¦ç”»åƒã‚’è¡¨ç¤ºç”¨ã«æ­£è¦åŒ–
            depth_normalized = cv2.normalize(depth_image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
            depth_colored = cv2.applyColorMap(depth_normalized, cv2.COLORMAP_JET)
            
            # æ‰‹æ¤œå‡ºå‡¦ç†ï¼ˆé‡è¤‡æ’é™¤ï¼š_process_frameã§æ—¢ã«å®Ÿè¡Œæ¸ˆã¿ã®çµæœã‚’ä½¿ç”¨ï¼‰
            hands_2d = getattr(self, 'current_hands_2d', [])
            hands_3d = getattr(self, 'current_hands_3d', [])
            tracked_hands = getattr(self, 'current_tracked_hands', [])
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆé‡è¤‡å®Ÿè¡Œæ’é™¤æ¸ˆã¿ï¼‰
            if len(hands_2d) > 0 or len(hands_3d) > 0 or len(tracked_hands) > 0:
                print(f"[HAND-DEBUG] Frame {self.frame_count}: Using cached hand detection results - 2D:{len(hands_2d)}, 3D:{len(hands_3d)}, Tracked:{len(tracked_hands)}")
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã¯_process_frameã§è¨ˆæ¸¬æ¸ˆã¿ãªã®ã§çœç•¥
            self.performance_stats['hand_detection_time'] = 0.0  # é‡è¤‡å®Ÿè¡Œæ’é™¤ã®ãŸã‚0ms
        
            # ã‚«ãƒ©ãƒ¼ç”»åƒãŒã‚ã‚Œã°è¡¨ç¤º
            display_images = []
            
            # æ·±åº¦ç”»åƒï¼ˆç–‘ä¼¼ã‚«ãƒ©ãƒ¼ï¼‰
            depth_resized = cv2.resize(depth_colored, self.rgb_window_size)
            cv2.putText(depth_resized, f"Depth (Frame: {self.frame_count})", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            display_images.append(depth_resized)
            
            # RGBç”»åƒ
            color_bgr = None
            if frame_data.color_frame is not None and self.camera.has_color:
                color_data = np.frombuffer(frame_data.color_frame.get_data(), dtype=np.uint8)
                color_format = frame_data.color_frame.get_format()
                
                # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¿œã˜ãŸå¤‰æ›ï¼ˆDualViewerã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
                try:
                    from pyorbbecsdk import OBFormat
                except ImportError:
                    pass  # Use imported OBFormat from src.types
                
                color_image = None
                if color_format == OBFormat.RGB:
                    # RGBå½¢å¼ã®å ´åˆã€ã‚«ãƒ©ãƒ¼ç”»åƒã®å®Ÿéš›ã®ã‚µã‚¤ã‚ºã‚’å–å¾—
                    total_pixels = len(color_data) // 3
                    # 1280x720 æƒ³å®šã§ãƒªã‚·ã‚§ã‚¤ãƒ—
                    color_image = color_data.reshape((720, 1280, 3))
                elif color_format == OBFormat.BGR:
                    total_pixels = len(color_data) // 3
                    color_image = color_data.reshape((720, 1280, 3))
                    color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)
                elif color_format == OBFormat.MJPG:
                    color_image = cv2.imdecode(color_data, cv2.IMREAD_COLOR)
                    if color_image is not None:
                        color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)
                
                if color_image is not None:
                    color_resized = cv2.resize(color_image, self.rgb_window_size)
                    color_bgr = cv2.cvtColor(color_resized, cv2.COLOR_RGB2BGR)
                    
                    # æ‰‹æ¤œå‡ºçµæœã‚’æç”»
                    if self.enable_hand_detection and hands_2d:
                        color_bgr = self._draw_hand_detections(color_bgr, hands_2d, hands_3d, tracked_hands)
                    
                    # è¡çªæ¤œå‡ºæƒ…å ±ã‚’æç”»
                    if collision_events:
                        self._draw_collision_info(color_bgr, collision_events)
                    
                    cv2.putText(color_bgr, f"RGB (FPS: {self.performance_stats['fps']:.1f})", 
                               (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                    display_images.append(color_bgr)
            
            # ç”»åƒã‚’æ¨ªã«ä¸¦ã¹ã¦è¡¨ç¤º
            if len(display_images) > 1:
                combined_image = np.hstack(display_images)
            else:
                combined_image = display_images[0]
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
            self._draw_performance_overlay(combined_image)
            
            # è¡çªæ¤œå‡ºãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’è¿½åŠ æç”»
            if hasattr(self, 'perf_stats'):
                self._draw_collision_performance_info(combined_image, collision_events)
            
            cv2.imshow("Geocussion-SP Input Viewer", combined_image)
            
            # ã‚­ãƒ¼å…¥åŠ›å‡¦ç†ï¼ˆDualViewerã®åŸºæœ¬æ©Ÿèƒ½ + è¡çªæ¤œå‡ºæ©Ÿèƒ½ï¼‰
            key = cv2.waitKey(1) & 0xFF
            
            # æ—¢å­˜ã®ã‚­ãƒ¼å‡¦ç†
            if key == ord('q') or key == 27:  # Q or ESC
                return False
            elif key == ord('f'):  # Toggle filter
                self.enable_filter = not self.enable_filter
                print(f"Depth filter: {'Enabled' if self.enable_filter else 'Disabled'}")
            elif key == ord('r') and self.depth_filter is not None:  # Reset filter
                self.depth_filter.reset_temporal_history()
                print("Filter history reset")
            elif key == ord('h'):  # Toggle hand detection
                self.enable_hand_detection = not self.enable_hand_detection
                print(f"Hand detection: {'Enabled' if self.enable_hand_detection else 'Disabled'}")
            elif key == ord('t') and self.enable_hand_detection:  # Toggle tracking
                self.enable_tracking = not self.enable_tracking
                print(f"Hand tracking: {'Enabled' if self.enable_tracking else 'Disabled'}")
            elif key == ord('y') and self.tracker is not None:  # Reset tracker
                self.tracker.reset()
                print("Hand tracker reset")
            
            # è¡çªæ¤œå‡ºã®ã‚­ãƒ¼å‡¦ç†
            else:
                # è¡çªæ¤œå‡ºã®ã‚­ãƒ¼å‡¦ç†ã‚’ç›´æ¥å®Ÿè£…
                if key == ord('m') or key == ord('M'):
                    self.enable_mesh_generation = not self.enable_mesh_generation
                    status = "æœ‰åŠ¹" if self.enable_mesh_generation else "ç„¡åŠ¹"
                    print(f"ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ: {status}")
                elif key == ord('c') or key == ord('C'):
                    self.enable_collision_detection = not self.enable_collision_detection
                    status = "æœ‰åŠ¹" if self.enable_collision_detection else "ç„¡åŠ¹"
                    print(f"è¡çªæ¤œå‡º: {status}")
                elif key == ord('v') or key == ord('V'):
                    self.enable_collision_visualization = not self.enable_collision_visualization
                    status = "æœ‰åŠ¹" if self.enable_collision_visualization else "ç„¡åŠ¹"
                    print(f"è¡çªå¯è¦–åŒ–: {status}")
                elif key == ord('n') or key == ord('N'):
                    print("ãƒ¡ãƒƒã‚·ãƒ¥ã‚’å¼·åˆ¶æ›´æ–°ä¸­...")
                    self._force_mesh_update()
                elif key == ord('+') or key == ord('='):
                    self.sphere_radius = min(self.sphere_radius + 0.01, 0.2)
                    print(f"çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
                elif key == ord('-') or key == ord('_'):
                    self.sphere_radius = max(self.sphere_radius - 0.01, 0.01)
                    print(f"çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
                elif key == ord('p') or key == ord('P'):
                    self._print_performance_stats()
            
            return True
            
        except Exception as e:
            print(f"RGB display error: {e}")
            return True

    def _draw_collision_info(self, image: np.ndarray, collision_events: list) -> None:
        """è¡çªæƒ…å ±ã‚’RGBç”»åƒã«æç”»"""
        if not collision_events:
            return
            
        # è¡çªã‚¤ãƒ™ãƒ³ãƒˆè¡¨ç¤º
        cv2.putText(image, f"COLLISION DETECTED! ({len(collision_events)} events)", 
                   (10, image.shape[0] - 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)
        
        # éŸ³éŸ¿å†ç”Ÿè¡¨ç¤º
        if self.enable_audio_synthesis and self.audio_enabled:
            cv2.putText(image, f"PLAYING AUDIO ({self.audio_instrument.value})", 
                       (10, image.shape[0] - 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
    
    def _draw_collision_performance_info(self, image: np.ndarray, collision_events: list) -> None:
        """è¡çªæ¤œå‡ºãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’æç”»"""
        if not hasattr(self, 'perf_stats'):
            return
            
        # å³å´ã«è¡çªæ¤œå‡ºæƒ…å ±ã‚’æç”»
        info_lines = [
            f"Mesh: {self.perf_stats.get('mesh_generation_time', 0):.1f}ms",
            f"Collision: {self.perf_stats.get('collision_detection_time', 0):.1f}ms",
            f"Audio: {self.perf_stats.get('audio_synthesis_time', 0):.1f}ms",
            f"Events: {len(collision_events)}",
            f"Sphere R: {self.sphere_radius*100:.1f}cm"
        ]
        
        # ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æƒ…å ±
        if self.pointcloud_converter:
            voxel_stats = self.pointcloud_converter.get_performance_stats()
            if voxel_stats.get('voxel_downsampling_enabled', False):
                ratio = voxel_stats.get('last_downsampling_ratio', 0)
                voxel_size = voxel_stats.get('current_voxel_size_mm', 0)
                info_lines.append(f"Voxel: {ratio*100:.0f}% @ {voxel_size:.1f}mm")
            else:
                info_lines.append("Voxel: OFF")
        
        if self.current_mesh:
            info_lines.append(f"Triangles: {self.current_mesh.num_triangles}")
        
        if self.current_collision_points:
            info_lines.append(f"Contacts: {len(self.current_collision_points)}")
        
        # å³å´ã«æç”»
        x_offset = image.shape[1] - 200
        y_offset = 30
        for i, line in enumerate(info_lines):
            cv2.putText(image, line, (x_offset, y_offset + i * 25), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)

    def run(self):
        """ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚’å®Ÿè¡Œ"""
        if self.headless_mode:
            self.run_headless()
        else:
            # è¦ªã‚¯ãƒ©ã‚¹ã®run()ã‚’å‘¼ã³å‡ºã—
            super().run()
    
    def run_headless(self):
        """ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œï¼ˆGUIç„¡åŠ¹åŒ–ã§FPSæ¸¬å®šç‰¹åŒ–ï¼‰"""
        import time
        
        print("\\nğŸ–¥ï¸  ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰é–‹å§‹ - GUIç„¡åŠ¹åŒ–ã«ã‚ˆã‚‹FPSæœ€é©åŒ–")
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {self.headless_duration}ç§’")
        print("=" * 50)
        
        # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹å°‚ç”¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        print("ğŸ”§ ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ç”¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–ä¸­...")
        self._initialize_headless_components()
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–ç¢ºèª
        print("ğŸ” ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–çŠ¶æ³:")
        print(f"   Camera: {'âœ…' if self.camera else 'âŒ (ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨)'}")
        print(f"   Hands2D: {'âœ…' if hasattr(self, 'hands_2d') and self.hands_2d else 'âŒ'}")
        print(f"   Projector3D: {'âœ…' if hasattr(self, 'projector_3d') and self.projector_3d else 'âŒ (ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹å¯¾å¿œ)'}")
        print(f"   Tracker: {'âœ…' if hasattr(self, 'tracker') and self.tracker else 'âŒ (ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹å¯¾å¿œ)'}")
        print(f"   PointcloudConverter: {'âœ…' if hasattr(self, 'pointcloud_converter') and self.pointcloud_converter else 'âŒ (ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿)'}")
        
        print("\\nğŸ¯ ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†é–‹å§‹...")
        print("=" * 50)
        
        start_time = time.time()
        frame_count = 0
        total_pipeline_time = 0.0
        total_collision_events = 0
        
        # FPSã®çµ±è¨ˆ
        fps_samples = []
        frame_times = []
        last_report_time = start_time
        
        try:
            while True:
                frame_start = time.time()
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆGUIç„¡ã—ï¼‰
                success = self._process_frame_headless()
                
                frame_end = time.time()
                frame_time = frame_end - frame_start
                frame_times.append(frame_time)
                
                if success:
                    frame_count += 1
                    total_pipeline_time += frame_time
                    
                    # FPSè¨ˆç®—
                    current_fps = 1.0 / frame_time if frame_time > 0 else 0
                    fps_samples.append(current_fps)
                    
                    # 5ç§’é–“éš”ã§çµ±è¨ˆè¡¨ç¤º
                    elapsed = frame_end - start_time
                    if elapsed - (last_report_time - start_time) >= 5.0:
                        avg_fps = sum(fps_samples[-100:]) / len(fps_samples[-100:]) if fps_samples else 0
                        print(f"ğŸ“Š [{elapsed:.1f}s] ãƒ•ãƒ¬ãƒ¼ãƒ : {frame_count}, å¹³å‡FPS: {avg_fps:.1f}, ç¾åœ¨FPS: {current_fps:.1f}")
                        last_report_time = frame_end
                
                # å®Ÿè¡Œæ™‚é–“ãƒã‚§ãƒƒã‚¯
                if time.time() - start_time >= self.headless_duration:
                    break
                    
        except KeyboardInterrupt:
            print("\\nâ¹ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ä¸­æ–­")
        except Exception as e:
            print(f"\\nâŒ ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
        
        # çµ±è¨ˆè¨ˆç®—
        execution_time = time.time() - start_time
        avg_fps = frame_count / execution_time if execution_time > 0 else 0
        avg_frame_time = total_pipeline_time / frame_count if frame_count > 0 else 0
        max_fps = max(fps_samples) if fps_samples else 0
        min_fps = min(fps_samples) if fps_samples else 0
        
        # çµæœè¡¨ç¤º
        print("\\n" + "=" * 50)
        print("ğŸ ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ å®Ÿè¡Œçµæœ")
        print("=" * 50)
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {execution_time:.1f}ç§’")
        print(f"ğŸ¬ ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frame_count}")
        print(f"ğŸš€ å¹³å‡FPS: {avg_fps:.1f}")
        print(f"âš¡ å¹³å‡ãƒ•ãƒ¬ãƒ¼ãƒ æ™‚é–“: {avg_frame_time*1000:.1f}ms")
        print(f"ğŸ“ˆ æœ€å¤§FPS: {max_fps:.1f}")
        print(f"ğŸ“‰ æœ€å°FPS: {min_fps:.1f}")
        print(f"âš™ï¸  å¹³å‡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ™‚é–“: {total_pipeline_time/frame_count*1000:.1f}ms" if frame_count > 0 else "âš™ï¸  ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ™‚é–“: N/A")
        print(f"ğŸµ è¡çªã‚¤ãƒ™ãƒ³ãƒˆç·æ•°: {self.perf_stats.get('collision_events_count', 0)}")
        print(f"ğŸ”Š éŸ³éŸ¿ãƒãƒ¼ãƒˆç·æ•°: {getattr(self, 'audio_notes_generated', 0)}")
        
        # ROI ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°çµ±è¨ˆå‡ºåŠ›
        if hasattr(self.hands_2d, 'get_roi_tracking_stats'):
            roi_stats = self.hands_2d.get_roi_tracking_stats()
            print(f"\nğŸ“Š ROI ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°çµ±è¨ˆ:")
            print(f"   MediaPipe å®Ÿè¡Œ: {roi_stats.mediapipe_executions}/{roi_stats.total_frames}")
            print(f"   ã‚¹ã‚­ãƒƒãƒ—ç‡: {roi_stats.skip_ratio*100:.1f}%")
            print(f"   ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æˆåŠŸç‡: {roi_stats.success_rate*100:.1f}%")
            if roi_stats.mediapipe_executions > 0:
                avg_mediapipe_time = roi_stats.total_mediapipe_time_ms / roi_stats.mediapipe_executions
                print(f"   å¹³å‡MediaPipeæ™‚é–“: {avg_mediapipe_time:.1f}ms")
            if roi_stats.tracking_successes > 0:
                avg_tracking_time = roi_stats.total_tracking_time_ms / roi_stats.tracking_successes
                print(f"   å¹³å‡ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æ™‚é–“: {avg_tracking_time:.1f}ms")
        
        print()

    def _initialize_headless_components(self):
        """ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹å°‚ç”¨ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–"""
        # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã§ã¯å¿…è¦æœ€å°é™ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã¿åˆæœŸåŒ–
        try:
            # 3D projectorï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ç”¨ç°¡æ˜“ç‰ˆï¼‰
            if not hasattr(self, 'projector_3d') or not self.projector_3d:
                print("ğŸ”§ ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ç”¨ 3D projector ã‚’åˆæœŸåŒ–ä¸­...")
                self.projector_3d = None  # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ã§ã¯ç„¡åŠ¹åŒ–
                
            # Hand trackerï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ç”¨ç°¡æ˜“ç‰ˆï¼‰
            if not hasattr(self, 'tracker') or not self.tracker:
                print("ğŸ”§ ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ç”¨ tracker ã‚’åˆæœŸåŒ–ä¸­...")
                self.tracker = None  # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ã§ã¯ç„¡åŠ¹åŒ–
                
            # PointCloud converterï¼ˆãƒ¢ãƒƒã‚¯å¯¾å¿œï¼‰
            if not hasattr(self, 'pointcloud_converter') or not self.pointcloud_converter:
                print("ğŸ”§ ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ç”¨ pointcloud converter ã‚’åˆæœŸåŒ–ä¸­...")
                self.pointcloud_converter = None  # ãƒ¢ãƒƒã‚¯ç‚¹ç¾¤ã‚’ä½¿ç”¨
                
            print("âœ… ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ç”¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
            
        except Exception as e:
            print(f"âš ï¸  ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ç”¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–è­¦å‘Š: {e}")
            # ã‚¨ãƒ©ãƒ¼ã§ã‚‚ç¶™ç¶šï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ã§ã¯éè‡´å‘½çš„ï¼‰

    def _process_frame_headless(self) -> bool:
        """ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹å°‚ç”¨ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆGUIæç”»ãªã—ï¼‰"""
        # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ç”¨ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        if not self.camera:
            # ãƒ¢ãƒƒã‚¯æ·±åº¦ãƒ»ã‚«ãƒ©ãƒ¼ç”»åƒç”Ÿæˆ
            import numpy as np
            depth_image = np.random.randint(500, 2000, (240, 424), dtype=np.uint16)
            color_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            frame_data = (depth_image, color_image)
            
        else:
            # å®Ÿã‚«ãƒ¡ãƒ©ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—
            try:
                frame_data = self.camera.get_frame()
                if frame_data is None:
                    return False
                
                depth_image, color_image = frame_data
                if depth_image is None:
                    return False
                    
            except Exception as e:
                print(f"âŒ ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                return False
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        depth_image, color_image = frame_data
        if depth_image is None:
            return False
            
        self.frame_counter += 1
        collision_events = []
        
        try:
            # æ‰‹æ¤œå‡ºå‡¦ç†ï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ã§ã¯ç°¡æ˜“ç‰ˆï¼‰
            if self.enable_hand_detection and hasattr(self, 'hands_2d') and self.hands_2d and not getattr(self, 'pure_headless_mode', False):
                try:
                    # MediaPipe 2Dæ¤œå‡ºï¼ˆæ­£ã—ã„ãƒ¡ã‚½ãƒƒãƒ‰åã‚’ä½¿ç”¨ï¼‰
                    self.current_hands_2d = self.hands_2d.detect_hands(color_image) if color_image is not None else []
                except Exception as e:
                    # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ã§ã¯æ‰‹æ¤œå‡ºã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
                    self.current_hands_2d = []
                
                # 3DæŠ•å½±ã¯ç„¡åŠ¹åŒ–ï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ï¼‰
                self.current_tracked_hands = []
            else:
                # ç´”ç²‹ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã¾ãŸã¯æ‰‹æ¤œå‡ºç„¡åŠ¹
                self.current_hands_2d = []
                self.current_tracked_hands = []
            
            # ç‚¹ç¾¤ç”Ÿæˆï¼ˆãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ï¼‰
            points_3d = None
            if self.enable_mesh_generation:
                # ãƒ¢ãƒƒã‚¯ç‚¹ç¾¤ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
                import numpy as np
                mock_points = np.random.rand(5000, 3).astype(np.float32)  # 5000ç‚¹ã®ãƒ¢ãƒƒã‚¯ç‚¹ç¾¤
                mock_points[:, 2] += 0.5  # Zåº§æ¨™ã‚’ã‚«ãƒ¡ãƒ©ã‹ã‚‰é›¢ã™
                points_3d = mock_points
                
            # ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°åˆ¤å®šã¨ç”Ÿæˆ
            if self.enable_mesh_generation and points_3d is not None:
                should_update = self._should_update_mesh()
                if should_update:
                    import time
                    mesh_start_time = time.time()
                    self._update_terrain_mesh(points_3d)
                    mesh_time = time.time() - mesh_start_time
                    self.perf_stats['mesh_generation_time'] += mesh_time
                    self.last_mesh_update = self.frame_counter
            
            # è¡çªæ¤œå‡ºï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ã§ã¯ç°¡æ˜“ç‰ˆï¼‰
            if self.enable_collision_detection and self.current_tracked_hands and hasattr(self, 'current_mesh') and self.current_mesh:
                try:
                    import time
                    collision_start_time = time.time()
                    collision_events = self._detect_collisions(self.current_tracked_hands)
                    collision_time = time.time() - collision_start_time
                    self.perf_stats['collision_detection_time'] += collision_time
                    self.perf_stats['collision_events_count'] += len(collision_events)
                except Exception:
                    # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ã§ã¯è¡çªæ¤œå‡ºã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
                    collision_events = []
            
            # éŸ³éŸ¿ç”Ÿæˆï¼ˆéŸ³ã¯å‡ºåŠ›ã•ã‚Œã‚‹ï¼‰
            if self.enable_audio_synthesis and collision_events:
                try:
                    import time
                    audio_start_time = time.time()
                    self._generate_audio(collision_events)
                    audio_time = time.time() - audio_start_time
                    self.perf_stats['audio_synthesis_time'] += audio_time
                except Exception:
                    # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ã§ã¯éŸ³éŸ¿ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
                    pass
            
            self.perf_stats['frame_count'] += 1
            
            # å‡¦ç†æ™‚é–“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒ¢ãƒƒã‚¯ã®å ´åˆï¼‰
            if not self.camera:
                # å®Ÿéš›ã®å‡¦ç†æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                import time as time_module
                processing_delay = 0.015  # 15ms å‡¦ç†æ™‚é–“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                time_module.sleep(processing_delay)
            
            return True
            
        except Exception as e:
            # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ã§ã¯ã‚¨ãƒ©ãƒ¼ã§ã‚‚ç¶™ç¶š
            if self.frame_counter <= 3:
                print(f"âš ï¸  ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†è­¦å‘Š: {e}")
            return True  # ã‚¨ãƒ©ãƒ¼ã§ã‚‚ç¶™ç¶š
    
    def _should_update_mesh(self) -> bool:
        """ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°åˆ¤å®š"""
        frames_since_update = self.frame_counter - self.last_mesh_update
        
        # å¼·åˆ¶æ›´æ–°è¦æ±‚
        if hasattr(self, 'force_mesh_update_requested') and self.force_mesh_update_requested:
            self.force_mesh_update_requested = False
            return True
            
        # æ‰‹ãŒæ¤œå‡ºã•ã‚Œã¦ã„ãªã„å ´åˆã¯é€šå¸¸é–“éš”ã§æ›´æ–°
        if not self.current_tracked_hands:
            return frames_since_update >= self.mesh_update_interval
        
        # æ‰‹ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã‚‹å ´åˆã¯æ›´æ–°é–“éš”ã‚’é•·ãã™ã‚‹
        # ãŸã ã—ã€æœ€å¤§ã‚¹ã‚­ãƒƒãƒ—ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’è¶…ãˆãŸã‚‰å¼·åˆ¶æ›´æ–°
        return frames_since_update >= getattr(self, 'max_mesh_skip_frames', 60)

    def _generate_traditional_mesh(self, points_3d):
        """å¾“æ¥æ–¹å¼ã§ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰"""
        try:
            import time
            
            # 1. ç‚¹ç¾¤æŠ•å½±
            projection_start = time.perf_counter()
            height_map = self.projector.project_points(points_3d)
            projection_time = (time.perf_counter() - projection_start) * 1000
            
            # 2. Delaunayä¸‰è§’åˆ†å‰²
            triangulation_start = time.perf_counter()
            triangle_mesh = self.triangulator.triangulate_heightmap(height_map)
            triangulation_time = (time.perf_counter() - triangulation_start) * 1000
            
            if triangle_mesh is None or triangle_mesh.num_triangles == 0:
                return None
            
            # 3. ãƒ¡ãƒƒã‚·ãƒ¥ç°¡ç•¥åŒ–
            simplification_start = time.perf_counter()
            simplified_mesh = self.simplifier.simplify_mesh(triangle_mesh)
            simplification_time = (time.perf_counter() - simplification_start) * 1000
            
            if simplified_mesh is None:
                simplified_mesh = triangle_mesh
            
            # ãƒ‡ãƒãƒƒã‚°ç”¨æ™‚é–“æ¸¬å®šå‡ºåŠ›
            if hasattr(self, 'frame_counter') and self.frame_counter % 50 == 0:
                total_mesh_time = projection_time + triangulation_time + simplification_time
                print(f"[TRADITIONAL-MESH] Projection: {projection_time:.1f}ms, Triangulation: {triangulation_time:.1f}ms, Simplification: {simplification_time:.1f}ms (Total: {total_mesh_time:.1f}ms)")
            
            return simplified_mesh
            
        except Exception as e:
            print(f"å¾“æ¥æ–¹å¼ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="Geocussion-SP å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆãƒ‡ãƒ¢ï¼ˆComplete Pipelineï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
    python demo_collision_detection.py                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼ˆä½è§£åƒåº¦424x240ï¼‰
    python demo_collision_detection.py --force-high-resolution # é«˜è§£åƒåº¦848x480ï¼ˆä½FPSæ³¨æ„ï¼‰
    python demo_collision_detection.py --depth-width 640 --depth-height 360 # ã‚«ã‚¹ã‚¿ãƒ è§£åƒåº¦
    python demo_collision_detection.py --no-collision     # è¡çªæ¤œå‡ºç„¡åŠ¹
    python demo_collision_detection.py --no-mesh          # ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆç„¡åŠ¹
    python demo_collision_detection.py --no-audio         # éŸ³éŸ¿åˆæˆç„¡åŠ¹
    python demo_collision_detection.py --sphere-radius 0.08 # çƒåŠå¾„8cm
    python demo_collision_detection.py --audio-instrument BELL # ãƒ™ãƒ«æ¥½å™¨

æ“ä½œæ–¹æ³•:
    RGB Window:
        Q/ESC: çµ‚äº†
        F: æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿ ON/OFF
        H: æ‰‹æ¤œå‡º ON/OFF
        T: ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚° ON/OFF
        
        M: ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ ON/OFF
        C: è¡çªæ¤œå‡º ON/OFF
        V: è¡çªå¯è¦–åŒ– ON/OFF
        N: ãƒ¡ãƒƒã‚·ãƒ¥å¼·åˆ¶æ›´æ–°
        +/-: çƒåŠå¾„èª¿æ•´
        P: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆè¡¨ç¤º
        
        A: éŸ³éŸ¿åˆæˆ ON/OFF
        S: éŸ³éšåˆ‡ã‚Šæ›¿ãˆ
        I: æ¥½å™¨åˆ‡ã‚Šæ›¿ãˆ
        1/2: éŸ³é‡èª¿æ•´
        R: éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³å†èµ·å‹•
        Q: å…¨éŸ³å£°åœæ­¢
    
    3D Viewer:
        ãƒã‚¦ã‚¹: å›è»¢/ãƒ‘ãƒ³/ã‚ºãƒ¼ãƒ 
        R: è¦–ç‚¹ãƒªã‚»ãƒƒãƒˆ
        """
    )
    
    # åŸºæœ¬è¨­å®š
    parser.add_argument('--no-filter', action='store_true', help='æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿ã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--no-hand-detection', action='store_true', help='æ‰‹æ¤œå‡ºã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--no-tracking', action='store_true', help='ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--gpu-mediapipe', action='store_true', help='MediaPipeã§GPUã‚’ä½¿ç”¨')
    
    # è¡çªæ¤œå‡ºè¨­å®š
    parser.add_argument('--no-mesh', action='store_true', help='ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--no-collision', action='store_true', help='è¡çªæ¤œå‡ºã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--no-collision-viz', action='store_true', help='è¡çªå¯è¦–åŒ–ã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--mesh-interval', type=int, default=15, help='ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼‰ â€»ä½è§£åƒåº¦æ™‚ã¯15frameæ¨å¥¨')
    parser.add_argument('--sphere-radius', type=float, default=0.05, help='è¡çªæ¤œå‡ºçƒã®åŠå¾„ï¼ˆãƒ¡ãƒ¼ãƒˆãƒ«ï¼‰')
    parser.add_argument('--max-mesh-skip', type=int, default=60, help='æ‰‹ãŒå†™ã£ã¦ã„ã‚‹å ´åˆã§ã‚‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°çµŒéã§å¼·åˆ¶æ›´æ–°')
    
    # éŸ³éŸ¿ç”Ÿæˆè¨­å®š
    parser.add_argument('--no-audio', action='store_true', help='éŸ³éŸ¿åˆæˆã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--audio-scale', type=str, default='PENTATONIC', 
                       choices=['PENTATONIC', 'MAJOR', 'MINOR', 'DORIAN', 'MIXOLYDIAN', 'CHROMATIC', 'BLUES'],
                       help='éŸ³éšã®ç¨®é¡')
    parser.add_argument('--audio-instrument', type=str, default='MARIMBA',
                       choices=['MARIMBA', 'SYNTH_PAD', 'BELL', 'PLUCK', 'BASS', 'LEAD', 'PERCUSSION', 'AMBIENT'],
                       help='æ¥½å™¨ã®ç¨®é¡')
    parser.add_argument('--audio-polyphony', type=int, default=16, help='æœ€å¤§åŒæ™‚ç™ºéŸ³æ•°')
    parser.add_argument('--audio-volume', type=float, default=0.7, help='ãƒã‚¹ã‚¿ãƒ¼éŸ³é‡ (0.0-1.0)')
    
    # æ‰‹æ¤œå‡ºè¨­å®š
    parser.add_argument('--min-confidence', type=float, default=0.7, help='æœ€å°æ¤œå‡ºä¿¡é ¼åº¦ (0.0-1.0)')
    
    # è¡¨ç¤ºè¨­å®š
    parser.add_argument('--update-interval', type=int, default=3, help='ç‚¹ç¾¤æ›´æ–°é–“éš”ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼‰')
    parser.add_argument('--point-size', type=float, default=2.0, help='ç‚¹ç¾¤ã®ç‚¹ã‚µã‚¤ã‚º')
    parser.add_argument('--high-resolution', action='store_true', help='é«˜è§£åƒåº¦è¡¨ç¤º (1280x720)')
    
    # è§£åƒåº¦æœ€é©åŒ–è¨­å®šï¼ˆãƒ—ãƒ­ä¿®æ­£ï¼šFPSå‘ä¸Šã®ãŸã‚ã®ä½è§£åƒåº¦ãƒ¢ãƒ¼ãƒ‰ï¼‰
    parser.add_argument('--low-resolution', action='store_true', default=True, help='ä½è§£åƒåº¦ãƒ¢ãƒ¼ãƒ‰ (424x240) â€»FPSå‘ä¸Šã®ãŸã‚æ—¢å®šON')
    parser.add_argument('--force-high-resolution', action='store_true', help='å¼·åˆ¶çš„ã«é«˜è§£åƒåº¦ (848x480) ã‚’ä½¿ç”¨ â€»ä½FPSæ³¨æ„')
    parser.add_argument('--depth-width', type=int, help='æ·±åº¦è§£åƒåº¦å¹…ã‚’ç›´æ¥æŒ‡å®š')
    parser.add_argument('--depth-height', type=int, help='æ·±åº¦è§£åƒåº¦é«˜ã•ã‚’ç›´æ¥æŒ‡å®š')
    
    # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
    parser.add_argument('--window-width', type=int, default=640, help='RGBã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®å¹…')
    parser.add_argument('--window-height', type=int, default=480, help='RGBã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®é«˜ã•')
    
    # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰
    parser.add_argument('--test', action='store_true', help='ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ')
    
    # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ï¼ˆFPSå‘ä¸Šã®ãŸã‚ã®GUIç„¡åŠ¹åŒ–ï¼‰
    parser.add_argument('--headless', action='store_true', help='ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ï¼ˆGUIç„¡åŠ¹ï¼‰â€»FPSå¤§å¹…å‘ä¸Š')
    parser.add_argument('--headless-duration', type=int, default=30, help='ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰')
    parser.add_argument('--headless-pure', action='store_true', help='ç´”ç²‹ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ï¼ˆæ‰‹æ¤œå‡ºç„¡åŠ¹ã€æœ€å¤§FPSæ¸¬å®šï¼‰')
    
    args = parser.parse_args()
    
    # è¨­å®šå€¤æ¤œè¨¼
    if args.min_confidence < 0.0 or args.min_confidence > 1.0:
        print("Error: --min-confidence must be between 0.0 and 1.0")
        return 1
    
    if args.sphere_radius <= 0.0 or args.sphere_radius > 0.5:
        print("Error: --sphere-radius must be between 0.0 and 0.5")
        return 1
    
    if args.audio_polyphony < 1 or args.audio_polyphony > 64:
        print("Error: --audio-polyphony must be between 1 and 64")
        return 1
    
    if args.audio_volume < 0.0 or args.audio_volume > 1.0:
        print("Error: --audio-volume must be between 0.0 and 1.0")
        return 1
    
    # è§£åƒåº¦è¨­å®šã®æ±ºå®šï¼ˆãƒ—ãƒ­ä¿®æ­£ï¼šç¢ºå®Ÿãªæœ€é©åŒ–ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    depth_width, depth_height = None, None
    if args.depth_width and args.depth_height:
        # ç›´æ¥æŒ‡å®šãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’å„ªå…ˆ
        depth_width, depth_height = args.depth_width, args.depth_height
    elif args.force_high_resolution:
        # å¼·åˆ¶é«˜è§£åƒåº¦ãƒ¢ãƒ¼ãƒ‰
        depth_width, depth_height = 848, 480
    elif args.low_resolution:
        # ä½è§£åƒåº¦ãƒ¢ãƒ¼ãƒ‰ï¼ˆæ—¢å®šï¼‰
        depth_width, depth_height = 424, 240
    # ãã‚Œä»¥å¤–ã¯Noneï¼ˆOrbbecSDKã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    
    # è§£åƒåº¦ã«ã‚ˆã‚‹ç‚¹ç¾¤æ•°ã®äºˆæ¸¬
    if depth_width and depth_height:
        estimated_points = depth_width * depth_height
        if estimated_points > 300000:  # 30ä¸‡ç‚¹ä»¥ä¸Š
            print(f"âš ï¸  Warning: High resolution ({depth_width}x{depth_height}) may cause low FPS")
            print(f"   Estimated points: {estimated_points:,}")
            print(f"   Consider using --low-resolution for better performance")
        else:
            print(f"âœ… Optimized resolution: {depth_width}x{depth_height} (~{estimated_points:,} points)")
    else:
        print("ğŸ“ Using camera default resolution")
    
    # éŸ³éšã¨æ¥½å™¨ã®åˆ—æŒ™å€¤å¤‰æ›
    try:
        audio_scale = ScaleType[args.audio_scale]
        audio_instrument = InstrumentType[args.audio_instrument]
    except KeyError as e:
        print(f"Error: Invalid audio parameter: {e}")
        return 1
    
    # æƒ…å ±è¡¨ç¤º
    print("=" * 70)
    print("Geocussion-SP å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆãƒ‡ãƒ¢ï¼ˆComplete Pipelineï¼‰")
    print("=" * 70)
    
    # è§£åƒåº¦æœ€é©åŒ–æƒ…å ±ã‚’æœ€åˆã«è¡¨ç¤ºï¼ˆé‡è¦æ€§ã‚’å¼·èª¿ï¼‰
    if depth_width and depth_height:
        resolution_mode = "ä½è§£åƒåº¦" if depth_width <= 424 else "é«˜è§£åƒåº¦"
        points_estimate = depth_width * depth_height
        print(f"ğŸš€ è§£åƒåº¦æœ€é©åŒ–: {resolution_mode} ({depth_width}x{depth_height})")
        print(f"   äºˆæƒ³ç‚¹ç¾¤æ•°: {points_estimate:,} points")
        fps_estimate = "25-30 FPS" if depth_width <= 424 else "5-15 FPS"
        print(f"   äºˆæƒ³FPS: {fps_estimate}")
    
    print(f"æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿: {'ç„¡åŠ¹' if args.no_filter else 'æœ‰åŠ¹'}")
    print(f"æ‰‹æ¤œå‡º: {'ç„¡åŠ¹' if args.no_hand_detection else 'æœ‰åŠ¹'}")
    print(f"ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ: {'ç„¡åŠ¹' if args.no_mesh else 'æœ‰åŠ¹'}")
    print(f"è¡çªæ¤œå‡º: {'ç„¡åŠ¹' if args.no_collision else 'æœ‰åŠ¹'}")
    if not args.no_collision:
        print(f"  - çƒåŠå¾„: {args.sphere_radius*100:.1f}cm")
        print(f"  - å¯è¦–åŒ–: {'ç„¡åŠ¹' if args.no_collision_viz else 'æœ‰åŠ¹'}")
    print(f"éŸ³éŸ¿åˆæˆ: {'ç„¡åŠ¹' if args.no_audio else 'æœ‰åŠ¹'}")
    if not args.no_audio:
        print(f"  - éŸ³éš: {audio_scale.value}")
        print(f"  - æ¥½å™¨: {audio_instrument.value}")
        print(f"  - ãƒãƒªãƒ•ã‚©ãƒ‹ãƒ¼: {args.audio_polyphony}")
        print(f"  - éŸ³é‡: {args.audio_volume:.1f}")
    
    # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰æƒ…å ±è¡¨ç¤º
    if args.headless:
        print(f"ğŸ–¥ï¸  ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰: æœ‰åŠ¹ï¼ˆGUIç„¡åŠ¹åŒ–ã§FPSå‘ä¸Šï¼‰")
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {args.headless_duration}ç§’")
        print(f"ğŸš€ äºˆæƒ³FPSå‘ä¸Š: +5-15 FPS (GUIè² è·å‰Šé™¤)")
    else:
        print(f"ğŸ–¥ï¸  è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰: GUIæœ‰åŠ¹")
    
    print("=" * 70)
    
    # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰
    if args.test:
        run_preprocessing_optimization_test()
        print("\n" + "=" * 70)
        run_headless_fps_comparison_test()
        return 0
    
    # è¨­å®šçµ±åˆã‚·ã‚¹ãƒ†ãƒ ã§ä½è§£åƒåº¦ãƒ¢ãƒ¼ãƒ‰ã‚’é©ç”¨ï¼ˆãƒ—ãƒ­ä¿®æ­£ï¼šä¸€å…ƒç®¡ç†ï¼‰
    config = get_config()
    config.input.enable_low_resolution_mode = (depth_width == 424 and depth_height == 240)
    config.input.depth_width = depth_width
    config.input.depth_height = depth_height
    
    # ä½è§£åƒåº¦æ™‚ã®æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è‡ªå‹•é©ç”¨
    if config.input.enable_low_resolution_mode:
        # ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”ã‚’æœ€é©åŒ–ï¼ˆæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿ï¼‰
        if args.mesh_interval == 15:  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å ´åˆ
            args.mesh_interval = 20  # ã•ã‚‰ã«é–“éš”ã‚’ç©ºã‘ã‚‹
        print(f"ğŸ”§ ä½è§£åƒåº¦æœ€é©åŒ–: ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”={args.mesh_interval}ãƒ•ãƒ¬ãƒ¼ãƒ ")
    else:
        # é«˜è§£åƒåº¦å¼·åˆ¶æ™‚ã®ç·Šæ€¥FPSæœ€é©åŒ–
        if depth_width and depth_height and (depth_width >= 848 or depth_height >= 480):
            print(f"ğŸš¨ é«˜è§£åƒåº¦ãƒ¢ãƒ¼ãƒ‰æ¤œå‡º: {depth_width}x{depth_height}")
            print(f"âš¡ ç·Šæ€¥FPSæœ€é©åŒ–ã‚’é©ç”¨ä¸­...")
            
            # ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”ã‚’å¤§å¹…å»¶é•·
            if args.mesh_interval <= 20:
                args.mesh_interval = 40  # 2å€ã«å»¶é•·
                print(f"ğŸ”§ ç·Šæ€¥æœ€é©åŒ–: ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”={args.mesh_interval}ãƒ•ãƒ¬ãƒ¼ãƒ  (40fé–“éš”)")
            
            # æœ€å¤§ã‚¹ã‚­ãƒƒãƒ—ãƒ•ãƒ¬ãƒ¼ãƒ ã‚‚å»¶é•·
            if args.max_mesh_skip <= 60:
                args.max_mesh_skip = 120  # 2å€ã«å»¶é•·
                print(f"ğŸ”§ ç·Šæ€¥æœ€é©åŒ–: æœ€å¤§ãƒ¡ãƒƒã‚·ãƒ¥ã‚¹ã‚­ãƒƒãƒ—={args.max_mesh_skip}ãƒ•ãƒ¬ãƒ¼ãƒ ")
            
            # è§£åƒåº¦ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
            config.input.enable_resolution_downsampling = True
            config.input.resolution_target_width = 424
            config.input.resolution_target_height = 240
            print(f"ğŸ”§ ç·Šæ€¥æœ€é©åŒ–: è§£åƒåº¦ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æœ‰åŠ¹ ({depth_width}x{depth_height} â†’ 424x240)")
                
            print(f"âš¡ é«˜è§£åƒåº¦ã§ã®äºˆæƒ³FPS: 8-15 FPS (æœ€é©åŒ–é©ç”¨æ¸ˆã¿)")
        elif depth_width and depth_height:
            print(f"ğŸ”§ ä¸­è§£åƒåº¦æœ€é©åŒ–: ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”={args.mesh_interval}ãƒ•ãƒ¬ãƒ¼ãƒ ")
    
    # CollisionDetectionViewerå®Ÿè¡Œ
    try:
        viewer = FullPipelineViewer(
            enable_filter=not args.no_filter,
            enable_hand_detection=not args.no_hand_detection,
                enable_tracking=not args.no_tracking,
                enable_mesh_generation=not args.no_mesh,
                enable_collision_detection=not args.no_collision,
                enable_collision_visualization=not args.no_collision_viz,
                enable_audio_synthesis=not args.no_audio,
                update_interval=args.update_interval,
                point_size=args.point_size,
                rgb_window_size=(args.window_width, args.window_height),
                min_detection_confidence=args.min_confidence,
                use_gpu_mediapipe=args.gpu_mediapipe,
                mesh_update_interval=args.mesh_interval,
                sphere_radius=args.sphere_radius,
                audio_scale=audio_scale,
                audio_instrument=audio_instrument,
                audio_polyphony=args.audio_polyphony,
            audio_master_volume=args.audio_volume,
            max_mesh_skip_frames=args.max_mesh_skip,
            headless_mode=args.headless,
            headless_duration=args.headless_duration,
            pure_headless_mode=args.headless_pure
        )
        
        print("\nå…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚’é–‹å§‹ã—ã¾ã™...")
        print("=" * 70)
        
        # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰æ™‚ã¯ç›´æ¥å®Ÿè¡Œ
        if args.headless:
            print("ğŸ–¥ï¸  ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰: ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            print("ğŸ¯ ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹FPSæ¸¬å®šã‚’é–‹å§‹ã—ã¾ã™...")
            viewer.run()
            print("\nãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ãŒæ­£å¸¸ã«çµ‚äº†ã—ã¾ã—ãŸ")
            return 0
        
        print("ã‚«ãƒ¡ãƒ©ã‚’åˆæœŸåŒ–ä¸­...")
        # ã‚«ãƒ¡ãƒ©ã‚’æœ€é©åŒ–ã•ã‚ŒãŸè§£åƒåº¦ã§åˆæœŸåŒ–ï¼ˆãƒ—ãƒ­ä¿®æ­£ï¼šç¢ºå®Ÿãªé«˜é€ŸåŒ–ï¼‰
        if depth_width and depth_height:
            print(f"   æ·±åº¦è§£åƒåº¦: {depth_width}x{depth_height} ã«è¨­å®š")
        viewer.camera = OrbbecCamera(
            enable_color=True,
            depth_width=depth_width,
            depth_height=depth_height
        )
        
        # DualViewerã®åˆæœŸåŒ–ã‚’å®Ÿè¡Œ
        if not viewer.initialize():
            print("Failed to initialize dual viewer")
            return 1
        
        viewer.run()
        
        print("\nãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ãŒæ­£å¸¸ã«çµ‚äº†ã—ã¾ã—ãŸ")
        return 0
        
    except KeyboardInterrupt:
        print("\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        return 0
    except Exception as e:
        print(f"\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 