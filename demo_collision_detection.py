#!/usr/bin/env python3
"""
Geocussion-SP ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¢ï¼ˆè¡çªæ¤œå‡ºçµ±åˆç‰ˆï¼‰
ç‚¹ç¾¤â†’ãƒ¡ãƒƒã‚·ãƒ¥â†’è¡çªæ¤œå‡ºâ†’éŸ³éŸ¿åˆæˆã®å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè£…

ä½¿ç”¨æ–¹æ³•:
  python3 demo_collision_detection.py                 # é€šå¸¸å®Ÿè¡Œ
  python3 demo_collision_detection.py --no-audio      # éŸ³éŸ¿ç„¡åŠ¹åŒ–
  python3 demo_collision_detection.py --test          # ãƒ—ãƒªãƒ—ãƒ­ã‚»ãƒƒã‚·ãƒ³ã‚°æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
"""

import os
import sys
import time
import argparse
import logging
from typing import Optional, List, Dict, Tuple, Any, Union
from dataclasses import dataclass
from pathlib import Path
import signal
import numpy as np
import cv2

# Constants
DEFAULT_SPHERE_RADIUS = 0.05  # 5cm
DEFAULT_MESH_UPDATE_INTERVAL = 15
DEFAULT_MAX_MESH_SKIP_FRAMES = 60
DEFAULT_AUDIO_COOLDOWN_TIME = 0.3  # 300ms (debounce)
DEFAULT_VOXEL_SIZE = 0.005  # 5mm
DEFAULT_AUDIO_POLYPHONY = 16
DEFAULT_MASTER_VOLUME = 0.7
LOW_RESOLUTION = (424, 240)
HIGH_RESOLUTION = (848, 480)
ESTIMATED_HIGH_RES_POINTS = 300000

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# =============================================================================
# å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨ãƒ¢ãƒƒã‚¯ã®å®šç¾©
# =============================================================================

# OrbbecSDKã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
HAS_ORBBEC_SDK = False
try:
    # type: ignore[import]
    from pyorbbecsdk import Pipeline, FrameSet, Config, OBSensorType, OBError, OBFormat  # type: ignore  # pylint: disable=import-error
    HAS_ORBBEC_SDK = True
    logger.info("OrbbecSDK is available")
except ImportError:
    logger.warning("OrbbecSDK is not available. Using mock implementations.")
    # Mock classes
    class Pipeline:
        def __init__(self): pass
        def start(self, config): pass
        def stop(self): pass
        def wait_for_frames(self, timeout): return None
    
    class FrameSet:
        def get_depth_frame(self): return None
        def get_color_frame(self): return None
    
    class Config:
        def enable_stream(self, stream, width, height, fmt, fps): pass
    
    class OBSensorType:
        DEPTH = "depth"
        COLOR = "color"
    
    class OBError(Exception):
        pass
    
    class OBFormat:
        RGB = "rgb"
        BGR = "bgr"
        MJPG = "mjpg"

# MediaPipeã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
HAS_MEDIAPIPE = False
try:
    import mediapipe as mp
    HAS_MEDIAPIPE = True
    logger.info("MediaPipe is available")
except ImportError:
    logger.warning("MediaPipe is not available. Hand detection will be disabled.")

# Open3Dã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
HAS_OPEN3D = False
try:
    import open3d as o3d
    HAS_OPEN3D = True
except ImportError:
    logger.warning("Open3D is not available. 3D visualization will be disabled.")

# éŸ³éŸ¿ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
HAS_AUDIO = False
try:
    import pyo
    HAS_AUDIO = True
    logger.info("Pyo audio engine is available")
except ImportError:
    logger.warning("Pyo audio engine is not available. Audio synthesis will be disabled.")

# Numba JITæœ€é©åŒ–ã®åˆæœŸåŒ–
def initialize_numba_optimization():
    """Numba JITæœ€é©åŒ–ã‚’åˆæœŸåŒ–"""
    try:
        sys.path.insert(0, str(project_root / "src"))
        from src.numba_config import initialize_numba, get_numba_status, warmup_basic_functions
        
        logger.info("Starting Numba initialization...")
        success = initialize_numba(verbose=True, force_retry=True)
        if success:
            status = get_numba_status()
            logger.info(f"Numba JIT acceleration enabled (v{status['version']})")
            logger.info("Warming up JIT functions...")
            warmup_basic_functions()
            logger.info("JIT functions warmed up - maximum performance ready")
        else:
            logger.warning("Numba JIT acceleration disabled (falling back to NumPy)")
    except Exception as e:
        logger.warning(f"Numba configuration error: {e}")
        logger.warning("Using NumPy fallback for all computations")

# NumbaåˆæœŸåŒ–ã‚’å®Ÿè¡Œ
initialize_numba_optimization()

# å¿…è¦ãªã‚¯ãƒ©ã‚¹ã®import
from src.detection.tracker import TrackedHand
from src.sound.mapping import ScaleType, InstrumentType
from src.mesh.projection import PointCloudProjector, ProjectionMethod
from src.mesh.delaunay import DelaunayTriangulator
from src.mesh.simplify import MeshSimplifier
from src.mesh.index import SpatialIndex, IndexType
from src.collision.search import CollisionSearcher
from src.collision.sphere_tri import SphereTriangleCollision
from src.collision.events import CollisionEventQueue
from src.sound.mapping import AudioMapper
from src.detection.hands2d import MediaPipeHandsWrapper
from src.input.stream import OrbbecCamera
from src.detection.hands3d import Hand3DProjector
from src.detection.tracker import Hand3DTracker
from src.sound.synth import AudioSynthesizer, AudioConfig, EngineState, create_audio_synthesizer
from src.sound.voice_mgr import VoiceManager, StealStrategy, SpatialMode, SpatialConfig, create_voice_manager, allocate_and_play
from src.debug.dual_viewer import DualViewer
from src.input.depth_filter import DepthFilter, FilterType
from src.input.pointcloud import PointCloudConverter
from src.config import get_config, InputConfig
from src.mesh.pipeline import create_mesh_pipeline  # unified mesh pipeline
from src.mesh.manager import PipelineManager  # NEW pipeline manager

# GPUåŠ é€Ÿã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
HAS_GPU_ACCELERATION = False
try:
    from src.collision.distance_gpu import GPUDistanceCalculator, create_gpu_distance_calculator
    from src.mesh.delaunay_gpu import GPUDelaunayTriangulator, create_gpu_triangulator
    HAS_GPU_ACCELERATION = True
    logger.info("GPU acceleration modules loaded (CuPy available)")
except ImportError:
    logger.warning("GPU acceleration unavailable (CuPy not installed)")

# =============================================================================
# ãƒ†ã‚¹ãƒˆé–¢æ•°
# =============================================================================

def run_preprocessing_optimization_test():
    """å‰å‡¦ç†æœ€é©åŒ–åŠ¹æœæ¸¬å®šãƒ†ã‚¹ãƒˆ"""
    def mock_mediapipe_process(image):
        """MediaPipeå‡¦ç†ã®ãƒ¢ãƒƒã‚¯"""
        time.sleep(0.015)  # ~15mså‡¦ç†æ™‚é–“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        return []
    
    print("=" * 70)
    print("å‰å‡¦ç†æœ€é©åŒ–åŠ¹æœ æ¸¬å®šãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    
    # ãƒ¢ãƒƒã‚¯æ·±åº¦ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    depth_low = np.random.randint(500, 2000, LOW_RESOLUTION[::-1], dtype=np.uint16)
    depth_high = np.random.randint(500, 2000, (480, 848), dtype=np.uint16)
    color_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
    
    # ã‚±ãƒ¼ã‚¹1: é«˜è§£åƒåº¦ + MediaPipeé‡è¤‡å®Ÿè¡Œ
    print("ğŸ” ã‚±ãƒ¼ã‚¹1: 848x480 + MediaPipeé‡è¤‡å®Ÿè¡Œ")
    fps_case1 = _measure_fps_for_test_case(
        depth_high, color_image, mock_mediapipe_process, 
        num_mediapipe_calls=2, target_frame_time=0.075
    )
    
    # ã‚±ãƒ¼ã‚¹2: ä½è§£åƒåº¦ + MediaPipe1å›å®Ÿè¡Œ
    print("ğŸ” ã‚±ãƒ¼ã‚¹2: 424x240 + MediaPipe1å›å®Ÿè¡Œ")
    fps_case2 = _measure_fps_for_test_case(
        depth_low, color_image, mock_mediapipe_process,
        num_mediapipe_calls=1, target_frame_time=0.036
    )
    
    # çµæœè¡¨ç¤º
    _display_test_results("å‰å‡¦ç†æœ€é©åŒ–åŠ¹æœ", fps_case1, fps_case2)

def run_headless_fps_comparison_test():
    """ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰FPSåŠ¹æœæ¸¬å®šãƒ†ã‚¹ãƒˆ"""
    def mock_core_processing():
        """ã‚³ã‚¢å‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        time.sleep(0.025)  # 25mså‡¦ç†æ™‚é–“
    
    def mock_gui_rendering():
        """GUIæç”»å‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        time.sleep(0.008)  # Open3D 3Dæç”»
        time.sleep(0.003)  # OpenCV RGBè¡¨ç¤º
        time.sleep(0.002)  # UIæ›´æ–°
    
    print("=" * 70)
    print("ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ FPSåŠ¹æœ æ¸¬å®šãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    
    # GUIæœ‰ã‚Šãƒ¢ãƒ¼ãƒ‰æ¸¬å®š
    print("ğŸ–¥ï¸  GUIæœ‰ã‚Šãƒ¢ãƒ¼ãƒ‰æ¸¬å®šä¸­...")
    fps_gui = _measure_fps_with_processing(
        mock_core_processing, mock_gui_rendering, num_frames=100
    )
    
    # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰æ¸¬å®š
    print("âš¡ ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰æ¸¬å®šä¸­...")
    fps_headless = _measure_fps_with_processing(
        mock_core_processing, None, num_frames=100
    )
    
    # çµæœè¡¨ç¤º
    _display_test_results("ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ FPSåŠ¹æœ", fps_gui, fps_headless)

def _measure_fps_for_test_case(depth_data, color_image, mediapipe_func, 
                               num_mediapipe_calls, target_frame_time):
    """ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®FPSã‚’æ¸¬å®š"""
    start_time = time.time()
    frames = 0
    
    for _ in range(50):  # 50ãƒ•ãƒ¬ãƒ¼ãƒ æ¸¬å®š
        frame_start = time.time()
        
        # ç‚¹ç¾¤å‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        points = depth_data.reshape(-1)
        valid_points = points[points > 0]
        
        # MediaPipeå®Ÿè¡Œ
        for _ in range(num_mediapipe_calls):
            mediapipe_func(color_image)
        
        frame_time = time.time() - frame_start
        frames += 1
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ æ™‚é–“èª¿æ•´
        if frame_time < target_frame_time:
            time.sleep(target_frame_time - frame_time)
    
    elapsed = time.time() - start_time
    return frames / elapsed

def _measure_fps_with_processing(core_func, gui_func, num_frames):
    """å‡¦ç†é–¢æ•°ã®FPSã‚’æ¸¬å®š"""
    start_time = time.time()
    
    for _ in range(num_frames):
        core_func()
        if gui_func:
            gui_func()
    
    elapsed = time.time() - start_time
    return num_frames / elapsed

def _display_test_results(test_name, fps1, fps2):
    """ãƒ†ã‚¹ãƒˆçµæœã‚’è¡¨ç¤º"""
    print(f"\nğŸ“Š {test_name} çµæœ")
    print("=" * 50)
    print(f"ã‚±ãƒ¼ã‚¹1: {fps1:.1f} FPS")
    print(f"ã‚±ãƒ¼ã‚¹2: {fps2:.1f} FPS")
    print(f"æ”¹å–„å€ç‡: {fps2/fps1:.1f}x")
    print(f"FPSå‘ä¸Š: +{fps2-fps1:.1f} FPS")
    print(f"ãƒ•ãƒ¬ãƒ¼ãƒ æ™‚é–“çŸ­ç¸®: {(1/fps1-1/fps2)*1000:.1f}ms")

# =============================================================================
# ãƒ¡ã‚¤ãƒ³ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚¯ãƒ©ã‚¹
# =============================================================================

class FullPipelineViewer(DualViewer):
    """å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆæ‹¡å¼µDualViewerï¼ˆæ‰‹æ¤œå‡º+ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ+è¡çªæ¤œå‡º+éŸ³éŸ¿ç”Ÿæˆï¼‰"""
    
    def __init__(self, **kwargs):
        # è¨­å®šå€¤ã®æŠ½å‡º
        self._extract_configuration(kwargs)
        
        # è¦ªã‚¯ãƒ©ã‚¹åˆæœŸåŒ–
        super().__init__(**kwargs)
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–
        self._initialize_components()
        
        # çŠ¶æ…‹ç®¡ç†ã®åˆæœŸåŒ–
        self._initialize_state()
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã®åˆæœŸåŒ–
        self._initialize_performance_stats()
        
        # GPUåŠ é€Ÿã®åˆæœŸåŒ–
        self._initialize_gpu_acceleration()
        
        # ãƒ˜ãƒ«ãƒ—ãƒ†ã‚­ã‚¹ãƒˆã®æ›´æ–°
        self.update_help_text()
        
        # åˆæœŸåŒ–å®Œäº†ãƒ•ãƒ©ã‚°
        self._components_initialized = False
        
        self._display_initialization_info()
    
    def _extract_configuration(self, kwargs):
        """è¨­å®šå€¤ã‚’æŠ½å‡º"""
        # éŸ³éŸ¿é–¢é€£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.enable_audio_synthesis = kwargs.pop('enable_audio_synthesis', True)
        self.audio_scale = kwargs.pop('audio_scale', ScaleType.PENTATONIC)
        self.audio_instrument = kwargs.pop('audio_instrument', InstrumentType.MARIMBA)
        self.audio_polyphony = kwargs.pop('audio_polyphony', DEFAULT_AUDIO_POLYPHONY)
        self.audio_master_volume = kwargs.pop('audio_master_volume', DEFAULT_MASTER_VOLUME)
        
        # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰è¨­å®š
        self.headless_mode = kwargs.pop('headless_mode', False)
        self.headless_duration = kwargs.pop('headless_duration', 30)
        self.pure_headless_mode = kwargs.pop('pure_headless_mode', False)
        
        # è¡çªæ¤œå‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.enable_mesh_generation = kwargs.pop('enable_mesh_generation', True)
        self.enable_collision_detection = kwargs.pop('enable_collision_detection', True)
        self.enable_collision_visualization = kwargs.pop('enable_collision_visualization', True)
        self.sphere_radius = kwargs.pop('sphere_radius', DEFAULT_SPHERE_RADIUS)
        
        # ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”åˆ¶å¾¡
        self.mesh_update_interval = kwargs.pop('mesh_update_interval', DEFAULT_MESH_UPDATE_INTERVAL)
        self.max_mesh_skip_frames = kwargs.pop('max_mesh_skip_frames', DEFAULT_MAX_MESH_SKIP_FRAMES)
        
        # ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.voxel_downsampling_enabled = kwargs.pop('enable_voxel_downsampling', True)
        self.voxel_size = kwargs.pop('voxel_size', DEFAULT_VOXEL_SIZE)
    
        # MediaPipe GPU ä½¿ç”¨è¨­å®š
        self.use_gpu_mediapipe = kwargs.pop('use_gpu_mediapipe', False)
    
    def _initialize_components(self):
        """ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        # ãƒ˜ãƒ«ãƒ—ãƒ†ã‚­ã‚¹ãƒˆ
        self.help_text = ""
        
        # åœ°å½¢ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.projector = PointCloudProjector(
            resolution=0.01,  # 1cmè§£åƒåº¦
            method=ProjectionMethod.MEDIAN_HEIGHT,
            fill_holes=True,
            plane="xz",  # ã‚«ãƒ¡ãƒ©åº§æ¨™ç³»ã«åˆã‚ã›ã¦ XZ å¹³é¢æŠ•å½±
        )
        
        # LODãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆå™¨
        self._initialize_mesh_generators()
        
        # ãƒ¡ãƒƒã‚·ãƒ¥ç°¡ç•¥åŒ–
        self.simplifier = MeshSimplifier(
            target_reduction=0.7,  # 70%å‰Šæ¸›
            preserve_boundary=True
        )
        
        # è¡çªæ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.spatial_index: Optional[SpatialIndex] = None
        self.collision_searcher: Optional[CollisionSearcher] = None
        self.collision_tester: Optional[SphereTriangleCollision] = None
        self.event_queue: CollisionEventQueue = CollisionEventQueue()
        
        # éŸ³éŸ¿ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.audio_mapper: Optional[AudioMapper] = None
        self.audio_synthesizer: Optional[AudioSynthesizer] = None
        self.voice_manager: Optional[VoiceManager] = None
        self.audio_enabled = False
        
        # éŸ³éŸ¿ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ç®¡ç†
        self.audio_cooldown_time = DEFAULT_AUDIO_COOLDOWN_TIME
        self.last_audio_trigger_time = {}
        # è¡çªãƒ‡ãƒã‚¦ãƒ³ã‚¹ç”¨: (hand_id, triangle_idx) -> last trigger time
        from typing import Tuple as _Tuple
        self._last_contact_trigger_time: Dict[_Tuple[str, int, int, int], float] = {}
    
        # æ‰‹æ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.enable_hand_detection = True
        self.enable_hand_tracking = True
        self.enable_tracking = True
        self.min_detection_confidence = 0.2
        self._initialize_hand_detection()
        
        # 3Dã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆå¾Œã§åˆæœŸåŒ–ï¼‰
        self.projector_3d = None
        self.tracker = None
    
    def _initialize_mesh_generators(self):
        """ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆå™¨ã‚’åˆæœŸåŒ– (T-MESH-101)"""

        # LOD ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆå™¨ï¼ˆMeshPipeline å†…éƒ¨ã§ã‚‚ä½¿ç”¨ï¼‰
        from src.mesh.lod_mesh import create_lod_mesh_generator  # é…å»¶ import ã§å¾ªç’°å›é¿
        self.lod_mesh_generator = create_lod_mesh_generator(
            high_radius=0.20,
            medium_radius=0.50,
            enable_gpu=True,
        )

        # å¾“æ¥ Triangulator â€“ ç›´æ¥å‘¼ã³å‡ºã—ç®‡æ‰€æ®‹å­˜ã®ãŸã‚ä¿æŒ
        self.triangulator = DelaunayTriangulator(
            adaptive_sampling=True,
            boundary_points=True,
            quality_threshold=0.3,
            use_gpu=True,
        )

        # çµ±åˆ MeshPipeline
        self.mesh_pipeline = create_mesh_pipeline(enable_incremental=False)
        self.pipeline_manager = PipelineManager(self.mesh_pipeline)
        self._mesh_version = -1  # track version for viewer refresh
    
    def _initialize_hand_detection(self):
        """æ‰‹æ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        self.hands_2d = MediaPipeHandsWrapper(
            use_gpu=self.use_gpu_mediapipe,
            min_detection_confidence=self.min_detection_confidence,
            min_tracking_confidence=0.5,
            max_num_hands=2,
            # ROI ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°è¨­å®šï¼ˆåŠ¹ç‡åŒ–ï¼‰
            enable_roi_tracking=True,
            tracker_type="KCF",           # KCFãƒˆãƒ©ãƒƒã‚«ãƒ¼ã§é«˜é€ŸåŒ–
            skip_interval=4,              # 4ãƒ•ãƒ¬ãƒ¼ãƒ ã«1å›MediaPipeå®Ÿè¡Œ
            roi_confidence_threshold=0.6,
            max_tracking_age=15
        )
        return True
    
    def _initialize_state(self):
        """çŠ¶æ…‹ç®¡ç†ã‚’åˆæœŸåŒ–"""
        self.current_mesh = None
        self.current_collision_points = []
        self.current_tracked_hands = []
        self.current_hands_2d = []
        self.current_hands_3d = []
        self.frame_counter = 0
        self.last_mesh_update = -999  # åˆå›ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚’ç¢ºå®Ÿã«ã™ã‚‹
        self.force_mesh_update_requested = False
        
        # ãƒ¡ãƒƒã‚·ãƒ¥ã¨ã‚³ãƒªã‚¸ãƒ§ãƒ³ã®å¯è¦–åŒ–ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        self.mesh_geometries = []
        self.collision_geometries = []
        
        # ç›´è¿‘ã®ç‚¹ç¾¤ / æ·±åº¦ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿æŒ
        self._last_points_3d: Optional[np.ndarray] = None
        self._latest_depth_image: Optional[np.ndarray] = None
    
    def _initialize_performance_stats(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’åˆæœŸåŒ–"""
        self.perf_stats = {
            'frame_count': 0,
            'mesh_generation_time': 0.0,
            'collision_detection_time': 0.0,
            'audio_synthesis_time': 0.0,
            'collision_events_count': 0,
            'audio_notes_played': 0,
            'total_pipeline_time': 0.0
        }
        
        # åŸºæœ¬ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆï¼ˆè¦ªã‚¯ãƒ©ã‚¹äº’æ›ï¼‰
        self.performance_stats = {
            'fps': 0.0,
            'frame_time': 0.0,
            'filter_time': 0.0,
            'pointcloud_time': 0.0,
            'hand_detection_time': 0.0,
            # DualViewer ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã§å‚ç…§ã•ã‚Œã‚‹è¿½åŠ ã‚­ãƒ¼ï¼ˆåˆæœŸåŒ–ã—ã¦ãŠãï¼‰
            'hand_projection_time': 0.0,
            'hand_tracking_time': 0.0,
            'display_time': 0.0,
            'hands_detected': 0,
            'hands_tracked': 0
        }
        
        # GPUçµ±è¨ˆ
        self.gpu_stats = {
            'distance_calculations': 0,
            'triangulations': 0,
            'gpu_time_total_ms': 0.0,
            'cpu_fallbacks': 0
        }
    
    def _initialize_gpu_acceleration(self):
        """GPUåŠ é€Ÿã‚’åˆæœŸåŒ–"""
        self.gpu_distance_calc = None
        self.gpu_triangulator = None
        self.gpu_acceleration_enabled = False
        
        if not HAS_GPU_ACCELERATION:
            return
        
        try:
            # GPUè·é›¢è¨ˆç®—å™¨
            self.gpu_distance_calc = create_gpu_distance_calculator(
                use_gpu=True,
                batch_size=10000,
                memory_limit_ratio=0.8
            )
            
            # GPUä¸‰è§’åˆ†å‰²å™¨
            self.gpu_triangulator = create_gpu_triangulator(
                use_gpu=True,
                quality_threshold=0.2,
                enable_caching=True
            )
            
            # å®Ÿéš›ã«GPUãŒä½¿ãˆã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            gpu_calc_available = (hasattr(self.gpu_distance_calc, 'gpu_available') and 
                                self.gpu_distance_calc.gpu_available)
            gpu_tri_available = (hasattr(self.gpu_triangulator, 'use_gpu') and 
                               self.gpu_triangulator.use_gpu)
            
            self.gpu_acceleration_enabled = gpu_calc_available or gpu_tri_available
            
            if self.gpu_acceleration_enabled:
                logger.info("ğŸš€ GPU acceleration initialized successfully")
                logger.info(f"  - Distance Calculator: {'GPU' if gpu_calc_available else 'CPU fallback'}")
                logger.info(f"  - Triangulator: {'GPU' if gpu_tri_available else 'CPU fallback'}")
            else:
                logger.warning("GPU acceleration components initialized but GPU not available")
                
        except Exception as e:
            logger.warning(f"GPU acceleration initialization failed: {e}")
            logger.warning("Falling back to CPU-only processing")
    
    def _display_initialization_info(self):
        """åˆæœŸåŒ–æƒ…å ±ã‚’è¡¨ç¤º"""
        print("å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
        print(f"  - ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ: {'æœ‰åŠ¹' if self.enable_mesh_generation else 'ç„¡åŠ¹'}")
        print(f"  - è¡çªæ¤œå‡º: {'æœ‰åŠ¹' if self.enable_collision_detection else 'ç„¡åŠ¹'}")
        print(f"  - æ¥è§¦ç‚¹å¯è¦–åŒ–: {'æœ‰åŠ¹' if self.enable_collision_visualization else 'ç„¡åŠ¹'}")
        print(f"  - çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
        print(f"  - éŸ³éŸ¿åˆæˆ: {'æœ‰åŠ¹' if self.enable_audio_synthesis else 'ç„¡åŠ¹'}")
        
        if self.enable_audio_synthesis:
            print(f"    - éŸ³éš: {self.audio_scale.value}")
            print(f"    - æ¥½å™¨: {self.audio_instrument.value}")
            print(f"    - ãƒãƒªãƒ•ã‚©ãƒ‹ãƒ¼: {self.audio_polyphony}")
            print(f"    - éŸ³é‡: {self.audio_master_volume:.1f}")
            print(f"    - ã‚¨ãƒ³ã‚¸ãƒ³çŠ¶æ…‹: {'å‹•ä½œä¸­' if self.audio_enabled else 'åœæ­¢ä¸­'}")
        
        # éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        if self.enable_audio_synthesis:
            self._initialize_audio_system()
    
    def update_help_text(self):
        """ãƒ˜ãƒ«ãƒ—ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°"""
        help_sections = [
            ("Basic Controls", [
                "Q/ESC: Exit",
                "F: Toggle filter",
                "H: Toggle hand detection",
                "T: Toggle tracking",
                "R: Reset filter",
                "Y: Reset tracker"
            ]),
            ("Point Cloud Optimization", [
                "X: Toggle voxel downsampling",
                "Z/Shift+Z: Voxel size -/+ (1mm-10cm)",
                "B: Print voxel performance stats"
            ]),
            ("è¡çªæ¤œå‡ºåˆ¶å¾¡", [
                "M: ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ ON/OFF",
                "C: è¡çªæ¤œå‡º ON/OFF",
                "V: è¡çªå¯è¦–åŒ– ON/OFF",
                "N: ãƒ¡ãƒƒã‚·ãƒ¥å¼·åˆ¶æ›´æ–°",
                "+/-: çƒåŠå¾„èª¿æ•´",
                "P: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆè¡¨ç¤º"
            ]),
            ("éŸ³éŸ¿ç”Ÿæˆåˆ¶å¾¡", [
                "A: éŸ³éŸ¿åˆæˆ ON/OFF",
                "S: éŸ³éšåˆ‡ã‚Šæ›¿ãˆ",
                "I: æ¥½å™¨åˆ‡ã‚Šæ›¿ãˆ",
                "1/2: éŸ³é‡èª¿æ•´",
                "R: éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³å†èµ·å‹•",
                "Q: å…¨éŸ³å£°åœæ­¢"
            ])
        ]
        
        self.help_text = ""
        for section_name, commands in help_sections:
            self.help_text += f"\n=== {section_name} ===\n"
            for command in commands:
                self.help_text += f"{command}\n"
    
    def handle_key_event(self, key: int) -> bool:
        """ã‚­ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†"""
        key_handlers = {
            # åŸºæœ¬æ“ä½œ
            ord('q'): lambda: False,
            27: lambda: False,  # ESC
            ord('f'): self._toggle_filter,
            ord('h'): self._toggle_hand_detection,
            ord('t'): self._toggle_tracking,
            ord('r'): self._reset_filter,
            ord('y'): self._reset_tracker,
            
            # ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            ord('x'): self._toggle_voxel_downsampling,
            ord('X'): self._toggle_voxel_downsampling,
            ord('z'): self._decrease_voxel_size,
            ord('Z'): self._increase_voxel_size,
            ord('b'): self._print_voxel_stats,
            ord('B'): self._print_voxel_stats,
            
            # è¡çªæ¤œå‡º
            ord('m'): self._toggle_mesh_generation,
            ord('M'): self._toggle_mesh_generation,
            ord('c'): self._toggle_collision_detection,
            ord('C'): self._toggle_collision_detection,
            ord('v'): self._toggle_collision_visualization,
            ord('V'): self._toggle_collision_visualization,
            ord('n'): self._force_mesh_update_request,
            ord('N'): self._force_mesh_update_request,
            ord('+'): self._increase_sphere_radius,
            ord('='): self._increase_sphere_radius,
            ord('-'): self._decrease_sphere_radius,
            ord('_'): self._decrease_sphere_radius,
            ord('p'): self._print_performance_stats,
            ord('P'): self._print_performance_stats,
            
            # éŸ³éŸ¿ç”Ÿæˆ
            ord('a'): self._toggle_audio_synthesis,
            ord('A'): self._toggle_audio_synthesis,
            ord('s'): self._cycle_audio_scale,
            ord('S'): self._cycle_audio_scale,
            ord('i'): self._cycle_audio_instrument,
            ord('I'): self._cycle_audio_instrument,
            ord('1'): self._decrease_volume,
            ord('2'): self._increase_volume,
        }
        
        # ç‰¹æ®Šã‚­ãƒ¼ã®å‡¦ç†
        if key == ord('r') or key == ord('R'):
            if self.enable_audio_synthesis and (key == ord('R')):
                print("éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³ã‚’å†èµ·å‹•ä¸­...")
                self._restart_audio_system()
                return True
            else:
                return self._reset_filter()
        
        if key == ord('q') or key == ord('Q'):
            if self.enable_audio_synthesis and self.voice_manager and (key == ord('Q')):
                self.voice_manager.stop_all_voices()
                print("å…¨éŸ³å£°ã‚’åœæ­¢ã—ã¾ã—ãŸ")
                return True
            else:
                return False
        
        # é€šå¸¸ã®ã‚­ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼å®Ÿè¡Œ
        handler = key_handlers.get(key)
        if handler:
            return handler()
        
        return True
    
    # ã‚­ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def _toggle_filter(self) -> bool:
        self.enable_filter = not self.enable_filter
        print(f"Depth filter: {'Enabled' if self.enable_filter else 'Disabled'}")
        return True
    
    def _toggle_hand_detection(self) -> bool:
        self.enable_hand_detection = not self.enable_hand_detection
        print(f"Hand detection: {'Enabled' if self.enable_hand_detection else 'Disabled'}")
        return True
    
    def _toggle_tracking(self) -> bool:
        self.enable_tracking = not self.enable_tracking
        print(f"Hand tracking: {'Enabled' if self.enable_tracking else 'Disabled'}")
        return True
    
    def _reset_filter(self) -> bool:
        if self.depth_filter is not None:
            self.depth_filter.reset_temporal_history()
            print("Filter history reset")
        return True
    
    def _reset_tracker(self) -> bool:
        if self.tracker is not None:
            self.tracker.reset()
            print("Hand tracker reset")
        return True
    
    def _toggle_voxel_downsampling(self) -> bool:
        if self.pointcloud_converter:
            self.pointcloud_converter.toggle_voxel_downsampling()
        return True
    
    def _decrease_voxel_size(self) -> bool:
        if self.pointcloud_converter:
            current_size = self.pointcloud_converter.voxel_size
            new_size = max(0.001, current_size - 0.001)
            self.pointcloud_converter.set_voxel_size(new_size)
        return True
    
    def _increase_voxel_size(self) -> bool:
        if self.pointcloud_converter:
            current_size = self.pointcloud_converter.voxel_size
            new_size = min(0.05, current_size + 0.001)
            self.pointcloud_converter.set_voxel_size(new_size)
        return True
    
    def _print_voxel_stats(self) -> bool:
        if self.pointcloud_converter:
            self.pointcloud_converter.print_performance_stats()
        return True
    
    def _toggle_mesh_generation(self) -> bool:
        self.enable_mesh_generation = not self.enable_mesh_generation
        print(f"ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ: {'æœ‰åŠ¹' if self.enable_mesh_generation else 'ç„¡åŠ¹'}")
        return True
    
    def _toggle_collision_detection(self) -> bool:
        self.enable_collision_detection = not self.enable_collision_detection
        print(f"è¡çªæ¤œå‡º: {'æœ‰åŠ¹' if self.enable_collision_detection else 'ç„¡åŠ¹'}")
        return True
    
    def _toggle_collision_visualization(self) -> bool:
        self.enable_collision_visualization = not self.enable_collision_visualization
        print(f"è¡çªå¯è¦–åŒ–: {'æœ‰åŠ¹' if self.enable_collision_visualization else 'ç„¡åŠ¹'}")
        self._update_visualization()
        return True
    
    def _force_mesh_update_request(self) -> bool:
        print("ãƒ¡ãƒƒã‚·ãƒ¥ã‚’å¼·åˆ¶æ›´æ–°ä¸­...")
        self._force_mesh_update()
        return True
    
    def _increase_sphere_radius(self) -> bool:
        self.sphere_radius = min(self.sphere_radius + 0.01, 0.2)
        print(f"çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
        return True
    
    def _decrease_sphere_radius(self) -> bool:
        self.sphere_radius = max(self.sphere_radius - 0.01, 0.01)
        print(f"çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
        return True
    
    def _toggle_audio_synthesis(self) -> bool:
        self.enable_audio_synthesis = not self.enable_audio_synthesis
        if self.enable_audio_synthesis:
            self._initialize_audio_system()
        else:
            self._shutdown_audio_system()
        print(f"éŸ³éŸ¿åˆæˆ: {'æœ‰åŠ¹' if self.enable_audio_synthesis else 'ç„¡åŠ¹'}")
        return True
    
    def _decrease_volume(self) -> bool:
        if self.enable_audio_synthesis and self.audio_synthesizer:
            self.audio_master_volume = max(0.0, self.audio_master_volume - 0.1)
            self.audio_synthesizer.update_master_volume(self.audio_master_volume)
            print(f"éŸ³é‡: {self.audio_master_volume:.1f}")
        return True
    
    def _increase_volume(self) -> bool:
        if self.enable_audio_synthesis and self.audio_synthesizer:
            self.audio_master_volume = min(1.0, self.audio_master_volume + 0.1)
            self.audio_synthesizer.update_master_volume(self.audio_master_volume)
            print(f"éŸ³é‡: {self.audio_master_volume:.1f}")
        return True
    
    def _update_terrain_mesh(self, points_3d: np.ndarray) -> None:
        """åœ°å½¢ãƒ¡ãƒƒã‚·ãƒ¥ã‚’æ›´æ–° â€“ MeshPipeline ç‰ˆ (T-MESH-101)"""
        if points_3d is None or len(points_3d) < 100:
            return

        try:
            import time

            start_t = time.perf_counter()

            # MeshPipeline ã«å§”è­²
            mesh_res = self.mesh_pipeline.generate_mesh(
                points_3d,
                self.current_tracked_hands,
                force_update=getattr(self, 'force_mesh_update_requested', False),
            )

            if mesh_res.mesh is None:
                return  # ç”Ÿæˆå¤±æ•— / ãƒã‚¤ãƒ³ãƒˆä¸è¶³

            simplified_mesh = mesh_res.mesh  # MeshPipeline å†…ã§ç°¡ç•¥åŒ–æ¸ˆã¿

            gen_ms = (time.perf_counter() - start_t) * 1000.0
            if self.frame_counter % 50 == 0:
                logger.debug("[MESH-PIPELINE] %d points -> %d tris in %.1fms", len(points_3d), simplified_mesh.num_triangles, gen_ms)

            # ç©ºé–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯ã€Œãƒ¡ãƒƒã‚·ãƒ¥ãŒå¤‰ã‚ã£ãŸã¨ãã€ã®ã¿å†æ§‹ç¯‰
            if mesh_res.changed or self.spatial_index is None:
                self.spatial_index = SpatialIndex(simplified_mesh, index_type=IndexType.BVH)
                # è¡çªæ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ– / æ›´æ–°
                self.collision_searcher = CollisionSearcher(self.spatial_index)
                self.collision_tester = SphereTriangleCollision(simplified_mesh)
            
            # ãƒ¡ãƒƒã‚·ãƒ¥ä¿å­˜
            self.current_mesh = simplified_mesh
            
            # ãƒ¡ãƒƒã‚·ãƒ¥ç¯„å›²ã®ãƒ­ã‚°å‡ºåŠ›
            self._log_mesh_info(simplified_mesh)
            
            # å¯è¦–åŒ–: mesh_res.needs_refresh ã¾ãŸã¯ mesh_res.changed
            if mesh_res.needs_refresh or mesh_res.changed:
                self._update_mesh_visualization(simplified_mesh)
            
            # å¼·åˆ¶æ›´æ–°ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
            if hasattr(self, 'force_mesh_update_requested'):
                self.force_mesh_update_requested = False
            
            print(f"ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°å®Œäº†: {simplified_mesh.num_triangles}ä¸‰è§’å½¢")
            
        except Exception as e:
            logger.error(f"ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
    
    def _log_lod_mesh_generation(self, points_3d: np.ndarray, triangle_mesh: Any, time_ms: float) -> None:
        """LODãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã®ãƒ­ã‚°"""
        if hasattr(self, 'frame_counter') and self.frame_counter % 50 == 0:
            print(f"[LOD-MESH] {len(points_3d)} points -> {triangle_mesh.num_vertices} vertices, "
                  f"{triangle_mesh.num_triangles} triangles in {time_ms:.1f}ms")
    
    def _log_mesh_info(self, mesh: Any) -> None:
        """ãƒ¡ãƒƒã‚·ãƒ¥æƒ…å ±ã®ãƒ­ã‚°"""
        if mesh.vertices.size > 0:
            mesh_min = np.min(mesh.vertices, axis=0)
            mesh_max = np.max(mesh.vertices, axis=0)
            logger.info(f"[MESH-INFO] Vertex range: X[{mesh_min[0]:.3f}, {mesh_max[0]:.3f}], "
                       f"Y[{mesh_min[1]:.3f}, {mesh_max[1]:.3f}], Z[{mesh_min[2]:.3f}, {mesh_max[2]:.3f}]")
    
    def _detect_collisions(self, tracked_hands: List[TrackedHand]) -> List[Any]:
        """è¡çªæ¤œå‡ºã‚’å®Ÿè¡Œ"""
        if not self.collision_searcher:
            logger.debug("No collision searcher available")
            return []
        
        events = []
        self.current_collision_points = []
        logger.debug(f"Processing {len(tracked_hands)} hands")
        
        # GPUåŠ é€Ÿè·é›¢è¨ˆç®—ã®æº–å‚™
        use_gpu_distance = (
            self.gpu_acceleration_enabled and 
            self.gpu_distance_calc is not None and
            len(tracked_hands) > 0
        )
        
        for i, hand in enumerate(tracked_hands):
            if hand.position is None:
                logger.debug(f"Hand {i} has no position")
                continue
            
            # Prepare list of positions to test: current + historical (predictive)
            pos_history = self._hand_position_history.get(hand.id, [])
            positions_to_test: List[np.ndarray] = [np.array(hand.position)] + [np.array(p) for p in pos_history]

            # Remove duplicates while preserving order
            seen = set()
            unique_positions = []
            for p in positions_to_test:
                tup = tuple(np.round(p, 4))
                if tup not in seen:
                    seen.add(tup)
                    unique_positions.append(p)

            hand_pos_np = unique_positions[0]
            
            logger.debug(f"Hand {i} position: ({hand_pos_np[0]:.3f}, {hand_pos_np[1]:.3f}, {hand_pos_np[2]:.3f})")
            
            try:
                for ptest in unique_positions:
                    # Adaptive radius: enlarge slightly based on velocity magnitude
                    vel_mag = float(np.linalg.norm(getattr(hand, "velocity", np.zeros(3)))) if hasattr(hand, "velocity") else 0.0
                    adaptive_radius = self.sphere_radius + min(0.03, vel_mag * 0.05)

                    # Direct sphere query for the specific test point
                    res = self.collision_searcher._search_point(ptest, adaptive_radius)

                    if not res.triangle_indices:
                        continue

                    info = self._perform_collision_test(
                        ptest, adaptive_radius, res, use_gpu_distance, i
                    )

                    if info and info.has_collision:
                        event = self._create_collision_event(hand, ptest, info)
                        if event:
                            events.append(event)
                            self._update_collision_points(info)
                        # Found collision, break predictive loop
                        break

            except Exception as e:
                logger.error(f"Error processing hand {i}: {e}")
        
        logger.debug(f"Total collision events: {len(events)}")
        return events
    
    def _perform_collision_test(self, hand_pos: np.ndarray, radius: float, 
                               search_result: Any, use_gpu: bool, hand_index: int) -> Any:
        """è¡çªãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        if use_gpu and len(search_result.triangle_indices) > 5:
            # GPUåŠ é€Ÿè·é›¢è¨ˆç®—
            info = self._gpu_collision_testing(hand_pos, radius, search_result)
            self.gpu_stats['distance_calculations'] += 1
            logger.debug(f"[GPU-DISTANCE] Hand {hand_index} collision test using GPU acceleration")
        else:
            # CPUè¡çªæ¤œå‡º
            if self.collision_tester is not None:
                info = self.collision_tester.test_sphere_collision(hand_pos, radius, search_result)
                if use_gpu:
                    self.gpu_stats['cpu_fallbacks'] += 1
                    logger.debug(f"[CPU-FALLBACK] Hand {hand_index} using CPU collision")
            else:
                return None
        
        return info
    
    def _create_collision_event(self, hand: TrackedHand, hand_pos: np.ndarray, info: Any) -> Any:
        """è¡çªã‚¤ãƒ™ãƒ³ãƒˆã‚’ç”Ÿæˆ"""
        velocity = np.array(hand.velocity) if hasattr(hand, 'velocity') and hand.velocity is not None else np.zeros(3)
        return self.event_queue.create_event(info, hand.id, hand_pos, velocity)
    
    def _update_collision_points(self, info: Any) -> None:
        """è¡çªç‚¹ã‚’æ›´æ–°ï¼ˆçµ±ä¸€å½¢å¼ï¼‰"""
        for cp in info.contact_points:
            # ContactPointã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ãã®ã¾ã¾ä¿æŒ
            self.current_collision_points.append(cp)
    
    def _gpu_collision_testing(self, hand_pos: np.ndarray, radius: float, search_result: Any) -> Any:
        """GPUåŠ é€Ÿè¡çªãƒ†ã‚¹ãƒˆ"""
        try:
            import time
            start_time = time.perf_counter()
            
            # Type safety hints for static analysers
            assert self.gpu_distance_calc is not None, "GPU distance calculator not initialized"

            # ä¸‰è§’å½¢ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            if self.current_mesh is None or not hasattr(self.current_mesh, 'vertices') or not hasattr(self.current_mesh, 'triangles'):
                # GPUå‡¦ç†å¤±æ•—æ™‚ã¯CPUå‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if self.collision_tester is not None:
                    return self.collision_tester.test_sphere_collision(hand_pos, radius, search_result)
                from src.collision.sphere_tri import CollisionInfo
                import numpy as _np
                return CollisionInfo(
                    has_collision=False,
                    contact_points=[],
                    closest_point=None,
                    total_penetration_depth=0.0,
                    collision_normal=_np.array([0.0, 0.0, 1.0]),
                    collision_time_ms=0.0,
                )
            
            vertices = np.asarray(self.current_mesh.vertices)
            triangles = np.asarray(self.current_mesh.triangles)
            
            # å¯¾è±¡ä¸‰è§’å½¢ã®ã¿æŠ½å‡º
            target_triangles = triangles[search_result.triangle_indices]
            
            # æ‰‹ä½ç½®ã‚’é…åˆ—ã«å¤‰æ›
            hand_points = hand_pos.reshape(1, 3)
            
            # GPUè·é›¢è¨ˆç®—
            distances = self.gpu_distance_calc.point_to_triangle_distance_batch(
                hand_points, target_triangles, vertices
            )
            
            elapsed = (time.perf_counter() - start_time) * 1000
            self.gpu_stats['gpu_time_total_ms'] += elapsed
            
            if distances is not None and distances.size > 0:
                # è¡çªçµæœã‚’ç”Ÿæˆ
                return self._create_collision_info_from_distances(
                    distances, hand_pos, radius, vertices, triangles, search_result, elapsed
                )
            
            # è¡çªãªã—ã®å ´åˆ
            from src.collision.sphere_tri import CollisionInfo
            import numpy as _np
            return CollisionInfo(
                has_collision=False,
                contact_points=[],
                closest_point=None,
                total_penetration_depth=0.0,
                collision_normal=_np.array([0.0, 0.0, 1.0]),
                collision_time_ms=elapsed,
            )
            
        except Exception as e:
            logger.error(f"GPU collision testing failed: {e}, falling back to CPU")
            self.gpu_stats['cpu_fallbacks'] += 1
            if self.collision_tester is not None:
                return self.collision_tester.test_sphere_collision(hand_pos, radius, search_result)
            from src.collision.sphere_tri import CollisionInfo
            import numpy as _np
            return CollisionInfo(
                has_collision=False,
                contact_points=[],
                closest_point=None,
                total_penetration_depth=0.0,
                collision_normal=_np.array([0.0, 0.0, 1.0]),
                collision_time_ms=0.0,
            )
    
    def _create_collision_info_from_distances(self, distances: np.ndarray, hand_pos: np.ndarray, 
                                            radius: float, vertices: np.ndarray, 
                                            triangles: np.ndarray, search_result: Any,
                                            computation_time_ms: float) -> Any:
        """è·é›¢æƒ…å ±ã‹ã‚‰è¡çªæƒ…å ±ã‚’ç”Ÿæˆ"""
        from src.collision.sphere_tri import CollisionInfo, ContactPoint
        from src.types import CollisionType
        
        # è¡çªåˆ¤å®šï¼ˆåŠå¾„å†…ã®è·é›¢ï¼‰
        collision_mask = distances[0] <= radius
        collision_triangle_indices = np.array(search_result.triangle_indices)[collision_mask]
        collision_distances = distances[0][collision_mask]
        
        contact_points = []
        if len(collision_triangle_indices) > 0:
            for i, tri_idx in enumerate(collision_triangle_indices):
                # ä¸‰è§’å½¢ã®é‡å¿ƒã‚’æ¥è§¦ç‚¹ã¨ã—ã¦ä½¿ç”¨ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                tri_vertices = vertices[triangles[tri_idx]]
                centroid = np.mean(tri_vertices, axis=0)
                
                # æ³•ç·šè¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                v1 = tri_vertices[1] - tri_vertices[0]
                v2 = tri_vertices[2] - tri_vertices[0]
                normal = np.cross(v1, v2)
                normal = normal / (np.linalg.norm(normal) + 1e-8)
                
                from numpy import array as _arr
                contact_point = ContactPoint(
                    position=centroid,
                    normal=normal,
                    depth=float(radius - collision_distances[i]),
                    triangle_index=int(tri_idx),
                    barycentric=_arr([1.0 / 3, 1.0 / 3, 1.0 / 3]),
                    collision_type=CollisionType.FACE_COLLISION,
                )
                contact_points.append(contact_point)
        
        if not contact_points:
            import numpy as _np
            return CollisionInfo(
                has_collision=False,
                contact_points=[],
                closest_point=None,
                total_penetration_depth=0.0,
                collision_normal=_np.array([0.0, 0.0, 1.0]),
                collision_time_ms=computation_time_ms,
            )

        # Determine aggregate metrics
        closest_point = max(contact_points, key=lambda cp: cp.depth)
        total_penetration = sum(cp.depth for cp in contact_points)
        import numpy as _np
        avg_normal = _np.mean([cp.normal for cp in contact_points], axis=0)
        avg_normal = avg_normal / (_np.linalg.norm(avg_normal) + 1e-8)

        return CollisionInfo(
            has_collision=True,
            contact_points=contact_points,
            closest_point=closest_point,
            total_penetration_depth=total_penetration,
            collision_normal=avg_normal,
            collision_time_ms=computation_time_ms,
        )
    
    def _update_mesh_visualization(self, mesh: Any) -> None:
        """ãƒ¡ãƒƒã‚·ãƒ¥å¯è¦–åŒ–ã‚’æ›´æ–°"""
        if not hasattr(self, 'vis') or self.vis is None:
            return
        
        # æ—¢å­˜ã®ãƒ¡ãƒƒã‚·ãƒ¥ã‚¸ã‚ªãƒ¡ãƒˆãƒªã‚’å‰Šé™¤
        for geom in self.mesh_geometries:
            self.vis.remove_geometry(geom, reset_bounding_box=False)
        self.mesh_geometries.clear()
        
        try:
            # Open3Dãƒ¡ãƒƒã‚·ãƒ¥ã‚’ä½œæˆ
            o3d_mesh = o3d.geometry.TriangleMesh()
            o3d_mesh.vertices = o3d.utility.Vector3dVector(mesh.vertices)
            o3d_mesh.triangles = o3d.utility.Vector3iVector(mesh.triangles)
            
            # æ³•ç·šè¨ˆç®—
            o3d_mesh.compute_vertex_normals()
            
            # åŠé€æ˜ã®ãƒãƒ†ãƒªã‚¢ãƒ«è¨­å®š
            o3d_mesh.paint_uniform_color([0.8, 0.8, 0.9])  # è–„é’è‰²
            
            # ãƒ¯ã‚¤ãƒ¤ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
            wireframe = o3d.geometry.LineSet.create_from_triangle_mesh(o3d_mesh)
            wireframe.paint_uniform_color([0.3, 0.3, 0.7])  # é’è‰²
            
            # ã‚¸ã‚ªãƒ¡ãƒˆãƒªã‚’è¿½åŠ 
            self.vis.add_geometry(o3d_mesh, reset_bounding_box=False)
            self.vis.add_geometry(wireframe, reset_bounding_box=False)
            
            self.mesh_geometries.extend([o3d_mesh, wireframe])
            
            # -- Open3D ãƒãƒƒãƒ•ã‚¡æ›´æ–° (T-MESH-106) --
            try:
                self.vis.update_geometry(o3d_mesh)
                self.vis.update_geometry(wireframe)
            except Exception as _exc:  # pylint: disable=broad-except
                logger.debug("Open3D update_geometry failed: %s", _exc)
            
        except Exception as e:
            logger.error(f"ãƒ¡ãƒƒã‚·ãƒ¥å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _update_collision_visualization(self) -> None:
        """è¡çªå¯è¦–åŒ–ã‚’æ›´æ–°"""
        if not hasattr(self, 'vis') or self.vis is None:
            return
        
        # æ—¢å­˜ã®è¡çªã‚¸ã‚ªãƒ¡ãƒˆãƒªã‚’å‰Šé™¤
        for geom in self.collision_geometries:
            self.vis.remove_geometry(geom, reset_bounding_box=False)
        self.collision_geometries.clear()
        
        if not self.enable_collision_visualization:
            return
        
        try:
            # æ¥è§¦ç‚¹ã‚’å¯è¦–åŒ–
            self._visualize_contact_points()
            
            # è¡çªçƒã‚’å¯è¦–åŒ–
            self._visualize_collision_spheres()
        
        except Exception as e:
            logger.error(f"è¡çªå¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _visualize_contact_points(self) -> None:
        """æ¥è§¦ç‚¹ã‚’å¯è¦–åŒ–"""
        if self.vis is None:
            return
        for contact in self.current_collision_points:
            # ContactPointã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹
            position = contact.position
            normal = contact.normal
            
            # æ¥è§¦ç‚¹ï¼ˆçƒï¼‰
            contact_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.01)
            contact_sphere.translate(position)
            contact_sphere.paint_uniform_color([1.0, 0.0, 0.0])  # èµ¤è‰²
            
            # æ³•ç·šãƒ™ã‚¯ãƒˆãƒ«ï¼ˆç·šåˆ†ï¼‰
            normal_end = position + normal * 0.05
            normal_line = o3d.geometry.LineSet()
            normal_line.points = o3d.utility.Vector3dVector([position, normal_end])
            normal_line.lines = o3d.utility.Vector2iVector([[0, 1]])
            normal_line.paint_uniform_color([1.0, 1.0, 0.0])  # é»„è‰²
            
            self.vis.add_geometry(contact_sphere, reset_bounding_box=False)
            self.vis.add_geometry(normal_line, reset_bounding_box=False)
            
            self.collision_geometries.extend([contact_sphere, normal_line])
    
    def _visualize_collision_spheres(self) -> None:
        """è¡çªçƒã‚’å¯è¦–åŒ–"""
        if self.vis is None:
            return
        if self.current_tracked_hands:
            for tracked in self.current_tracked_hands:
                if tracked.position is not None:
                    hand_sphere = o3d.geometry.TriangleMesh.create_sphere(
                        radius=self.sphere_radius
                    )
                    hand_sphere.translate(tracked.position)
                    hand_sphere.paint_uniform_color([0.0, 1.0, 0.0])  # ç·‘è‰²
                    
                    # ãƒ¯ã‚¤ãƒ¤ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
                    wireframe = o3d.geometry.LineSet.create_from_triangle_mesh(hand_sphere)
                    wireframe.paint_uniform_color([0.0, 0.8, 0.0])
                    
                    self.vis.add_geometry(wireframe, reset_bounding_box=False)
                    self.collision_geometries.append(wireframe)
    
    def _update_visualization(self) -> None:
        """å¯è¦–åŒ–å…¨ä½“ã‚’æ›´æ–°"""
        if self.current_mesh and self.enable_collision_visualization:
            self._update_mesh_visualization(self.current_mesh)
        self._update_collision_visualization()

        # Open3D ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã¸å†æç”»ã‚’é€šçŸ¥ (MS3 â€“ Viewer refresh)
        self._refresh_viewer()

    # ------------------------------------------------------------------
    # 3D Viewer helpers
    # ------------------------------------------------------------------

    def _refresh_viewer(self) -> None:
        """Force Open3D visualizer to redraw the scene."""
        if hasattr(self, "vis") and self.vis is not None:
            try:
                self.vis.poll_events()
                self.vis.update_renderer()
            except Exception as exc:  # pylint: disable=broad-except
                logger.debug("Visualizer refresh failed: %s", exc)
    
    def _force_mesh_update(self) -> None:
        """ãƒ¡ãƒƒã‚·ãƒ¥å¼·åˆ¶æ›´æ–°ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        self.force_mesh_update_requested = True
    
    def _print_performance_stats(self) -> bool:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’å°åˆ·"""
        print("\n" + "="*50)
        print("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ")
        print("="*50)
        
        # åŸºæœ¬çµ±è¨ˆ
        self._print_basic_stats()
        
        # ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°çµ±è¨ˆ
        self._print_voxel_stats_details()
        
        # ãƒ¡ãƒƒã‚·ãƒ¥ã¨è¡çªæ¤œå‡ºçµ±è¨ˆ
        self._print_mesh_collision_stats()
        
        # éŸ³éŸ¿çµ±è¨ˆ
        self._print_audio_stats()
        
        print("="*50)
        return True
    
    def _print_basic_stats(self) -> None:
        """åŸºæœ¬çµ±è¨ˆã‚’å°åˆ·"""
        print(f"ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {self.perf_stats['frame_count']}")
        print(f"ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ : {self.frame_counter}")
        print(f"ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ™‚é–“: {self.perf_stats['total_pipeline_time']:.2f}ms")
        print(f"ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆæ™‚é–“: {self.perf_stats['mesh_generation_time']:.2f}ms")
        print(f"è¡çªæ¤œå‡ºæ™‚é–“: {self.perf_stats['collision_detection_time']:.2f}ms")
        print(f"éŸ³éŸ¿ç”Ÿæˆæ™‚é–“: {self.perf_stats['audio_synthesis_time']:.2f}ms")
        print(f"ç·è¡çªã‚¤ãƒ™ãƒ³ãƒˆæ•°: {self.perf_stats['collision_events_count']}")
        print(f"ç·éŸ³éŸ¿ãƒãƒ¼ãƒˆæ•°: {self.perf_stats['audio_notes_played']}")
    
    def _print_voxel_stats_details(self) -> None:
        """ãƒœã‚¯ã‚»ãƒ«çµ±è¨ˆã®è©³ç´°ã‚’å°åˆ·"""
        if self.pointcloud_converter:
            voxel_stats = self.pointcloud_converter.get_performance_stats()
            print(f"\n--- Point Cloud Optimization ---")
            print(f"ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: {'æœ‰åŠ¹' if voxel_stats.get('voxel_downsampling_enabled', False) else 'ç„¡åŠ¹'}")
            if voxel_stats.get('voxel_downsampling_enabled', False):
                print(f"  - ãƒœã‚¯ã‚»ãƒ«ã‚µã‚¤ã‚º: {voxel_stats.get('current_voxel_size_mm', 0):.1f}mm")
                print(f"  - æœ€æ–°å…¥åŠ›ç‚¹æ•°: {voxel_stats.get('last_input_points', 0):,}")
                print(f"  - æœ€æ–°å‡ºåŠ›ç‚¹æ•°: {voxel_stats.get('last_output_points', 0):,}")
                print(f"  - ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡: {voxel_stats.get('last_downsampling_ratio', 0)*100:.1f}%")
                print(f"  - å¹³å‡å‡¦ç†æ™‚é–“: {voxel_stats.get('average_time_ms', 0):.2f}ms")
    
    def _print_mesh_collision_stats(self) -> None:
        """ãƒ¡ãƒƒã‚·ãƒ¥ã¨è¡çªæ¤œå‡ºçµ±è¨ˆã‚’å°åˆ·"""
        if self.current_mesh:
            print(f"ç¾åœ¨ã®ãƒ¡ãƒƒã‚·ãƒ¥: {self.current_mesh.num_triangles}ä¸‰è§’å½¢")
        print(f"çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
    
    def _print_audio_stats(self) -> None:
        """éŸ³éŸ¿çµ±è¨ˆã‚’å°åˆ·"""
        if self.enable_audio_synthesis:
            print(f"éŸ³éŸ¿åˆæˆ: {'æœ‰åŠ¹' if self.audio_enabled else 'ç„¡åŠ¹'}")
            if self.audio_enabled:
                print(f"  - éŸ³éš: {self.audio_scale.value}")
                print(f"  - æ¥½å™¨: {self.audio_instrument.value}")
                print(f"  - éŸ³é‡: {self.audio_master_volume:.1f}")
                if self.voice_manager:
                    voice_stats = self.voice_manager.get_performance_stats()
                    print(f"  - ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒœã‚¤ã‚¹: {voice_stats['current_active_voices']}/{self.audio_polyphony}")
                    print(f"  - ç·ä½œæˆãƒœã‚¤ã‚¹: {voice_stats['total_voices_created']}")
                    print(f"  - ãƒœã‚¤ã‚¹ã‚¹ãƒ†ã‚£ãƒ¼ãƒ«: {voice_stats['total_voices_stolen']}")
    
    def _process_frame(self) -> bool:
        """1ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆçµ±ä¸€ç‰ˆï¼‰"""
        frame_start_time = time.perf_counter()
        
        # 3Dæ‰‹æ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®é…å»¶åˆæœŸåŒ–
        self._lazy_initialize_3d_components()
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—
        frame_data = self._get_frame_data()
        if frame_data is None:
            return True
        
        # æ·±åº¦ãƒ»ã‚«ãƒ©ãƒ¼ç”»åƒã®æŠ½å‡º
        depth_image, color_image = self._extract_images_from_frame(frame_data)
        if depth_image is None:
            return True
        
        # ã‚«ãƒ©ãƒ¼ç”»åƒã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆæ‰‹æ¤œå‡ºç”¨ï¼‰
        self._last_color_frame = color_image
        
        # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
        depth_image = self._apply_depth_filter(depth_image)
        
        # ---------------- Hand masking (P-HAND-002) ----------------
        from src.detection.hand_mask import HandMasker  # type: ignore
        if not hasattr(self, "_hand_masker"):
            self._hand_masker = HandMasker()

        depth_image_masked, centers_3d, radii_arr = self._hand_masker.apply_mask(
            depth_image,
            self.current_hands_2d,
            self.current_tracked_hands,
        )

        # æœ€æ–°æ·±åº¦ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._latest_depth_image = depth_image_masked

        # ç‚¹ç¾¤ç”Ÿæˆ
        points_3d = self._generate_point_cloud_if_needed(depth_image_masked)

        # æ‰‹æ¤œå‡ºå‡¦ç†ã¯ãƒã‚¹ã‚¯å‰ã®æ·±åº¦ç”»åƒã‚’ä½¿ç”¨

        hands_2d, hands_3d, tracked_hands = self._perform_hand_detection(depth_image)
        self._save_hand_detection_results(hands_2d, hands_3d, tracked_hands)

        # ----- adjust further references -----
        # Use adaptive exclusion when we regenerate pointcloud on subsequent calls
        self._exclude_centers_cached = (centers_3d, radii_arr)

        # Continue pipeline below so we need to skip duplicated code (return later edits)
        
        # è¡çªæ¤œå‡ºã¨ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        collision_events = self._process_collision_pipeline(points_3d, tracked_hands)
        
        # è¡¨ç¤ºå‡¦ç†ï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã§ã¯è¡¨ç¤ºã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        if not self.headless_mode:
            # RGBè¡¨ç¤ºå‡¦ç†
            if not self._process_rgb_display(frame_data, collision_events):
                return False
            
            # ç‚¹ç¾¤è¡¨ç¤ºå‡¦ç†
            if self.frame_count % self.update_interval == 0:
                if not self._process_pointcloud_display(frame_data):
                    return False
        
        self.frame_count += 1
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆæ›´æ–°
        frame_time = (time.perf_counter() - frame_start_time) * 1000
        self.performance_stats['frame_time'] = frame_time
        self.performance_stats['fps'] = 1000.0 / frame_time if frame_time > 0 else 0.0
        
        return True
    
    def _get_frame_data(self) -> Optional[Any]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚«ãƒ¡ãƒ©ã¾ãŸã¯ãƒ¢ãƒƒã‚¯ï¼‰"""
        if self.camera is None:
            # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ç”¨ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿
            if self.headless_mode:
                # é…å»¶ã§ãƒ¢ãƒƒã‚¯ã‚«ãƒ¡ãƒ©ã‚’ç”Ÿæˆ
                from typing import cast, Any
                from src.input.mock_camera import MockCamera

                if not hasattr(self, "_mock_camera"):
                    self._mock_camera = MockCamera(LOW_RESOLUTION[0], LOW_RESOLUTION[1])

                # å‹ãƒã‚§ãƒƒã‚«ãƒ¼å¯¾ç­–ã§ OrbbecCamera äº’æ›ã¨ã—ã¦æ‰±ã†
                self.camera = cast(Any, self._mock_camera)
                return self._mock_camera.get_frame()
            logger.warning("Camera not available")
            return None
        
        return self.camera.get_frame(timeout_ms=100)
    
    def _extract_images_from_frame(self, frame_data: Any) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ·±åº¦ãƒ»ã‚«ãƒ©ãƒ¼ç”»åƒã‚’æŠ½å‡º"""
        depth_image = None
        color_image = None
        
        if frame_data.depth_frame is not None:
            depth_image = self._extract_depth_image(frame_data)
        
        if frame_data.color_frame is not None:
            color_image = self._extract_color_image(frame_data)
        
        return depth_image, color_image
    
    def _lazy_initialize_3d_components(self) -> None:
        """3Dæ‰‹æ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®é…å»¶åˆæœŸåŒ–"""
        if not self._components_initialized and hasattr(self, 'camera') and self.camera is not None:
            try:
                logger.info("Setting up 3D hand detection components...")
                if self.camera.depth_intrinsics is not None:
                    # 3DæŠ•å½±å™¨ã®åˆæœŸåŒ–
                    self.projector_3d = Hand3DProjector(
                        self.camera.depth_intrinsics,
                        min_confidence_3d=0.1
                    )
                    # ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã®åˆæœŸåŒ–
                    self.tracker = Hand3DTracker()
                    
                    # ç‚¹ç¾¤ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼ã®åˆæœŸåŒ–ï¼ˆã¾ã ãªã„å ´åˆï¼‰
                    if not hasattr(self, 'pointcloud_converter') or self.pointcloud_converter is None:
                        self.pointcloud_converter = PointCloudConverter(
                            self.camera.depth_intrinsics,
                            enable_voxel_downsampling=self.voxel_downsampling_enabled,
                            voxel_size=self.voxel_size
                        )
                    
                    self._components_initialized = True
                    logger.info("3D hand detection components initialized")
                else:
                    logger.warning("Camera depth intrinsics not available")
            except Exception as e:
                logger.error(f"3D component initialization error: {e}")
    
    def _extract_depth_image(self, frame_data: Any) -> Optional[np.ndarray]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ·±åº¦ç”»åƒã‚’æŠ½å‡º"""
        try:
            if self.camera is None or self.camera.depth_intrinsics is None:
                # --------------------------------------------------------------
                # Determine frame dimensions in a robust manner
                # --------------------------------------------------------------
                df = frame_data.depth_frame
                width = None
                height = None

                # Newer pyorbbecsdk versions expose width/height attributes
                if hasattr(df, "width") and hasattr(df, "height"):
                    width = int(df.width)
                    height = int(df.height)
                # Older versions expose getter functions
                elif hasattr(df, "get_width") and hasattr(df, "get_height"):
                    try:
                        width = int(df.get_width())
                        height = int(df.get_height())
                    except Exception:  # pragma: no cover â€“ defensive
                        width, height = None, None

                if width is None or height is None:
                    logger.warning("DepthFrame size unavailable â€“ defaulting to 424x240")
                    width, height = 424, 240

                from src.input.pointcloud import _create_default_intrinsics  # local import
                logger.warning("depth_intrinsics is None â€“ using fallback intrinsics (%dx%d)", width, height)
                fallback_intr = _create_default_intrinsics(width, height)

                if self.camera is not None:
                    self.camera.depth_intrinsics = fallback_intr  # type: ignore[attr-defined]

                intr = fallback_intr
            else:
                intr = self.camera.depth_intrinsics

            depth_data = np.frombuffer(frame_data.depth_frame.get_data(), dtype=np.uint16)
            return depth_data.reshape((intr.height, intr.width))
        except Exception as e:
            logger.error(f"Failed to extract depth image: {e}")
            return None
    
    def _extract_color_image(self, frame_data: Any) -> Optional[np.ndarray]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚«ãƒ©ãƒ¼ç”»åƒã‚’æŠ½å‡º"""
        try:
            if (
                frame_data.color_frame is None
                or self.camera is None
                or not getattr(self.camera, "has_color", False)
            ):
                return None
            
            color_data = np.frombuffer(frame_data.color_frame.get_data(), dtype=np.uint8)
            color_format = frame_data.color_frame.get_format()
            
            # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›
            return self._convert_color_format(color_data, color_format)
        except Exception as e:
            logger.error(f"Failed to extract color image: {e}")
            return None
    
    def _apply_depth_filter(self, depth_image: np.ndarray) -> np.ndarray:
        """æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨"""
        if self.depth_filter is not None and self.enable_filter:
            filter_start_time = time.perf_counter()
            filtered = self.depth_filter.apply_filter(depth_image)
            self.performance_stats['filter_time'] = (time.perf_counter() - filter_start_time) * 1000
            return filtered
        else:
            self.performance_stats['filter_time'] = 0.0
            return depth_image
    
    def _generate_point_cloud_if_needed(self, depth_image: np.ndarray, *, force: bool = False) -> Optional[np.ndarray]:
        """å¿…è¦ã«å¿œã˜ã¦ç‚¹ç¾¤ã‚’ç”Ÿæˆ"""
        need_points_for_mesh = force or (
            self.enable_mesh_generation and 
            (self.frame_count - self.last_mesh_update >= self.mesh_update_interval)
        )
        
        if self.pointcloud_converter and (self.frame_count % self.update_interval == 0 or need_points_for_mesh):
            pointcloud_start = time.perf_counter()
            # Exclude hand vicinity points â€“ adaptive radii (P-HAND-002)
            if hasattr(self, "_exclude_centers_cached"):
                exc_centers, exc_radii = self._exclude_centers_cached
            else:
                exc_centers, exc_radii = None, 0.03

            points_3d, _ = self.pointcloud_converter.numpy_to_pointcloud(
                depth_image,
                exclude_centers=exc_centers,
                exclude_radii=exc_radii,
            )
            self.performance_stats['pointcloud_time'] = (time.perf_counter() - pointcloud_start) * 1000
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥
            if points_3d is not None:
                self._last_points_3d = points_3d
            
            if need_points_for_mesh and points_3d is not None:
                logger.info(f"[MESH-PREP] Frame {self.frame_count}: Generated {len(points_3d)} points for mesh update")
            return points_3d
        elif self.headless_mode and not self.camera and need_points_for_mesh:
            # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ç”¨ãƒ¢ãƒƒã‚¯ç‚¹ç¾¤
            mock_points = np.random.rand(5000, 3).astype(np.float32)
            mock_points[:, 2] += 0.5  # Zåº§æ¨™èª¿æ•´
            return mock_points
        
        return None
    
    def _process_hand_detection(self, depth_image: np.ndarray) -> Tuple[List, List, List]:
        """æ‰‹æ¤œå‡ºå‡¦ç†ã®å®Ÿè£…ï¼ˆè¦ªã‚¯ãƒ©ã‚¹ã‹ã‚‰ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼‰"""
        if not self.enable_hand_detection:
            return [], [], []
        
        hands_2d = []
        hands_3d = []
        tracked_hands = []
        
        # ã‚«ãƒ©ãƒ¼ç”»åƒå–å¾—ï¼ˆRGBæ‰‹æ¤œå‡ºç”¨ï¼‰
        if hasattr(self, 'camera') and self.camera and self.camera.has_color:
            try:
                # æœ€æ–°ã®ã‚«ãƒ©ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
                color_frame = getattr(self, '_last_color_frame', None)
                if color_frame is not None:
                    # 2Dæ‰‹æ¤œå‡ºï¼ˆMediaPipeï¼‰
                    if self.hands_2d is not None:
                        hands_2d = self.hands_2d.detect_hands(color_frame)
                    
                    # 3DæŠ•å½±
                    if hands_2d and self.projector_3d is not None:
                        for hand_2d in hands_2d:
                            # é–¢æ•°åä¿®æ­£: Hand3DProjector.project_hand_to_3d ã«åˆã‚ã›ã‚‹
                            hand_3d = self.projector_3d.project_hand_to_3d(hand_2d, depth_image)
                            if hand_3d is not None:
                                hands_3d.append(hand_3d)
                    
                    # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
                    if self.enable_tracking and self.tracker is not None and hands_3d:
                        tracked_hands = self.tracker.update(hands_3d)
            except Exception as e:
                logger.error(f"Hand detection error: {e}")
        
        return hands_2d, hands_3d, tracked_hands
    
    def _perform_hand_detection(self, depth_image: np.ndarray) -> Tuple[List, List, List]:
        """æ‰‹æ¤œå‡ºå‡¦ç†ã‚’å®Ÿè¡Œï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆæ¸¬ä»˜ãï¼‰"""
        if self.enable_hand_detection and self.hands_2d is not None:
            hand_start_time = time.perf_counter()
            hands_2d, hands_3d, tracked_hands = self._process_hand_detection(depth_image)
            self.performance_stats['hand_detection_time'] = (time.perf_counter() - hand_start_time) * 1000
            
            if self.frame_count % 10 == 0 and any([hands_2d, hands_3d, tracked_hands]):
                logger.info(f"[HAND-DETECT] Frame {self.frame_count}: "
                           f"2D:{len(hands_2d)}, 3D:{len(hands_3d)}, Tracked:{len(tracked_hands)} "
                           f"({self.performance_stats['hand_detection_time']:.1f}ms)")
            
            return hands_2d, hands_3d, tracked_hands
        else:
            self.performance_stats['hand_detection_time'] = 0.0
            return [], [], []
    
    def _save_hand_detection_results(self, hands_2d: List, hands_3d: List, tracked_hands: List) -> None:
        """æ‰‹æ¤œå‡ºçµæœã‚’ä¿å­˜"""
        self.current_hands_2d = hands_2d
        self.current_hands_3d = hands_3d
        self.current_tracked_hands = tracked_hands
    
        # --- Maintain short history for predictive collision (tap detection) ---
        if not hasattr(self, "_hand_position_history"):
            self._hand_position_history: Dict[str, List[np.ndarray]] = {}

        # Update history per hand
        active_ids = set()
        for th in tracked_hands:
            hid = th.id
            active_ids.add(hid)
            if hid not in self._hand_position_history:
                self._hand_position_history[hid] = []
            if th.position is not None:
                self._hand_position_history[hid].append(np.array(th.position, dtype=float))
            # Keep last 3 positions max
            if len(self._hand_position_history[hid]) > 3:
                self._hand_position_history[hid].pop(0)

        # Remove stale hands from history
        stale_ids = [hid for hid in self._hand_position_history.keys() if hid not in active_ids]
        for hid in stale_ids:
            del self._hand_position_history[hid]
    
    def _process_collision_pipeline(self, points_3d: Optional[np.ndarray], 
                                   tracked_hands: List[TrackedHand]) -> List[Any]:
        """è¡çªæ¤œå‡ºã¨ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†"""
        pipeline_start = time.perf_counter()
        self.frame_counter = self.frame_count
        collision_events = []
        
        # Mesh update via PipelineManager (asynchronous-ready)
        res = self.pipeline_manager.update_if_needed(points_3d, tracked_hands)

        if res.mesh is not None and (
            self._mesh_version != self.pipeline_manager.get_version()
        ):
            # Mesh changed or needs refresh
            self.current_mesh = res.mesh
            self._mesh_version = self.pipeline_manager.get_version()

            # Rebuild index only when res.changed True
            if res.changed or self.spatial_index is None:
                self.spatial_index = SpatialIndex(res.mesh, index_type=IndexType.BVH)
                self.collision_searcher = CollisionSearcher(self.spatial_index)
                self.collision_tester = SphereTriangleCollision(res.mesh)

            self._update_mesh_visualization(res.mesh)
        
        # è¡çªæ¤œå‡º
        if self.enable_collision_detection and self.current_mesh is not None and tracked_hands:
            collision_events = self._perform_collision_detection(tracked_hands)
        
        # éŸ³éŸ¿ç”Ÿæˆ
        if self.enable_audio_synthesis and self.audio_enabled and collision_events:
            self._perform_audio_synthesis(collision_events)
        
        self.perf_stats['total_pipeline_time'] = (time.perf_counter() - pipeline_start) * 1000
        
        # ---- Memory hygiene: purge processed collision events (T-MEM-001) ----
        if hasattr(self, 'event_queue') and self.event_queue is not None:
            try:
                self.event_queue.pop_processed(max_length=256)
            except AttributeError:
                # Older versions of CollisionEventQueue may lack this method
                # (e.g. when running mixed code revisions). Fallback: clear if too big.
                if len(self.event_queue.event_queue) > 512:
                    while len(self.event_queue.event_queue) > 256:
                        self.event_queue.event_queue.popleft()

        return collision_events
    
    def _should_update_mesh(self, tracked_hands: List[TrackedHand], 
                           points_3d: Optional[np.ndarray]) -> bool:
        """ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯"""
        hands_present = len(tracked_hands) > 0
        frame_diff = self.frame_count - self.last_mesh_update
        
        mesh_condition = (
            self.enable_mesh_generation and (
                self.force_mesh_update_requested or
                (not hands_present and frame_diff >= self.mesh_update_interval) or
                (frame_diff >= self.max_mesh_skip_frames) or
                (self.current_mesh is None)
            ) and
            (
                points_3d is not None
                or self._last_points_3d is not None
            )
        )
        
        # è¨ºæ–­ãƒ­ã‚°
        if self.frame_count % 10 == 0:
            logger.debug(f"[MESH-DIAG] Frame {self.frame_count}: enable_mesh={self.enable_mesh_generation}, "
                        f"frame_diff={frame_diff}, points={len(points_3d) if points_3d is not None else 'None'}, "
                        f"condition={mesh_condition}")
        
        return mesh_condition
    
    def _perform_collision_detection(self, tracked_hands: List[TrackedHand]) -> List[Any]:
        """è¡çªæ¤œå‡ºã‚’å®Ÿè¡Œ"""
        logger.info(f"[COLLISION] Frame {self.frame_count}: *** CHECKING COLLISIONS *** "
                   f"with {len(tracked_hands)} hands and mesh available")
        
        collision_start = time.perf_counter()
        collision_events = self._detect_collisions(tracked_hands)
        
        self.perf_stats['collision_detection_time'] = (time.perf_counter() - collision_start) * 1000
        self.perf_stats['collision_events_count'] += len(collision_events)
        
        if len(collision_events) > 0:
            logger.info(f"[COLLISION] Frame {self.frame_count}: *** COLLISION DETECTED! *** "
                       f"{len(collision_events)} events")
        else:
            logger.info(f"[COLLISION] Frame {self.frame_count}: No collisions detected")
        
        return collision_events
    
    def _perform_audio_synthesis(self, collision_events: List[Any]) -> None:
        """éŸ³éŸ¿åˆæˆã‚’å®Ÿè¡Œ"""
        audio_start = time.perf_counter()
        logger.info(f"[AUDIO] Frame {self.frame_count}: *** GENERATING AUDIO *** "
                   f"for {len(collision_events)} collision events")
        
        audio_notes = self._generate_audio(collision_events)
        self.perf_stats['audio_notes_played'] += audio_notes
        self.perf_stats['audio_synthesis_time'] = (time.perf_counter() - audio_start) * 1000
        
        logger.info(f"[AUDIO] Frame {self.frame_count}: Generated {audio_notes} audio notes in "
                   f"{self.perf_stats['audio_synthesis_time']:.1f}ms")
    
    # éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ é–¢é€£ãƒ¡ã‚½ãƒƒãƒ‰
    def _initialize_audio_system(self) -> None:
        """éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–"""
        try:
            logger.info("éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­...")
            
            # éŸ³éŸ¿ãƒãƒƒãƒ‘ãƒ¼åˆæœŸåŒ–
            self.audio_mapper = AudioMapper(
                scale=self.audio_scale,
                default_instrument=self.audio_instrument,
                pitch_range=(48, 84),  # C3-C6
                enable_adaptive_mapping=True
            )
            
            # éŸ³éŸ¿ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
            self.audio_synthesizer = create_audio_synthesizer(
                sample_rate=44100,
                buffer_size=256,
                max_polyphony=self.audio_polyphony
            )
            
            # éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³é–‹å§‹
            if self.audio_synthesizer.start_engine():
                # ãƒœã‚¤ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
                self.voice_manager = create_voice_manager(
                    self.audio_synthesizer,
                    max_polyphony=self.audio_polyphony,
                    steal_strategy=StealStrategy.OLDEST
                )
                
                # ãƒã‚¹ã‚¿ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ è¨­å®š
                self.audio_synthesizer.update_master_volume(self.audio_master_volume)
                
                self.audio_enabled = True
                logger.info("éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            else:
                logger.error("éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ")
                self.audio_enabled = False
        
        except Exception as e:
            logger.error(f"éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.audio_enabled = False
    
    def _shutdown_audio_system(self) -> None:
        """éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢"""
        try:
            logger.info("[AUDIO-SHUTDOWN] éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ä¸­...")
            self.audio_enabled = False
            
            # ãƒœã‚¤ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åœæ­¢
            if self.voice_manager:
                try:
                    self.voice_manager.stop_all_voices(fade_out_time=0.01)
                    time.sleep(0.05)
                    self.voice_manager = None
                except Exception as e:
                    logger.error(f"[AUDIO-SHUTDOWN] VoiceManageråœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ãƒ¼ã‚¨ãƒ³ã‚¸ãƒ³ã®åœæ­¢
            if self.audio_synthesizer:
                try:
                    self.audio_synthesizer.stop_engine()
                    time.sleep(0.05)
                    self.audio_synthesizer = None
                except Exception as e:
                    logger.error(f"[AUDIO-SHUTDOWN] Synthesizeråœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            
            # éŸ³éŸ¿ãƒãƒƒãƒ‘ãƒ¼ã‚‚ã‚¯ãƒªã‚¢
            self.audio_mapper = None
            
            logger.info("[AUDIO-SHUTDOWN] éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã—ã¾ã—ãŸ")
        
        except Exception as e:
            logger.error(f"[AUDIO-SHUTDOWN] éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ åœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            self.audio_enabled = False
    
    def _restart_audio_system(self) -> None:
        """éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’å†èµ·å‹•"""
        self._shutdown_audio_system()
        time.sleep(0.1)
        if self.enable_audio_synthesis:
            self._initialize_audio_system()
    
    def _generate_audio(self, collision_events: List[Any]) -> int:
        """è¡çªã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰éŸ³éŸ¿ã‚’ç”Ÿæˆ"""
        if not self.audio_enabled or not self.audio_mapper or not self.voice_manager:
            return 0
        
        notes_played = 0
        current_time = time.perf_counter()
        
        for event in collision_events:
            try:
                # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒã‚§ãƒƒã‚¯
                if not self._check_audio_cooldown(event.hand_id, current_time):
                    continue
                
                # ãƒ‡ãƒã‚¦ãƒ³ã‚¹
                if not self._check_contact_debounce(event):
                    continue
                
                # éŸ³éŸ¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒƒãƒ”ãƒ³ã‚°
                audio_params = self.audio_mapper.map_collision_event(event)
                
                # ç©ºé–“ä½ç½®è¨­å®š
                spatial_position = self._get_spatial_position(event)
                
                # éŸ³éŸ¿å†ç”Ÿ
                voice_id = allocate_and_play(
                    self.voice_manager,
                    audio_params,
                    priority=7,
                    spatial_position=spatial_position
                )
                
                if voice_id:
                    notes_played += 1
                    self.last_audio_trigger_time[event.hand_id] = current_time
                    logger.debug(f"[AUDIO-TRIGGER] Hand {event.hand_id}: Note triggered")
                    # è¨˜éŒ² â€“ debounce ã¨åŒã˜ã‚­ãƒ¼å½¢å¼ (hand_id, gx, gy, gz)
                    gx = int(round(event.contact_position[0] * 50))
                    gy = int(round(event.contact_position[1] * 50))
                    gz = int(round(event.contact_position[2] * 50))
                    self._last_contact_trigger_time[(event.hand_id, gx, gy, gz)] = current_time

                    # Keep the debounce map bounded (T-MEM-001)
                    if len(self._last_contact_trigger_time) > 500:
                        # Remove ~20% oldest entries to avoid frequent churn
                        for _ in range(int(0.2 * len(self._last_contact_trigger_time))):
                            try:
                                self._last_contact_trigger_time.pop(next(iter(self._last_contact_trigger_time)))
                            except Exception:  # pragma: no cover
                                break
            
            except Exception as e:
                logger.error(f"éŸ³éŸ¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆ: {event.event_id}ï¼‰: {e}")
        
        # ãƒœã‚¤ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if self.voice_manager and self.frame_count % 10 == 0:
            try:
                self.voice_manager.cleanup_finished_voices()
            except Exception as e:
                logger.error(f"[AUDIO-CLEANUP] Error during cleanup: {e}")
        
        return notes_played
    
    def _check_audio_cooldown(self, hand_id: int, current_time: float) -> bool:
        """éŸ³éŸ¿ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯"""
        last_trigger = self.last_audio_trigger_time.get(hand_id, 0)
        time_since_last = current_time - last_trigger
        
        if time_since_last < self.audio_cooldown_time:
            logger.debug(f"[AUDIO-COOLDOWN] Hand {hand_id}: {time_since_last*1000:.1f}ms since last trigger")
            return False
        
        return True
    
    def _check_contact_debounce(self, event: Any) -> bool:
        """æ‰‹ID + æ¥è§¦ä½ç½®ã‚°ãƒªãƒƒãƒ‰ (â‰ˆ2 cm) ã§ 250 ms ãƒ‡ãƒã‚¦ãƒ³ã‚¹"""
        gx = int(round(event.contact_position[0] * 50))  # 1/50 m = 2 cm
        gy = int(round(event.contact_position[1] * 50))
        gz = int(round(event.contact_position[2] * 50))
        key = (event.hand_id, gx, gy, gz)
        last_t = self._last_contact_trigger_time.get(key, 0.0)
        if (time.perf_counter() - last_t) < 0.25:  # 250 ms
            return False
        return True
    
    def _get_spatial_position(self, event: Any) -> np.ndarray:
        """ã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰ç©ºé–“ä½ç½®ã‚’å–å¾—"""
        return np.array([
            float(event.contact_position[0]),
            0.0,
            float(event.contact_position[2])
        ], dtype=float)
    
    def _cycle_audio_scale(self) -> bool:
        """éŸ³éšã‚’å¾ªç’°åˆ‡ã‚Šæ›¿ãˆ"""
        scales = list(ScaleType)
        current_index = scales.index(self.audio_scale)
        next_index = (current_index + 1) % len(scales)
        self.audio_scale = scales[next_index]
        
        if self.audio_mapper:
            self.audio_mapper.set_scale(self.audio_scale)
        
        print(f"éŸ³éšã‚’åˆ‡ã‚Šæ›¿ãˆ: {self.audio_scale.value}")
        return True
    
    def _cycle_audio_instrument(self) -> bool:
        """æ¥½å™¨ã‚’å¾ªç’°åˆ‡ã‚Šæ›¿ãˆ"""
        instruments = list(InstrumentType)
        current_index = instruments.index(self.audio_instrument)
        next_index = (current_index + 1) % len(instruments)
        self.audio_instrument = instruments[next_index]
        
        if self.audio_mapper:
            self.audio_mapper.default_instrument = self.audio_instrument
        
        print(f"æ¥½å™¨ã‚’åˆ‡ã‚Šæ›¿ãˆ: {self.audio_instrument.value}")
        return True
    
    def __del__(self):
        """ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿"""
        try:
            if hasattr(self, 'audio_enabled') and self.audio_enabled:
                logger.info("[DESTRUCTOR] éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
                self._shutdown_audio_system()
        except Exception as e:
            logger.error(f"[DESTRUCTOR] ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã§ã‚¨ãƒ©ãƒ¼: {e}")
    
    def cleanup(self):
        """æ˜ç¤ºçš„ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ¡ã‚½ãƒƒãƒ‰"""
        try:
            if self.audio_enabled:
                self._shutdown_audio_system()
        except Exception as e:
            logger.error(f"[CLEANUP] ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _process_rgb_display(self, frame_data: Any, collision_events: Optional[List[Any]] = None) -> bool:
        """RGBè¡¨ç¤ºå‡¦ç†ï¼ˆè¡çªæ¤œå‡ºç‰ˆï¼‰"""
        try:
            # æ·±åº¦ç”»åƒã®å¯è¦–åŒ–
            depth_image = self._extract_depth_image(frame_data)
            if depth_image is None:
                return True
            
            depth_colored = self._create_depth_visualization(depth_image)
            
            # è¡¨ç¤ºç”»åƒã®æº–å‚™
            display_images = []
            
            # æ·±åº¦ç”»åƒè¿½åŠ 
            depth_resized = cv2.resize(depth_colored, self.rgb_window_size)
            cv2.putText(depth_resized, f"Depth (Frame: {self.frame_count})", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            display_images.append(depth_resized)
            
            # RGBç”»åƒå‡¦ç†ï¼ˆæ‰‹æ¤œå‡ºçµæœã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ï¼‰
            color_bgr = self._process_color_image(
                frame_data, 
                self.current_hands_2d,
                self.current_hands_3d,
                self.current_tracked_hands,
                collision_events
            )

            # ===== Flicker fix =====
            if not hasattr(self, "_last_color_bgr"):
                self._last_color_bgr = None  # åˆæœŸåŒ–

            if color_bgr is None:
                # ã‚«ãƒ©ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå–å¾—ã§ããªã‹ã£ãŸå ´åˆã¯å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å†åˆ©ç”¨
                if self._last_color_bgr is not None:
                    color_bgr = self._last_color_bgr
                else:
                    # ã¾ã ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒç„¡ã‘ã‚Œã°é»’ç”»åƒã§åŸ‹ã‚ã‚‹
                    color_bgr = np.zeros((self.rgb_window_size[1], self.rgb_window_size[0], 3), dtype=np.uint8)
            else:
                # æ­£å¸¸ã«å–å¾—ã§ããŸå ´åˆã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°
                self._last_color_bgr = color_bgr

            # ã‚«ãƒ©ãƒ¼ç”»åƒã‚’è¡¨ç¤ºç”¨ãƒªã‚¹ãƒˆã«è¿½åŠ 
            display_images.append(color_bgr)
            
            # ç”»åƒã‚’çµåˆã—ã¦è¡¨ç¤º
            combined_image = self._combine_display_images(display_images)
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
            if hasattr(super(), '_draw_performance_overlay'):
                super()._draw_performance_overlay(combined_image)
            
            # è¡çªæ¤œå‡ºãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’è¿½åŠ 
            self._draw_collision_performance_info(combined_image, collision_events)
            
            cv2.imshow("Geocussion-SP Input Viewer", combined_image)
            
            # ã‚­ãƒ¼å…¥åŠ›å‡¦ç†
            key = cv2.waitKey(1) & 0xFF
            return self.handle_key_event(key)
            
        except Exception as e:
            logger.error(f"RGB display error: {e}")
            return True
    
    def _create_depth_visualization(self, depth_image: np.ndarray) -> np.ndarray:
        """æ·±åº¦ç”»åƒã®å¯è¦–åŒ–ã‚’ä½œæˆ"""
        # Manual normalization to avoid cv2 stub type issues
        assert depth_image is not None
        d_min = float(depth_image.min())
        d_ptp = float(depth_image.ptp()) if depth_image.ptp() > 0 else 1.0
        depth_normalized = ((depth_image.astype(np.float32) - d_min) / d_ptp * 255.0).astype(np.uint8)
        return cv2.applyColorMap(depth_normalized, cv2.COLORMAP_JET)
    
    def _process_color_image(self, frame_data: Any, hands_2d: List, hands_3d: List, 
                           tracked_hands: List, collision_events: Optional[List[Any]]) -> Optional[np.ndarray]:
        """ã‚«ãƒ©ãƒ¼ç”»åƒã‚’å‡¦ç†"""
        if (
            frame_data.color_frame is None
            or self.camera is None
            or not getattr(self.camera, "has_color", False)
        ):
            return None
        
        color_data = np.frombuffer(frame_data.color_frame.get_data(), dtype=np.uint8)
        color_format = frame_data.color_frame.get_format()
        
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›
        color_image = self._convert_color_format(color_data, color_format)
        if color_image is None:
            return None
        
        # æ—¢ã« BGR é…åˆ—ã«ãªã£ã¦ã„ã‚‹ã®ã§ã€ãã®ã¾ã¾ãƒªã‚µã‚¤ã‚ºã—ã¦ä½¿ç”¨ã™ã‚‹
        color_bgr = cv2.resize(color_image, self.rgb_window_size)
        
        # æ‰‹æ¤œå‡ºçµæœã‚’æç”»
        if self.enable_hand_detection and hands_2d:
            color_bgr = self._draw_hand_detections(color_bgr, hands_2d, hands_3d, tracked_hands)
        
        # è¡çªæ¤œå‡ºæƒ…å ±ã‚’æç”»
        if collision_events:
            self._draw_collision_info(color_bgr, collision_events)
        
        cv2.putText(color_bgr, f"RGB (FPS: {self.performance_stats['fps']:.1f})", 
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        return color_bgr
    
    def _convert_color_format(self, color_data: np.ndarray, color_format: Any) -> Optional[np.ndarray]:
        """ã‚«ãƒ©ãƒ¼ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å¤‰æ›"""
        try:
            # MediaPipe ã®å…¥åŠ›ã¯ BGR ã‚’æƒ³å®šã—ã¦ã„ã‚‹ã®ã§ã€å¸¸ã« BGR é…åˆ—ã‚’è¿”ã™
            if color_format == OBFormat.RGB:
                # RGB â†’ BGR ã¸å¤‰æ›
                rgb_image = color_data.reshape((720, 1280, 3))
                return cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR)
            elif color_format == OBFormat.BGR:
                # ãã®ã¾ã¾ reshape
                return color_data.reshape((720, 1280, 3))
            elif color_format == OBFormat.MJPG:
                # imdecode ã¯ BGR ã§è¿”ã‚‹
                color_image = cv2.imdecode(color_data, cv2.IMREAD_COLOR)
                return color_image
        except Exception as e:
            logger.error(f"Color format conversion error: {e}")
        
        return None
    
    def _combine_display_images(self, display_images: List[np.ndarray]) -> np.ndarray:
        """è¡¨ç¤ºç”»åƒã‚’çµåˆ"""
        if len(display_images) > 1:
            return np.hstack(display_images)
        else:
            return display_images[0]
    
    def _draw_collision_info(self, image: np.ndarray, collision_events: List[Any]) -> None:
        """è¡çªæƒ…å ±ã‚’RGBç”»åƒã«æç”»"""
        if not collision_events:
            return
        
        # è¡çªã‚¤ãƒ™ãƒ³ãƒˆè¡¨ç¤º
        cv2.putText(image, f"COLLISION DETECTED! ({len(collision_events)} events)", 
                   (10, image.shape[0] - 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)
        
        # éŸ³éŸ¿å†ç”Ÿè¡¨ç¤º
        if self.enable_audio_synthesis and self.audio_enabled:
            cv2.putText(image, f"PLAYING AUDIO ({self.audio_instrument.value})", 
                       (10, image.shape[0] - 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
    
    def _draw_collision_performance_info(self, image: np.ndarray, collision_events: Optional[List[Any]]) -> None:
        """è¡çªæ¤œå‡ºãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’æç”»"""
        if not hasattr(self, 'perf_stats'):
            return
        
        # æƒ…å ±ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        info_lines = [
            f"Mesh: {self.perf_stats.get('mesh_generation_time', 0):.1f}ms",
            f"Collision: {self.perf_stats.get('collision_detection_time', 0):.1f}ms",
            f"Audio: {self.perf_stats.get('audio_synthesis_time', 0):.1f}ms",
            f"Events: {len(collision_events) if collision_events else 0}",
            f"Sphere R: {self.sphere_radius*100:.1f}cm"
        ]
        
        # ãƒœã‚¯ã‚»ãƒ«æƒ…å ±è¿½åŠ 
        self._add_voxel_info_to_lines(info_lines)
        
        # ãƒ¡ãƒƒã‚·ãƒ¥æƒ…å ±è¿½åŠ 
        if self.current_mesh:
            info_lines.append(f"Triangles: {self.current_mesh.num_triangles}")
        
        if self.current_collision_points:
            info_lines.append(f"Contacts: {len(self.current_collision_points)}")
        
        # å³å´ã«æç”»
        x_offset = image.shape[1] - 200
        y_offset = 30
        for i, line in enumerate(info_lines):
            cv2.putText(image, line, (x_offset, y_offset + i * 25), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
    
    def _add_voxel_info_to_lines(self, info_lines: List[str]) -> None:
        """ãƒœã‚¯ã‚»ãƒ«æƒ…å ±ã‚’è¡Œãƒªã‚¹ãƒˆã«è¿½åŠ """
        if self.pointcloud_converter:
            voxel_stats = self.pointcloud_converter.get_performance_stats()
            if voxel_stats.get('voxel_downsampling_enabled', False):
                ratio = voxel_stats.get('last_downsampling_ratio', 0)
                voxel_size = voxel_stats.get('current_voxel_size_mm', 0)
                info_lines.append(f"Voxel: {ratio*100:.0f}% @ {voxel_size:.1f}mm")
            else:
                info_lines.append("Voxel: OFF")
    
    def run(self):
        """ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚’å®Ÿè¡Œ"""
        if self.headless_mode:
            self.run_headless()
        else:
            super().run()
    
    def run_headless(self):
        """ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œ"""
        print("\nğŸ–¥ï¸  ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰é–‹å§‹ - GUIç„¡åŠ¹åŒ–ã«ã‚ˆã‚‹FPSæœ€é©åŒ–")
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {self.headless_duration}ç§’")
        print("=" * 50)
        
        # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ãƒ•ãƒ©ã‚°ã‚’è¨­å®š
        self.headless_mode = True
        
        # ã‚«ãƒ¡ãƒ©ãŒãªã„å ´åˆã¯ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–
        if not self.camera:
            print("ğŸ”§ ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
        
        print("\nğŸ¯ ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†é–‹å§‹...")
        print("=" * 50)
        
        # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹å®Ÿè¡Œãƒ«ãƒ¼ãƒ—
        start_time = time.time()
        frame_count = 0
        fps_samples = []
        last_report_time = start_time
        
        try:
            while time.time() - start_time < self.headless_duration:
                frame_start = time.time()
                
                # é€šå¸¸ã®ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚’å®Ÿè¡Œï¼ˆè¡¨ç¤ºã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹ï¼‰
                success = self._process_frame()
                
                if success:
                    frame_count += 1
                    frame_time = time.time() - frame_start
                    current_fps = 1.0 / frame_time if frame_time > 0 else 0
                    fps_samples.append(current_fps)
                    
                    # å®šæœŸçš„ãªçµ±è¨ˆè¡¨ç¤º
                    elapsed = time.time() - start_time
                    if elapsed - (last_report_time - start_time) >= 5.0:
                        avg_fps = sum(fps_samples[-100:]) / len(fps_samples[-100:]) if fps_samples else 0
                        print(f"ğŸ“Š [{elapsed:.1f}s] ãƒ•ãƒ¬ãƒ¼ãƒ : {frame_count}, å¹³å‡FPS: {avg_fps:.1f}, ç¾åœ¨FPS: {current_fps:.1f}")
                        last_report_time = time.time()
                        
        except KeyboardInterrupt:
            print("\nâ¹ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ä¸­æ–­")
        except Exception as e:
            logger.error(f"ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
        
        # çµæœè¡¨ç¤º
        self._display_headless_results({
            'execution_time': time.time() - start_time,
            'frame_count': frame_count,
            'fps_samples': fps_samples
        })
    

    
    def _display_headless_results(self, results: Dict[str, Any]) -> None:
        """ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹å®Ÿè¡Œçµæœã‚’è¡¨ç¤º"""
        execution_time = results['execution_time']
        frame_count = results['frame_count']
        fps_samples = results.get('fps_samples', [])
        
        # çµ±è¨ˆè¨ˆç®—
        avg_fps = frame_count / execution_time if execution_time > 0 else 0
        max_fps = max(fps_samples) if fps_samples else 0
        min_fps = min(fps_samples) if fps_samples else 0
        
        # çµæœè¡¨ç¤º
        print("\n" + "=" * 50)
        print("ğŸ ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ å®Ÿè¡Œçµæœ")
        print("=" * 50)
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {execution_time:.1f}ç§’")
        print(f"ğŸ¬ ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frame_count}")
        print(f"ğŸš€ å¹³å‡FPS: {avg_fps:.1f}")
        print(f"ğŸ“ˆ æœ€å¤§FPS: {max_fps:.1f}")
        print(f"ğŸ“‰ æœ€å°FPS: {min_fps:.1f}")
        print(f"ğŸµ è¡çªã‚¤ãƒ™ãƒ³ãƒˆç·æ•°: {self.perf_stats.get('collision_events_count', 0)}")
        print(f"ğŸ”Š éŸ³éŸ¿ãƒãƒ¼ãƒˆç·æ•°: {self.perf_stats.get('audio_notes_played', 0)}")
        
        # ROI ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°çµ±è¨ˆ
        if self.hands_2d is not None and hasattr(self.hands_2d, 'get_roi_tracking_stats'):
            self._display_roi_tracking_stats()
        
        print()
    
    def _display_roi_tracking_stats(self) -> None:
        """ROIãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°çµ±è¨ˆã‚’è¡¨ç¤º"""
        if self.hands_2d is not None and hasattr(self.hands_2d, 'get_roi_tracking_stats'):
            roi_stats = self.hands_2d.get_roi_tracking_stats()
            print(f"\nğŸ“Š ROI ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°çµ±è¨ˆ:")
            print(f"   MediaPipe å®Ÿè¡Œ: {roi_stats.mediapipe_executions}/{roi_stats.total_frames}")
            print(f"   ã‚¹ã‚­ãƒƒãƒ—ç‡: {roi_stats.skip_ratio*100:.1f}%")
            print(f"   ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æˆåŠŸç‡: {roi_stats.success_rate*100:.1f}%")
            
            if roi_stats.mediapipe_executions > 0:
                avg_mediapipe_time = roi_stats.total_mediapipe_time_ms / roi_stats.mediapipe_executions
                print(f"   å¹³å‡MediaPipeæ™‚é–“: {avg_mediapipe_time:.1f}ms")
            
            if roi_stats.tracking_successes > 0:
                avg_tracking_time = roi_stats.total_tracking_time_ms / roi_stats.tracking_successes
                print(f"   å¹³å‡ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æ™‚é–“: {avg_tracking_time:.1f}ms")
    

    
    def _draw_hand_detections(self, image: np.ndarray, hands_2d: List, hands_3d: List, 
                             tracked_hands: List) -> np.ndarray:
        """æ‰‹æ¤œå‡ºçµæœã‚’æç”»ï¼ˆè¦ªã‚¯ãƒ©ã‚¹ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼‰"""
        # è¦ªã‚¯ãƒ©ã‚¹ã®å®Ÿè£…ãŒã‚ã‚Œã°ä½¿ç”¨
        if hasattr(super(), '_draw_hand_detections'):
            return super()._draw_hand_detections(image, hands_2d, hands_3d, tracked_hands)  # type: ignore[attr-defined]
        
        # --- Custom implementation for our HandDetectionResult dataclass ---
        if hands_2d and self.hands_2d is not None:
            for hand_result in hands_2d:
                try:
                    image = self.hands_2d.draw_landmarks(image, hand_result)
                except Exception as e:
                    logger.debug(f"Landmark draw error: {e}")
        
        # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æƒ…å ±ã‚’æç”»
        if tracked_hands:
            for i, tracked in enumerate(tracked_hands):
                if tracked.position is not None:
                    info_text = f"Hand {tracked.id}: {tracked.position[2]:.2f}m"
                    cv2.putText(image, info_text, (10, 60 + i * 25),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        return image
    
    def _draw_performance_overlay(self, image: np.ndarray) -> None:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼ˆè¦ªã‚¯ãƒ©ã‚¹ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼‰"""
        # è¦ªã‚¯ãƒ©ã‚¹ã®å®Ÿè£…ãŒã‚ã‚Œã°ä½¿ç”¨
        if hasattr(super(), '_draw_performance_overlay'):
            super()._draw_performance_overlay(image)
            return
        
        # ç°¡æ˜“å®Ÿè£…
        fps = self.performance_stats.get('fps', 0.0)
        frame_time = self.performance_stats.get('frame_time', 0.0)
        
        info_text = f"FPS: {fps:.1f} | Frame: {frame_time:.1f}ms"
        cv2.putText(image, info_text, (10, image.shape[0] - 10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        # ã“ã“ã§çµ‚äº†ã€‚è¿½åŠ ã®æˆ»ã‚Šå€¤ã¯ä¸è¦ (-> None)
        return

    # ---------------------------------------------------------------------
    # Fallback: traditional mesh generation (used when LOD generator fails)
    # ---------------------------------------------------------------------
    def _generate_traditional_mesh(self, points_3d: np.ndarray):
        """å¾“æ¥æ–¹å¼ã§ãƒ¡ãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰"""
        if points_3d is None or len(points_3d) < 100:
            return None

        try:
            import time

            # 1) Point cloud projection to height map
            proj_start = time.perf_counter()
            height_map = self.projector.project_points(points_3d)
            proj_time = (time.perf_counter() - proj_start) * 1000.0

            # 2) Delaunay triangulation
            tri_start = time.perf_counter()
            triangle_mesh = self.triangulator.triangulate_heightmap(height_map)
            tri_time = (time.perf_counter() - tri_start) * 1000.0

            if triangle_mesh is None or triangle_mesh.num_triangles == 0:
                logger.warning("[TRADITIONAL-MESH] Triangulation failed (no triangles)")
                return None

            # 3) Mesh simplification
            simp_start = time.perf_counter()
            simplified_mesh = self.simplifier.simplify_mesh(triangle_mesh)
            simp_time = (time.perf_counter() - simp_start) * 1000.0

            if simplified_mesh is None:
                simplified_mesh = triangle_mesh

            # Logging every 50 frames for performance insight
            if hasattr(self, "frame_counter") and self.frame_counter % 50 == 0:
                total = proj_time + tri_time + simp_time
                logger.info(
                    f"[TRADITIONAL-MESH] {len(points_3d)} pts -> {simplified_mesh.num_triangles} tris "
                    f"(Proj {proj_time:.1f}ms, Tri {tri_time:.1f}ms, Simp {simp_time:.1f}ms, Total {total:.1f}ms)"
                )

            return simplified_mesh

        except Exception as e:
            logger.error(f"å¾“æ¥æ–¹å¼ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None


# =============================================================================
# ãƒ¡ã‚¤ãƒ³é–¢æ•°
# =============================================================================

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = create_argument_parser()
    args = parser.parse_args()
    
    # å¼•æ•°æ¤œè¨¼
    if not validate_arguments(args):
        return 1
    
    # è§£åƒåº¦è¨­å®š
    depth_width, depth_height = determine_resolution(args)
    
    # éŸ³éšã¨æ¥½å™¨ã®å¤‰æ›
    audio_scale, audio_instrument = convert_audio_parameters(args)
    if audio_scale is None or audio_instrument is None:
        return 1
    
    # æƒ…å ±è¡¨ç¤º
    display_configuration(args, depth_width, depth_height, audio_scale, audio_instrument)
    
    # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰
    if args.test:
        run_preprocessing_optimization_test()
        print("\n" + "=" * 70)
        run_headless_fps_comparison_test()
        return 0
    
    # è¨­å®šã®é©ç”¨
    apply_configuration(depth_width, depth_height, args)
    
    # ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼å®Ÿè¡Œ
    try:
        viewer = create_viewer(args, audio_scale, audio_instrument)
        
        print("\nå…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚’é–‹å§‹ã—ã¾ã™...")
        print("=" * 70)
        
        # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰å‡¦ç†
        if args.headless:
            print("ğŸ–¥ï¸  ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰: ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            print("ğŸ¯ ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹FPSæ¸¬å®šã‚’é–‹å§‹ã—ã¾ã™...")
            viewer.run()
            print("\nãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ãŒæ­£å¸¸ã«çµ‚äº†ã—ã¾ã—ãŸ")
            return 0
        
        # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰å‡¦ç†
        print("ã‚«ãƒ¡ãƒ©ã‚’åˆæœŸåŒ–ä¸­...")
        if depth_width and depth_height:
            print(f"   æ·±åº¦è§£åƒåº¦: {depth_width}x{depth_height} ã«è¨­å®š")
        
        viewer.camera = OrbbecCamera(
            enable_color=True,
            depth_width=depth_width,
            depth_height=depth_height
        )
        
        # DualViewer ã®åˆæœŸåŒ–ã¯ viewer.run() å†…éƒ¨ã§è¡Œã‚ã‚Œã‚‹ãŸã‚ã€ã“ã“ã§ã¯å‘¼ã³å‡ºã•ãªã„
        viewer.run()
        
        print("\nãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ãŒæ­£å¸¸ã«çµ‚äº†ã—ã¾ã—ãŸ")
        return 0
        
    except KeyboardInterrupt:
        print("\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        return 0
    except Exception as e:
        print(f"\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return 1


def create_argument_parser() -> argparse.ArgumentParser:
    """å¼•æ•°ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½œæˆ"""
    parser = argparse.ArgumentParser(
        description="Geocussion-SP å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆãƒ‡ãƒ¢ï¼ˆComplete Pipelineï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=create_help_epilog()
    )
    
    add_basic_arguments(parser)
    add_collision_arguments(parser)
    add_audio_arguments(parser)
    add_detection_arguments(parser)
    add_display_arguments(parser)
    add_resolution_arguments(parser)
    add_window_arguments(parser)
    add_mode_arguments(parser)
    
    return parser


def create_help_epilog() -> str:
    """ãƒ˜ãƒ«ãƒ—ã®ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ã‚’ä½œæˆ"""
    return """
ä½¿ç”¨ä¾‹:
    python demo_collision_detection.py                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼ˆä½è§£åƒåº¦424x240ï¼‰
    python demo_collision_detection.py --force-high-resolution # é«˜è§£åƒåº¦848x480ï¼ˆä½FPSæ³¨æ„ï¼‰
    python demo_collision_detection.py --depth-width 640 --depth-height 360 # ã‚«ã‚¹ã‚¿ãƒ è§£åƒåº¦
    python demo_collision_detection.py --no-collision     # è¡çªæ¤œå‡ºç„¡åŠ¹
    python demo_collision_detection.py --no-mesh          # ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆç„¡åŠ¹
    python demo_collision_detection.py --no-audio         # éŸ³éŸ¿åˆæˆç„¡åŠ¹
    python demo_collision_detection.py --sphere-radius 0.08 # çƒåŠå¾„8cm
    python demo_collision_detection.py --audio-instrument BELL # ãƒ™ãƒ«æ¥½å™¨

æ“ä½œæ–¹æ³•:
    RGB Window:
        Q/ESC: çµ‚äº†
        F: æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿ ON/OFF
        H: æ‰‹æ¤œå‡º ON/OFF
        T: ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚° ON/OFF
        
        M: ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ ON/OFF
        C: è¡çªæ¤œå‡º ON/OFF
        V: è¡çªå¯è¦–åŒ– ON/OFF
        N: ãƒ¡ãƒƒã‚·ãƒ¥å¼·åˆ¶æ›´æ–°
        +/-: çƒåŠå¾„èª¿æ•´
        P: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆè¡¨ç¤º
        
        A: éŸ³éŸ¿åˆæˆ ON/OFF
        S: éŸ³éšåˆ‡ã‚Šæ›¿ãˆ
        I: æ¥½å™¨åˆ‡ã‚Šæ›¿ãˆ
        1/2: éŸ³é‡èª¿æ•´
        R: éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³å†èµ·å‹•
        Q: å…¨éŸ³å£°åœæ­¢
    
    3D Viewer:
        ãƒã‚¦ã‚¹: å›è»¢/ãƒ‘ãƒ³/ã‚ºãƒ¼ãƒ 
        R: è¦–ç‚¹ãƒªã‚»ãƒƒãƒˆ
    """


def add_basic_arguments(parser: argparse.ArgumentParser):
    """åŸºæœ¬çš„ãªå¼•æ•°ã‚’è¿½åŠ """
    parser.add_argument('--no-filter', action='store_true', help='æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿ã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--no-hand-detection', action='store_true', help='æ‰‹æ¤œå‡ºã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--no-tracking', action='store_true', help='ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--gpu-mediapipe', action='store_true', help='MediaPipeã§GPUã‚’ä½¿ç”¨')


def add_collision_arguments(parser: argparse.ArgumentParser):
    """è¡çªæ¤œå‡ºé–¢é€£ã®å¼•æ•°ã‚’è¿½åŠ """
    parser.add_argument('--no-mesh', action='store_true', help='ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--no-collision', action='store_true', help='è¡çªæ¤œå‡ºã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--no-collision-viz', action='store_true', help='è¡çªå¯è¦–åŒ–ã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--mesh-interval', type=int, default=DEFAULT_MESH_UPDATE_INTERVAL, 
                       help='ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼‰ â€»ä½è§£åƒåº¦æ™‚ã¯15frameæ¨å¥¨')
    parser.add_argument('--sphere-radius', type=float, default=DEFAULT_SPHERE_RADIUS, 
                       help='è¡çªæ¤œå‡ºçƒã®åŠå¾„ï¼ˆãƒ¡ãƒ¼ãƒˆãƒ«ï¼‰')
    parser.add_argument('--max-mesh-skip', type=int, default=DEFAULT_MAX_MESH_SKIP_FRAMES, 
                       help='æ‰‹ãŒå†™ã£ã¦ã„ã‚‹å ´åˆã§ã‚‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°çµŒéã§å¼·åˆ¶æ›´æ–°')


def add_audio_arguments(parser: argparse.ArgumentParser):
    """éŸ³éŸ¿é–¢é€£ã®å¼•æ•°ã‚’è¿½åŠ """
    parser.add_argument('--no-audio', action='store_true', help='éŸ³éŸ¿åˆæˆã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--audio-scale', type=str, default='PENTATONIC', 
                       choices=['PENTATONIC', 'MAJOR', 'MINOR', 'DORIAN', 'MIXOLYDIAN', 'CHROMATIC', 'BLUES'],
                       help='éŸ³éšã®ç¨®é¡')
    parser.add_argument('--audio-instrument', type=str, default='MARIMBA',
                       choices=['MARIMBA', 'SYNTH_PAD', 'BELL', 'PLUCK', 'BASS', 'LEAD', 'PERCUSSION', 'AMBIENT'],
                       help='æ¥½å™¨ã®ç¨®é¡')
    parser.add_argument('--audio-polyphony', type=int, default=DEFAULT_AUDIO_POLYPHONY, 
                       help='æœ€å¤§åŒæ™‚ç™ºéŸ³æ•°')
    parser.add_argument('--audio-volume', type=float, default=DEFAULT_MASTER_VOLUME, 
                       help='ãƒã‚¹ã‚¿ãƒ¼éŸ³é‡ (0.0-1.0)')


def add_detection_arguments(parser: argparse.ArgumentParser):
    """æ¤œå‡ºé–¢é€£ã®å¼•æ•°ã‚’è¿½åŠ """
    parser.add_argument('--min-confidence', type=float, default=0.7, 
                       help='æœ€å°æ¤œå‡ºä¿¡é ¼åº¦ (0.0-1.0)')


def add_display_arguments(parser: argparse.ArgumentParser):
    """è¡¨ç¤ºé–¢é€£ã®å¼•æ•°ã‚’è¿½åŠ """
    parser.add_argument('--update-interval', type=int, default=3, 
                       help='ç‚¹ç¾¤æ›´æ–°é–“éš”ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼‰')
    parser.add_argument('--point-size', type=float, default=2.0, 
                       help='ç‚¹ç¾¤ã®ç‚¹ã‚µã‚¤ã‚º')
    parser.add_argument('--high-resolution', action='store_true', 
                       help='é«˜è§£åƒåº¦è¡¨ç¤º (1280x720)')


def add_resolution_arguments(parser: argparse.ArgumentParser):
    """è§£åƒåº¦é–¢é€£ã®å¼•æ•°ã‚’è¿½åŠ """
    parser.add_argument('--low-resolution', action='store_true', default=True, 
                       help='ä½è§£åƒåº¦ãƒ¢ãƒ¼ãƒ‰ (424x240) â€»FPSå‘ä¸Šã®ãŸã‚æ—¢å®šON')
    parser.add_argument('--force-high-resolution', action='store_true', 
                       help='å¼·åˆ¶çš„ã«é«˜è§£åƒåº¦ (848x480) ã‚’ä½¿ç”¨ â€»ä½FPSæ³¨æ„')
    parser.add_argument('--depth-width', type=int, help='æ·±åº¦è§£åƒåº¦å¹…ã‚’ç›´æ¥æŒ‡å®š')
    parser.add_argument('--depth-height', type=int, help='æ·±åº¦è§£åƒåº¦é«˜ã•ã‚’ç›´æ¥æŒ‡å®š')


def add_window_arguments(parser: argparse.ArgumentParser):
    """ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é–¢é€£ã®å¼•æ•°ã‚’è¿½åŠ """
    parser.add_argument('--window-width', type=int, default=640, help='RGBã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®å¹…')
    parser.add_argument('--window-height', type=int, default=480, help='RGBã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®é«˜ã•')


def add_mode_arguments(parser: argparse.ArgumentParser):
    """ãƒ¢ãƒ¼ãƒ‰é–¢é€£ã®å¼•æ•°ã‚’è¿½åŠ """
    parser.add_argument('--test', action='store_true', help='ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ')
    parser.add_argument('--headless', action='store_true', help='ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ï¼ˆGUIç„¡åŠ¹ï¼‰â€»FPSå¤§å¹…å‘ä¸Š')
    parser.add_argument('--headless-duration', type=int, default=30, help='ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰')
    parser.add_argument('--headless-pure', action='store_true', help='ç´”ç²‹ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ï¼ˆæ‰‹æ¤œå‡ºç„¡åŠ¹ã€æœ€å¤§FPSæ¸¬å®šï¼‰')


def validate_arguments(args) -> bool:
    """å¼•æ•°ã‚’æ¤œè¨¼"""
    if args.min_confidence < 0.0 or args.min_confidence > 1.0:
        print("Error: --min-confidence must be between 0.0 and 1.0")
        return False
    
    if args.sphere_radius <= 0.0 or args.sphere_radius > 0.5:
        print("Error: --sphere-radius must be between 0.0 and 0.5")
        return False
    
    if args.audio_polyphony < 1 or args.audio_polyphony > 64:
        print("Error: --audio-polyphony must be between 1 and 64")
        return False
    
    if args.audio_volume < 0.0 or args.audio_volume > 1.0:
        print("Error: --audio-volume must be between 0.0 and 1.0")
        return False
    
    return True


def determine_resolution(args) -> Tuple[Optional[int], Optional[int]]:
    """è§£åƒåº¦ã‚’æ±ºå®š"""
    if args.depth_width and args.depth_height:
        return args.depth_width, args.depth_height
    elif args.force_high_resolution:
        return HIGH_RESOLUTION
    elif args.low_resolution:
        return LOW_RESOLUTION
    else:
        return None, None


def convert_audio_parameters(args) -> Tuple[Optional[ScaleType], Optional[InstrumentType]]:
    """éŸ³éŸ¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤‰æ›"""
    try:
        audio_scale = ScaleType[args.audio_scale]
        audio_instrument = InstrumentType[args.audio_instrument]
        return audio_scale, audio_instrument
    except KeyError as e:
        print(f"Error: Invalid audio parameter: {e}")
        return None, None


def display_configuration(args, depth_width: Optional[int], depth_height: Optional[int], 
                         audio_scale: ScaleType, audio_instrument: InstrumentType):
    """è¨­å®šã‚’è¡¨ç¤º"""
    print("=" * 70)
    print("Geocussion-SP å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆãƒ‡ãƒ¢ï¼ˆComplete Pipelineï¼‰")
    print("=" * 70)
    
    # è§£åƒåº¦æƒ…å ±
    display_resolution_info(depth_width, depth_height)
    
    # æ©Ÿèƒ½çŠ¶æ…‹
    print(f"æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿: {'ç„¡åŠ¹' if args.no_filter else 'æœ‰åŠ¹'}")
    print(f"æ‰‹æ¤œå‡º: {'ç„¡åŠ¹' if args.no_hand_detection else 'æœ‰åŠ¹'}")
    print(f"ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ: {'ç„¡åŠ¹' if args.no_mesh else 'æœ‰åŠ¹'}")
    print(f"è¡çªæ¤œå‡º: {'ç„¡åŠ¹' if args.no_collision else 'æœ‰åŠ¹'}")
    
    if not args.no_collision:
        print(f"  - çƒåŠå¾„: {args.sphere_radius*100:.1f}cm")
        print(f"  - å¯è¦–åŒ–: {'ç„¡åŠ¹' if args.no_collision_viz else 'æœ‰åŠ¹'}")
    
    print(f"éŸ³éŸ¿åˆæˆ: {'ç„¡åŠ¹' if args.no_audio else 'æœ‰åŠ¹'}")
    if not args.no_audio:
        print(f"  - éŸ³éš: {audio_scale.value}")
        print(f"  - æ¥½å™¨: {audio_instrument.value}")
        print(f"  - ãƒãƒªãƒ•ã‚©ãƒ‹ãƒ¼: {args.audio_polyphony}")
        print(f"  - éŸ³é‡: {args.audio_volume:.1f}")
    
    # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰æƒ…å ±
    if args.headless:
        print(f"ğŸ–¥ï¸  ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰: æœ‰åŠ¹ï¼ˆGUIç„¡åŠ¹åŒ–ã§FPSå‘ä¸Šï¼‰")
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {args.headless_duration}ç§’")
        print(f"ğŸš€ äºˆæƒ³FPSå‘ä¸Š: +5-15 FPS (GUIè² è·å‰Šé™¤)")
    else:
        print(f"ğŸ–¥ï¸  è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰: GUIæœ‰åŠ¹")
    
    print("=" * 70)


def display_resolution_info(width: Optional[int], height: Optional[int]):
    """è§£åƒåº¦æƒ…å ±ã‚’è¡¨ç¤º"""
    if width and height:
        resolution_mode = "ä½è§£åƒåº¦" if width <= 424 else "é«˜è§£åƒåº¦"
        points_estimate = width * height
        print(f"ğŸš€ è§£åƒåº¦æœ€é©åŒ–: {resolution_mode} ({width}x{height})")
        print(f"   äºˆæƒ³ç‚¹ç¾¤æ•°: {points_estimate:,} points")
        fps_estimate = "25-30 FPS" if width <= 424 else "5-15 FPS"
        print(f"   äºˆæƒ³FPS: {fps_estimate}")
        
        # é«˜è§£åƒåº¦è­¦å‘Š
        if points_estimate > ESTIMATED_HIGH_RES_POINTS:
            print(f"âš ï¸  Warning: High resolution ({width}x{height}) may cause low FPS")
            print(f"   Estimated points: {points_estimate:,}")
            print(f"   Consider using --low-resolution for better performance")
        else:
            print(f"âœ… Optimized resolution: {width}x{height} (~{points_estimate:,} points)")
    else:
        print("ğŸ“ Using camera default resolution")


def apply_configuration(depth_width: Optional[int], depth_height: Optional[int], args):
    """è¨­å®šã‚’é©ç”¨"""
    config = get_config()
    config.input.enable_low_resolution_mode = (depth_width == LOW_RESOLUTION[0] and 
                                               depth_height == LOW_RESOLUTION[1])
    config.input.depth_width = depth_width
    config.input.depth_height = depth_height
    
    # è§£åƒåº¦ã«åŸºã¥ãæœ€é©åŒ–
    if config.input.enable_low_resolution_mode:
        apply_low_resolution_optimizations(args)
    else:
        apply_high_resolution_optimizations(depth_width, depth_height, args, config)


def apply_low_resolution_optimizations(args):
    """ä½è§£åƒåº¦æ™‚ã®æœ€é©åŒ–ã‚’é©ç”¨"""
    if args.mesh_interval == DEFAULT_MESH_UPDATE_INTERVAL:
        args.mesh_interval = 20  # ã•ã‚‰ã«é–“éš”ã‚’ç©ºã‘ã‚‹
    print(f"ğŸ”§ ä½è§£åƒåº¦æœ€é©åŒ–: ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”={args.mesh_interval}ãƒ•ãƒ¬ãƒ¼ãƒ ")


def apply_high_resolution_optimizations(width: Optional[int], height: Optional[int], args, config):
    """é«˜è§£åƒåº¦æ™‚ã®æœ€é©åŒ–ã‚’é©ç”¨"""
    if width and height and (width >= HIGH_RESOLUTION[0] or height >= HIGH_RESOLUTION[1]):
        print(f"ğŸš¨ é«˜è§£åƒåº¦ãƒ¢ãƒ¼ãƒ‰æ¤œå‡º: {width}x{height}")
        print(f"âš¡ ç·Šæ€¥FPSæœ€é©åŒ–ã‚’é©ç”¨ä¸­...")
        
        # ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”ã‚’å¤§å¹…å»¶é•·
        if args.mesh_interval <= 20:
            args.mesh_interval = 40
            print(f"ğŸ”§ ç·Šæ€¥æœ€é©åŒ–: ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”={args.mesh_interval}ãƒ•ãƒ¬ãƒ¼ãƒ  (40fé–“éš”)")
        
        # æœ€å¤§ã‚¹ã‚­ãƒƒãƒ—ãƒ•ãƒ¬ãƒ¼ãƒ ã‚‚å»¶é•·
        if args.max_mesh_skip <= DEFAULT_MAX_MESH_SKIP_FRAMES:
            args.max_mesh_skip = 120
            print(f"ğŸ”§ ç·Šæ€¥æœ€é©åŒ–: æœ€å¤§ãƒ¡ãƒƒã‚·ãƒ¥ã‚¹ã‚­ãƒƒãƒ—={args.max_mesh_skip}ãƒ•ãƒ¬ãƒ¼ãƒ ")
        
        # è§£åƒåº¦ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
        config.input.enable_resolution_downsampling = True
        config.input.resolution_target_width = LOW_RESOLUTION[0]
        config.input.resolution_target_height = LOW_RESOLUTION[1]
        print(f"ğŸ”§ ç·Šæ€¥æœ€é©åŒ–: è§£åƒåº¦ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æœ‰åŠ¹ ({width}x{height} â†’ {LOW_RESOLUTION[0]}x{LOW_RESOLUTION[1]})")
        
        print(f"âš¡ é«˜è§£åƒåº¦ã§ã®äºˆæƒ³FPS: 8-15 FPS (æœ€é©åŒ–é©ç”¨æ¸ˆã¿)")
    elif width and height:
        print(f"ğŸ”§ ä¸­è§£åƒåº¦æœ€é©åŒ–: ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”={args.mesh_interval}ãƒ•ãƒ¬ãƒ¼ãƒ ")


def create_viewer(args, audio_scale: ScaleType, audio_instrument: InstrumentType) -> FullPipelineViewer:
    """ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚’ä½œæˆ"""
    return FullPipelineViewer(
        enable_filter=not args.no_filter,
        enable_hand_detection=not args.no_hand_detection,
        enable_tracking=not args.no_tracking,
        enable_mesh_generation=not args.no_mesh,
        enable_collision_detection=not args.no_collision,
        enable_collision_visualization=not args.no_collision_viz,
        enable_audio_synthesis=not args.no_audio,
        update_interval=args.update_interval,
        point_size=args.point_size,
        rgb_window_size=(args.window_width, args.window_height),
        min_detection_confidence=args.min_confidence,
        use_gpu_mediapipe=args.gpu_mediapipe,
        mesh_update_interval=args.mesh_interval,
        sphere_radius=args.sphere_radius,
        audio_scale=audio_scale,
        audio_instrument=audio_instrument,
        audio_polyphony=args.audio_polyphony,
        audio_master_volume=args.audio_volume,
        max_mesh_skip_frames=args.max_mesh_skip,
        headless_mode=args.headless,
        headless_duration=args.headless_duration,
        pure_headless_mode=args.headless_pure
    )


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)