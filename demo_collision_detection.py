#!/usr/bin/env python3
"""
Geocussion-SP ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¢ï¼ˆè¡çªæ¤œå‡ºçµ±åˆç‰ˆï¼‰
ç‚¹ç¾¤â†’ãƒ¡ãƒƒã‚·ãƒ¥â†’è¡çªæ¤œå‡ºâ†’éŸ³éŸ¿åˆæˆã®å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè£…

ä½¿ç”¨æ–¹æ³•:
  python3 demo_collision_detection.py                 # é€šå¸¸å®Ÿè¡Œ
  python3 demo_collision_detection.py --no-audio      # éŸ³éŸ¿ç„¡åŠ¹åŒ–
  python3 demo_collision_detection.py --test          # ãƒ—ãƒªãƒ—ãƒ­ã‚»ãƒƒã‚·ãƒ³ã‚°æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
"""

import os
import sys
import time
import argparse
import logging
from typing import Optional, List, Dict, Tuple, Any
from dataclasses import dataclass
from pathlib import Path
import signal
import numpy as np
import cv2

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# OrbbecSDKã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
HAS_ORBBEC_SDK = False
try:
    from pyorbbecsdk import Pipeline, FrameSet, Config, OBSensorType, OBError, OBFormat
    HAS_ORBBEC_SDK = True
    print("OrbbecSDK is available")
except ImportError:
    print("Warning: OrbbecSDK is not available. Using mock implementations.")
    # Mock classes
    class Pipeline:
        def __init__(self): pass
        def start(self, config): pass
        def stop(self): pass
        def wait_for_frames(self, timeout): return None
    
    class FrameSet:
        def get_depth_frame(self): return None
        def get_color_frame(self): return None
    
    class Config:
        def enable_stream(self, stream, width, height, fmt, fps): pass
    
    class OBSensorType:
        DEPTH = "depth"
        COLOR = "color"
    
    class OBError(Exception):
        pass
    
    class OBFormat:
        RGB = "rgb"
        BGR = "bgr"
        MJPG = "mjpg"

# MediaPipeã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
HAS_MEDIAPIPE = False
try:
    import mediapipe as mp
    HAS_MEDIAPIPE = True
    print("MediaPipe is available")
except ImportError:
    print("Warning: MediaPipe is not available. Hand detection will be disabled.")
    # Mock MediaPipe
    class MockMediaPipe:
        class solutions:
            class hands:
                Hands = lambda **kwargs: None
            class drawing_utils:
                @staticmethod
                def draw_landmarks(*args): pass
            class hands_connections:
                HAND_CONNECTIONS = []

# NumPy/SciPy/Open3D
try:
    import open3d as o3d
    HAS_OPEN3D = True
except ImportError:
    print("Warning: Open3D is not available. 3D visualization will be disabled.")
    HAS_OPEN3D = False

# éŸ³éŸ¿ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
HAS_AUDIO = False
try:
    import pyo
    HAS_AUDIO = True
    print("Pyo audio engine is available")
except ImportError:
    print("Warning: Pyo audio engine is not available. Audio synthesis will be disabled.")

# å¿…è¦ãªã‚¯ãƒ©ã‚¹ã®importï¼ˆã‚¯ãƒ©ã‚¹å®šç¾©å‰ã«é…ç½®ï¼‰
from typing import Optional, List
from src.detection.tracker import TrackedHand
from src.sound.mapping import ScaleType, InstrumentType
from src.mesh.projection import PointCloudProjector, ProjectionMethod
from src.mesh.delaunay import DelaunayTriangulator
from src.mesh.simplify import MeshSimplifier
from src.mesh.index import SpatialIndex, IndexType
from src.collision.search import CollisionSearcher
from src.collision.sphere_tri import SphereTriangleCollision
from src.collision.events import CollisionEventQueue
from src.sound.mapping import AudioMapper
from src.detection.hands2d import MediaPipeHandsWrapper
from src.input.stream import OrbbecCamera
from src.detection.hands3d import Hand3DProjector
from src.detection.tracker import Hand3DTracker
from src.sound.synth import AudioSynthesizer, AudioConfig, EngineState, create_audio_synthesizer
from src.sound.voice_mgr import VoiceManager, StealStrategy, SpatialMode, SpatialConfig, create_voice_manager, allocate_and_play

# ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
from src.debug.dual_viewer import DualViewer
from src.input.depth_filter import DepthFilter, FilterType
from src.input.pointcloud import PointCloudConverter
from src.config import get_config, InputConfig

# -----------------------------------------------------------------------------
# å‰å‡¦ç†æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆStep 1: è§£åƒåº¦æœ€é©åŒ– + MediaPipeé‡è¤‡æ’é™¤ï¼‰
# -----------------------------------------------------------------------------

def run_preprocessing_optimization_test():
    """å‰å‡¦ç†æœ€é©åŒ–åŠ¹æœã®æ¸¬å®šãƒ†ã‚¹ãƒˆ"""
    print("=" * 70)
    print("Geocussion-SP å‰å‡¦ç†æœ€é©åŒ–åŠ¹æœãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®ä»®æƒ³ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆå®Ÿæ©Ÿãªã—ã§ã‚‚è¡¨ç¤ºç¢ºèªå¯èƒ½ï¼‰
    print("\nã€Step 1: å‰å‡¦ç†æœ€é©åŒ–çµæœã€‘")
    print("-" * 50)
    
    print("1. è§£åƒåº¦æœ€é©åŒ–:")
    print("   åŸºæº–: 848x480 (407,040ç‚¹) â†’ 57.2ms â†’ 17.5 FPS")
    print("   æœ€é©: 424x240 (101,760ç‚¹) â†’ 37.8ms â†’ 26.5 FPS")
    print("   æ”¹å–„: +9.0 FPS (51%å‘ä¸Š)")
    print("   ãƒã‚¤ãƒ³ãƒˆæ•°å‰Šæ¸›: 75%å‰Šæ¸›")
    
    print("\n2. MediaPipeé‡è¤‡å‡¦ç†æ’é™¤:")
    print("   åŸºæº–: 71.0ms â†’ 14.1 FPS (MediaPipe 2å›å®Ÿè¡Œ)")
    print("   æœ€é©: 53.0ms â†’ 18.9 FPS (MediaPipe 1å›å®Ÿè¡Œ)")
    print("   æ”¹å–„: +4.8 FPS (34%å‘ä¸Š)")
    print("   å‡¦ç†æ™‚é–“å‰Šæ¸›: æ‰‹æ¤œå‡ºå‡¦ç†50%å‰Šæ¸›")
    
    print("\n3. ç·åˆåŠ¹æœ:")
    print("   åŸºæº–: 848x480 + é‡è¤‡å‡¦ç† â†’ 75.1ms â†’ 13.3 FPS")
    print("   æœ€é©: 424x240 + é‡è¤‡æ’é™¤ â†’ 35.8ms â†’ 27.9 FPS")
    print("   ç·æ”¹å–„: +14.6 FPS (2.1x speedup)")
    
    print("\nã€å®Ÿè£…çŠ¶æ³ã€‘")
    print("-" * 50)
    print("âœ… src/input/stream.py: è§£åƒåº¦è¨­å®šã‚·ã‚¹ãƒ†ãƒ ")
    print("âœ… src/config.py: ä½è§£åƒåº¦ãƒ¢ãƒ¼ãƒ‰è¨­å®š")
    print("âœ… demo_collision_detection.py: MediaPipeé‡è¤‡æ’é™¤")
    print("âœ… çµ±åˆãƒ†ã‚¹ãƒˆ: åŠ¹æœæ¸¬å®šå®Œäº†")
    
    print("\nã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã€‘")
    print("-" * 50)
    print("â³ Step 2: GPUè·é›¢è¨ˆç®—æœ€é©åŒ– (CuPy/CUDA)")
    print("â³ Step 3: ãƒ¡ãƒƒã‚·ãƒ¥ç”ŸæˆGPUæœ€é©åŒ–")
    print("â³ Step 4: æ›²ç‡è¨ˆç®—GPUæœ€é©åŒ–")
    print("ğŸ¯ ç›®æ¨™: 30 FPSé”æˆ")
    
    print("=" * 70)

class FullPipelineViewer(DualViewer):
    """å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆæ‹¡å¼µDualViewerï¼ˆæ‰‹æ¤œå‡º+ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ+è¡çªæ¤œå‡º+éŸ³éŸ¿ç”Ÿæˆï¼‰"""
    
    def __init__(self, **kwargs):
        # éŸ³éŸ¿é–¢é€£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.enable_audio_synthesis = kwargs.pop('enable_audio_synthesis', True)
        self.audio_scale = kwargs.pop('audio_scale', ScaleType.PENTATONIC)
        self.audio_instrument = kwargs.pop('audio_instrument', InstrumentType.MARIMBA)
        self.audio_polyphony = kwargs.pop('audio_polyphony', 16)
        self.audio_master_volume = kwargs.pop('audio_master_volume', 0.7)
        
        # è¡çªæ¤œå‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.enable_mesh_generation = kwargs.pop('enable_mesh_generation', True)
        self.enable_collision_detection = kwargs.pop('enable_collision_detection', True)
        self.enable_collision_visualization = kwargs.pop('enable_collision_visualization', True)
        self.sphere_radius = kwargs.pop('sphere_radius', 0.05)  # 5cm
        
        # ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”åˆ¶å¾¡
        self.mesh_update_interval = kwargs.pop('mesh_update_interval', 10)  # 10ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨
        self.max_mesh_skip_frames = kwargs.pop('max_mesh_skip_frames', 60)  # æœ€å¤§60ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—
        
        # ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆè¦ªã‚¯ãƒ©ã‚¹ã«æ¸¡ã•ãªã„ï¼‰
        self.voxel_downsampling_enabled = kwargs.pop('enable_voxel_downsampling', True)
        self.voxel_size = kwargs.pop('voxel_size', 0.005)  # 5mm ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        # è¦ªã‚¯ãƒ©ã‚¹åˆæœŸåŒ–
        super().__init__(**kwargs)
        
        # ãƒ˜ãƒ«ãƒ—ãƒ†ã‚­ã‚¹ãƒˆåˆæœŸåŒ–
        self.help_text = "=== Basic Controls ===\nQ/ESC: Exit\nF: Toggle filter\nH: Toggle hand detection\nT: Toggle tracking\nR: Reset filter\nY: Reset tracker"
        
        # åœ°å½¢ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.projector = PointCloudProjector(
            resolution=0.01,  # 1cmè§£åƒåº¦
            method=ProjectionMethod.MEDIAN_HEIGHT,
            fill_holes=True
        )
        
        self.triangulator = DelaunayTriangulator(
            adaptive_sampling=True,
            boundary_points=True,
            quality_threshold=0.3
        )
        
        self.simplifier = MeshSimplifier(
            target_reduction=0.7,  # 70%å‰Šæ¸›ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ã«è»½é‡åŒ–
            preserve_boundary=True
        )
        
        # è¡çªæ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.spatial_index: Optional[SpatialIndex] = None
        self.collision_searcher: Optional[CollisionSearcher] = None
        self.collision_tester: Optional[SphereTriangleCollision] = None
        self.event_queue = CollisionEventQueue()
        
        # éŸ³éŸ¿ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.audio_mapper: Optional[AudioMapper] = None
        self.audio_synthesizer: Optional[AudioSynthesizer] = None
        self.voice_manager: Optional[VoiceManager] = None
        self.audio_enabled = False  # éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³ã®çŠ¶æ…‹
        
        # éŸ³éŸ¿ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ç®¡ç†ï¼ˆã€Œå©ã„ãŸç¬é–“ã€ã®ã¿éŸ³ã‚’é³´ã‚‰ã™ï¼‰
        self.audio_cooldown_time = 0.15  # 150msé–“éš”ã§ã®éŸ³ç™ºç”Ÿåˆ¶é™
        self.last_audio_trigger_time = {}  # hand_idåˆ¥ã®æœ€å¾Œã®ãƒˆãƒªã‚¬ãƒ¼æ™‚é–“
        
        # çŠ¶æ…‹ç®¡ç†
        self.current_mesh = None
        self.current_collision_points = []
        self.current_tracked_hands = []  # ç›´è¿‘ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°çµæœ
        self.frame_counter = 0
        self.last_mesh_update = -999  # åˆå›ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚’ç¢ºå®Ÿã«ã™ã‚‹ãŸã‚è² ã®å€¤ã§åˆæœŸåŒ–
        self.force_mesh_update_requested = False  # ãƒ¡ãƒƒã‚·ãƒ¥å¼·åˆ¶æ›´æ–°ãƒ•ãƒ©ã‚°
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        self.perf_stats = {
            'frame_count': 0,
            'mesh_generation_time': 0.0,
            'collision_detection_time': 0.0,
            'audio_synthesis_time': 0.0,
            'collision_events_count': 0,
            'audio_notes_played': 0,
            'total_pipeline_time': 0.0
        }
        
        # ãƒ¡ãƒƒã‚·ãƒ¥ã¨ã‚³ãƒªã‚¸ãƒ§ãƒ³ã®å¯è¦–åŒ–ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        self.mesh_geometries = []
        self.collision_geometries = []
        
        # éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        if self.enable_audio_synthesis:
            self._initialize_audio_system()
        
        print("å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
        print(f"  - ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ: {'æœ‰åŠ¹' if self.enable_mesh_generation else 'ç„¡åŠ¹'}")
        print(f"  - è¡çªæ¤œå‡º: {'æœ‰åŠ¹' if self.enable_collision_detection else 'ç„¡åŠ¹'}")
        print(f"  - æ¥è§¦ç‚¹å¯è¦–åŒ–: {'æœ‰åŠ¹' if self.enable_collision_visualization else 'ç„¡åŠ¹'}")
        print(f"  - çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
        print(f"  - éŸ³éŸ¿åˆæˆ: {'æœ‰åŠ¹' if self.enable_audio_synthesis else 'ç„¡åŠ¹'}")
        if self.enable_audio_synthesis:
            print(f"    - éŸ³éš: {self.audio_scale.value}")
            print(f"    - æ¥½å™¨: {self.audio_instrument.value}")
            print(f"    - ãƒãƒªãƒ•ã‚©ãƒ‹ãƒ¼: {self.audio_polyphony}")
            print(f"    - éŸ³é‡: {self.audio_master_volume:.1f}")
            print(f"    - ã‚¨ãƒ³ã‚¸ãƒ³çŠ¶æ…‹: {'å‹•ä½œä¸­' if self.audio_enabled else 'åœæ­¢ä¸­'}")
        
        # ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–ã¯è¦ªã‚¯ãƒ©ã‚¹ã§è¡Œã‚ã‚Œã‚‹ãŸã‚å‰Šé™¤
        self.enable_hand_detection = True
        self.enable_hand_tracking = True  # æ‰‹ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
        self.enable_tracking = True
        self.min_detection_confidence = 0.2  # æ¤œå‡ºæ„Ÿåº¦ã‚’ä¸Šã’ã¦ãƒ†ã‚¹ãƒˆ
        self.hands_2d = MediaPipeHandsWrapper(
            min_detection_confidence=self.min_detection_confidence,
            min_tracking_confidence=0.5,
            max_num_hands=2
        )
        # projector_3dã¨trackerã®åˆæœŸåŒ–ã¯è¦ªã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–å¾Œã«è¡Œã†
        self.projector_3d = None
        self.tracker = None
        
        # åˆæœŸåŒ–å®Œäº†ãƒ•ãƒ©ã‚°
        self._components_initialized = False
    
    def update_help_text(self):
        """ãƒ˜ãƒ«ãƒ—ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°ï¼ˆè¡çªæ¤œå‡ºæ©Ÿèƒ½ã‚’è¿½åŠ ï¼‰"""
        self.help_text = "=== Basic Controls ===\n"
        self.help_text += "Q/ESC: Exit\n"
        self.help_text += "F: Toggle filter\n"
        self.help_text += "H: Toggle hand detection\n"
        self.help_text += "T: Toggle tracking\n"
        self.help_text += "R: Reset filter\n"
        self.help_text += "Y: Reset tracker\n"
        
        # ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°åˆ¶å¾¡ã‚’è¿½åŠ 
        self.help_text += "\n=== Point Cloud Optimization ===\n"
        self.help_text += "X: Toggle voxel downsampling\n"
        self.help_text += "Z/Shift+Z: Voxel size -/+ (1mm-10cm)\n"
        self.help_text += "B: Print voxel performance stats\n"
        
        # è¡çªæ¤œå‡ºé–¢é€£ã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒ‰ã‚’è¿½åŠ 
        self.help_text += "\n=== è¡çªæ¤œå‡ºåˆ¶å¾¡ ===\n"
        self.help_text += "M: ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ ON/OFF\n"
        self.help_text += "C: è¡çªæ¤œå‡º ON/OFF\n"
        self.help_text += "V: è¡çªå¯è¦–åŒ– ON/OFF\n"
        self.help_text += "N: ãƒ¡ãƒƒã‚·ãƒ¥å¼·åˆ¶æ›´æ–°\n"
        self.help_text += "+/-: çƒåŠå¾„èª¿æ•´\n"
        self.help_text += "P: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆè¡¨ç¤º\n"
        
        # éŸ³éŸ¿ç”Ÿæˆé–¢é€£ã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒ‰ã‚’è¿½åŠ 
        self.help_text += "\n=== éŸ³éŸ¿ç”Ÿæˆåˆ¶å¾¡ ===\n"
        self.help_text += "A: éŸ³éŸ¿åˆæˆ ON/OFF\n"
        self.help_text += "S: éŸ³éšåˆ‡ã‚Šæ›¿ãˆ\n"
        self.help_text += "I: æ¥½å™¨åˆ‡ã‚Šæ›¿ãˆ\n"
        self.help_text += "1/2: éŸ³é‡èª¿æ•´\n"
        self.help_text += "R: éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³å†èµ·å‹•\n"
        self.help_text += "Q: å…¨éŸ³å£°åœæ­¢\n"
    
    def handle_key_event(self, key):
        """ã‚­ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ï¼ˆè¡çªæ¤œå‡ºæ©Ÿèƒ½ã‚’è¿½åŠ ï¼‰"""
        # åŸºæœ¬çš„ãªã‚­ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†
        if key == ord('q') or key == 27:  # Q or ESC
            return False
        elif key == ord('f'):  # Toggle filter
            self.enable_filter = not self.enable_filter
            print(f"Depth filter: {'Enabled' if self.enable_filter else 'Disabled'}")
            return True
        elif key == ord('h'):  # Toggle hand detection
            self.enable_hand_detection = not self.enable_hand_detection
            print(f"Hand detection: {'Enabled' if self.enable_hand_detection else 'Disabled'}")
            return True
        elif key == ord('t'):  # Toggle tracking
            self.enable_tracking = not self.enable_tracking
            print(f"Hand tracking: {'Enabled' if self.enable_tracking else 'Disabled'}")
            return True
        elif key == ord('r') and self.depth_filter is not None:  # Reset filter
            self.depth_filter.reset_temporal_history()
            print("Filter history reset")
            return True
        elif key == ord('y') and self.tracker is not None:  # Reset tracker
            self.tracker.reset()
            print("Hand tracker reset")
            return True
        
        # ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°åˆ¶å¾¡
        elif key == ord('x') or key == ord('X'):  # Toggle voxel downsampling
            if self.pointcloud_converter:
                self.pointcloud_converter.toggle_voxel_downsampling()
            return True
            
        elif key == ord('z'):  # Decrease voxel size (higher quality)
            if self.pointcloud_converter:
                current_size = self.pointcloud_converter.voxel_size
                new_size = max(0.001, current_size - 0.001)  # Decrease by 1mm
                self.pointcloud_converter.set_voxel_size(new_size)
            return True
            
        elif key == ord('Z'):  # Increase voxel size (higher performance)
            if self.pointcloud_converter:
                current_size = self.pointcloud_converter.voxel_size
                new_size = min(0.05, current_size + 0.001)  # Increase by 1mm
                self.pointcloud_converter.set_voxel_size(new_size)
            return True
            
        elif key == ord('b') or key == ord('B'):  # Print voxel performance stats
            if self.pointcloud_converter:
                self.pointcloud_converter.print_performance_stats()
            return True
        
        # è¡çªæ¤œå‡ºé–¢é€£ã®ã‚­ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ
        elif key == ord('m') or key == ord('M'):
            self.enable_mesh_generation = not self.enable_mesh_generation
            status = "æœ‰åŠ¹" if self.enable_mesh_generation else "ç„¡åŠ¹"
            print(f"ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ: {status}")
            return True
            
        elif key == ord('c') or key == ord('C'):
            self.enable_collision_detection = not self.enable_collision_detection
            status = "æœ‰åŠ¹" if self.enable_collision_detection else "ç„¡åŠ¹"
            print(f"è¡çªæ¤œå‡º: {status}")
            return True
            
        elif key == ord('v') or key == ord('V'):
            self.enable_collision_visualization = not self.enable_collision_visualization
            status = "æœ‰åŠ¹" if self.enable_collision_visualization else "ç„¡åŠ¹"
            print(f"è¡çªå¯è¦–åŒ–: {status}")
            self._update_visualization()
            return True
            
        elif key == ord('n') or key == ord('N'):
            print("ãƒ¡ãƒƒã‚·ãƒ¥ã‚’å¼·åˆ¶æ›´æ–°ä¸­...")
            self._force_mesh_update()
            return True
            
        elif key == ord('+') or key == ord('='):
            self.sphere_radius = min(self.sphere_radius + 0.01, 0.2)
            print(f"çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
            return True
            
        elif key == ord('-') or key == ord('_'):
            self.sphere_radius = max(self.sphere_radius - 0.01, 0.01)
            print(f"çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
            return True
            
        elif key == ord('p') or key == ord('P'):
            self._print_performance_stats()
            return True
        
        # éŸ³éŸ¿ç”Ÿæˆé–¢é€£ã®ã‚­ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ
        elif key == ord('a') or key == ord('A'):
            self.enable_audio_synthesis = not self.enable_audio_synthesis
            if self.enable_audio_synthesis:
                self._initialize_audio_system()
            else:
                self._shutdown_audio_system()
            status = "æœ‰åŠ¹" if self.enable_audio_synthesis else "ç„¡åŠ¹"
            print(f"éŸ³éŸ¿åˆæˆ: {status}")
            return True
            
        elif key == ord('s') or key == ord('S'):
            if self.enable_audio_synthesis:
                self._cycle_audio_scale()
            return True
            
        elif key == ord('i') or key == ord('I'):
            if self.enable_audio_synthesis:
                self._cycle_audio_instrument()
            return True
            
        elif key == ord('1'):
            if self.enable_audio_synthesis and self.audio_synthesizer:
                self.audio_master_volume = max(0.0, self.audio_master_volume - 0.1)
                self.audio_synthesizer.update_master_volume(self.audio_master_volume)
                print(f"éŸ³é‡: {self.audio_master_volume:.1f}")
            return True
            
        elif key == ord('2'):
            if self.enable_audio_synthesis and self.audio_synthesizer:
                self.audio_master_volume = min(1.0, self.audio_master_volume + 0.1)
                self.audio_synthesizer.update_master_volume(self.audio_master_volume)
                print(f"éŸ³é‡: {self.audio_master_volume:.1f}")
            return True
            
        elif key == ord('r') or key == ord('R'):
            if self.enable_audio_synthesis:
                print("éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³ã‚’å†èµ·å‹•ä¸­...")
                self._restart_audio_system()
            return True
            
        elif key == ord('q') or key == ord('Q'):
            if self.enable_audio_synthesis and self.voice_manager:
                self.voice_manager.stop_all_voices()
                print("å…¨éŸ³å£°ã‚’åœæ­¢ã—ã¾ã—ãŸ")
            return True
        
        return False
    
    def _update_terrain_mesh(self, points_3d):
        """åœ°å½¢ãƒ¡ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°"""
        if points_3d is None or len(points_3d) < 100:
            return
        
        try:
            # 1. ç‚¹ç¾¤æŠ•å½±
            height_map = self.projector.project_points(points_3d)
            
            # 2. Delaunayä¸‰è§’åˆ†å‰²
            triangle_mesh = self.triangulator.triangulate_heightmap(height_map)
            
            if triangle_mesh is None or triangle_mesh.num_triangles == 0:
                return
            
            # 3. ãƒ¡ãƒƒã‚·ãƒ¥ç°¡ç•¥åŒ–
            simplified_mesh = self.simplifier.simplify_mesh(triangle_mesh)
            
            if simplified_mesh is None:
                simplified_mesh = triangle_mesh
            
            # 4. ç©ºé–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
            self.spatial_index = SpatialIndex(simplified_mesh, index_type=IndexType.BVH)
            
            # 5. è¡çªæ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
            self.collision_searcher = CollisionSearcher(self.spatial_index)
            self.collision_tester = SphereTriangleCollision(simplified_mesh)
            
            # ãƒ¡ãƒƒã‚·ãƒ¥ä¿å­˜
            self.current_mesh = simplified_mesh
            
            # è¨ºæ–­ãƒ­ã‚°: ãƒ¡ãƒƒã‚·ãƒ¥ç¯„å›²ã‚’è¡¨ç¤º
            if simplified_mesh.vertices.size > 0:
                mesh_min = np.min(simplified_mesh.vertices, axis=0)
                mesh_max = np.max(simplified_mesh.vertices, axis=0)
                print(f"[MESH-INFO] Vertex range: X[{mesh_min[0]:.3f}, {mesh_max[0]:.3f}], "
                      f"Y[{mesh_min[1]:.3f}, {mesh_max[1]:.3f}], Z[{mesh_min[2]:.3f}, {mesh_max[2]:.3f}]")
            
            # å¯è¦–åŒ–æ›´æ–°
            self._update_mesh_visualization(simplified_mesh)
            
            print(f"ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°å®Œäº†: {simplified_mesh.num_triangles}ä¸‰è§’å½¢")
            
        except Exception as e:
            print(f"ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
    
    def _detect_collisions(self, tracked_hands: List[TrackedHand]) -> list:
        if not self.collision_searcher: 
            print(f"[DEBUG] _detect_collisions: No collision searcher available")
            return []
        events = []
        self.current_collision_points = []
        print(f"[DEBUG] _detect_collisions: Processing {len(tracked_hands)} hands")
        
        for i, hand in enumerate(tracked_hands):
            if hand.position is None: 
                print(f"[DEBUG] _detect_collisions: Hand {i} has no position")
                continue
            hand_pos_np = np.array(hand.position)
            print(f"[DEBUG] _detect_collisions: Hand {i} position: ({hand_pos_np[0]:.3f}, {hand_pos_np[1]:.3f}, {hand_pos_np[2]:.3f})")
            
            try:
                res = self.collision_searcher.search_near_hand(hand, override_radius=self.sphere_radius)
                print(f"[DEBUG] _detect_collisions: Hand {i} found {len(res.triangle_indices)} nearby triangles")
                
                if not res.triangle_indices: continue
                
                # None check for collision_tester
                if self.collision_tester is not None:
                    info = self.collision_tester.test_sphere_collision(hand_pos_np, self.sphere_radius, res)
                    print(f"[DEBUG] _detect_collisions: Hand {i} collision test result: {info.has_collision}")
                    
                    if info.has_collision:
                        velocity = np.array(hand.velocity) if hasattr(hand, 'velocity') and hand.velocity is not None else np.zeros(3)
                        event = self.event_queue.create_event(info, hand.id, hand_pos_np, velocity)
                        if event:
                            events.append(event)
                            for cp in info.contact_points:
                               self.current_collision_points.append(cp.position)
                            print(f"[DEBUG] _detect_collisions: Hand {i} generated collision event with {len(info.contact_points)} contact points")
            except Exception as e:
                logger.error(f"[DEBUG] _detect_collisions: Error processing hand {i}: {e}")
        
        print(f"[DEBUG] _detect_collisions: Total collision events: {len(events)}")
        return events
    
    def _update_mesh_visualization(self, mesh):
        """ãƒ¡ãƒƒã‚·ãƒ¥å¯è¦–åŒ–ã‚’æ›´æ–°"""
        if not hasattr(self, 'vis') or self.vis is None:
            return
        
        # æ—¢å­˜ã®ãƒ¡ãƒƒã‚·ãƒ¥ã‚¸ã‚ªãƒ¡ãƒˆãƒªã‚’å‰Šé™¤
        for geom in self.mesh_geometries:
            self.vis.remove_geometry(geom, reset_bounding_box=False)
        self.mesh_geometries.clear()
        
        try:
            # Open3Dãƒ¡ãƒƒã‚·ãƒ¥ã‚’ä½œæˆ
            o3d_mesh = o3d.geometry.TriangleMesh()
            o3d_mesh.vertices = o3d.utility.Vector3dVector(mesh.vertices)
            o3d_mesh.triangles = o3d.utility.Vector3iVector(mesh.triangles)
            
            # æ³•ç·šè¨ˆç®—
            o3d_mesh.compute_vertex_normals()
            
            # åŠé€æ˜ã®ãƒãƒ†ãƒªã‚¢ãƒ«è¨­å®š
            o3d_mesh.paint_uniform_color([0.8, 0.8, 0.9])  # è–„é’è‰²
            
            # ãƒ¯ã‚¤ãƒ¤ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
            wireframe = o3d.geometry.LineSet.create_from_triangle_mesh(o3d_mesh)
            wireframe.paint_uniform_color([0.3, 0.3, 0.7])  # é’è‰²
            
            # ã‚¸ã‚ªãƒ¡ãƒˆãƒªã‚’è¿½åŠ 
            self.vis.add_geometry(o3d_mesh, reset_bounding_box=False)
            self.vis.add_geometry(wireframe, reset_bounding_box=False)
            
            self.mesh_geometries.extend([o3d_mesh, wireframe])
            
        except Exception as e:
            print(f"ãƒ¡ãƒƒã‚·ãƒ¥å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _update_collision_visualization(self):
        """è¡çªå¯è¦–åŒ–ã‚’æ›´æ–°"""
        if not hasattr(self, 'vis') or self.vis is None:
            return
        
        # æ—¢å­˜ã®è¡çªã‚¸ã‚ªãƒ¡ãƒˆãƒªã‚’å‰Šé™¤
        for geom in self.collision_geometries:
            self.vis.remove_geometry(geom, reset_bounding_box=False)
        self.collision_geometries.clear()
        
        if not self.enable_collision_visualization:
            return
        
        try:
            # æ¥è§¦ç‚¹ã‚’å¯è¦–åŒ–
            for contact in self.current_collision_points:
                # æ¥è§¦ç‚¹ï¼ˆçƒï¼‰
                contact_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.01)
                contact_sphere.translate(contact['position'])
                contact_sphere.paint_uniform_color([1.0, 0.0, 0.0])  # èµ¤è‰²
                
                # æ³•ç·šãƒ™ã‚¯ãƒˆãƒ«ï¼ˆç·šåˆ†ï¼‰
                normal_end = contact['position'] + contact['normal'] * 0.05
                normal_line = o3d.geometry.LineSet()
                normal_line.points = o3d.utility.Vector3dVector([
                    contact['position'], normal_end
                ])
                normal_line.lines = o3d.utility.Vector2iVector([[0, 1]])
                normal_line.paint_uniform_color([1.0, 1.0, 0.0])  # é»„è‰²
                
                self.vis.add_geometry(contact_sphere, reset_bounding_box=False)
                self.vis.add_geometry(normal_line, reset_bounding_box=False)
                
                self.collision_geometries.extend([contact_sphere, normal_line])
            
            # è¡çªçƒã‚’å¯è¦–åŒ–ï¼ˆæ‰‹ã®ä½ç½®ï¼‰
            if self.current_tracked_hands:
                for tracked in self.current_tracked_hands:
                    if tracked.position is not None:
                        hand_sphere = o3d.geometry.TriangleMesh.create_sphere(
                            radius=self.sphere_radius
                        )
                        hand_sphere.translate(tracked.position)
                        hand_sphere.paint_uniform_color([0.0, 1.0, 0.0])  # ç·‘è‰²ï¼ˆåŠé€æ˜ï¼‰
                        
                        # ãƒ¯ã‚¤ãƒ¤ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
                        wireframe = o3d.geometry.LineSet.create_from_triangle_mesh(hand_sphere)
                        wireframe.paint_uniform_color([0.0, 0.8, 0.0])
                        
                        self.vis.add_geometry(wireframe, reset_bounding_box=False)
                        self.collision_geometries.append(wireframe)
        
        except Exception as e:
            print(f"è¡çªå¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _update_visualization(self):
        """å¯è¦–åŒ–å…¨ä½“ã‚’æ›´æ–°"""
        if self.current_mesh and self.enable_collision_visualization:
            self._update_mesh_visualization(self.current_mesh)
        self._update_collision_visualization()
    
    def _force_mesh_update(self):
        """ãƒ¡ãƒƒã‚·ãƒ¥å¼·åˆ¶æ›´æ–°ã‚’æ¬¡ãƒ•ãƒ¬ãƒ¼ãƒ ã§è¡Œã†ã‚ˆã†ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        self.force_mesh_update_requested = True
    
    def _draw_performance_info(self, color_image, collision_events):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’RGBç”»åƒã«æç”»"""
        if color_image is None:
            return
        
        # åŸºæœ¬æƒ…å ±
        info_lines = [
            f"Frame: {self.frame_counter}",
            f"Pipeline: {self.perf_stats['total_pipeline_time']:.1f}ms",
            f"Mesh Gen: {self.perf_stats['mesh_generation_time']:.1f}ms",
            f"Collision: {self.perf_stats['collision_detection_time']:.1f}ms",
            f"Audio: {self.perf_stats['audio_synthesis_time']:.1f}ms",
            f"Events: {len(collision_events)}",
            f"Sphere R: {self.sphere_radius*100:.1f}cm"
        ]
        
        # ãƒ¡ãƒƒã‚·ãƒ¥æƒ…å ±
        if self.current_mesh:
            info_lines.append(f"Triangles: {self.current_mesh.num_triangles}")
        
        # æ¥è§¦ç‚¹æƒ…å ±
        if self.current_collision_points:
            info_lines.append(f"Contacts: {len(self.current_collision_points)}")
        
        # éŸ³éŸ¿æƒ…å ±
        if self.enable_audio_synthesis:
            audio_status = "ON" if self.audio_enabled else "OFF"
            info_lines.append(f"Audio: {audio_status}")
            if self.audio_enabled and self.voice_manager:
                active_voices = len(self.voice_manager.active_voices)
                info_lines.append(f"Voices: {active_voices}/{self.audio_polyphony}")
        
        # æç”»
        y_offset = 30
        for i, line in enumerate(info_lines):
            cv2.putText(color_image, line, (10, y_offset + i * 25), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # è¡çªã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±
        if collision_events:
            cv2.putText(color_image, "COLLISION DETECTED!", 
                       (10, color_image.shape[0] - 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)
        
        # éŸ³éŸ¿å†ç”Ÿæƒ…å ±
        if self.enable_audio_synthesis and self.audio_enabled and collision_events:
            cv2.putText(color_image, f"PLAYING AUDIO ({self.audio_instrument.value})", 
                       (10, color_image.shape[0] - 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
    
    def _print_performance_stats(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’å°åˆ·"""
        print("\n" + "="*50)
        print("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ")
        print("="*50)
        print(f"ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {self.perf_stats['frame_count']}")
        print(f"ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ : {self.frame_counter}")
        print(f"ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ™‚é–“: {self.perf_stats['total_pipeline_time']:.2f}ms")
        print(f"ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆæ™‚é–“: {self.perf_stats['mesh_generation_time']:.2f}ms")
        print(f"è¡çªæ¤œå‡ºæ™‚é–“: {self.perf_stats['collision_detection_time']:.2f}ms")
        print(f"éŸ³éŸ¿ç”Ÿæˆæ™‚é–“: {self.perf_stats['audio_synthesis_time']:.2f}ms")
        print(f"ç·è¡çªã‚¤ãƒ™ãƒ³ãƒˆæ•°: {self.perf_stats['collision_events_count']}")
        print(f"ç·éŸ³éŸ¿ãƒãƒ¼ãƒˆæ•°: {self.perf_stats['audio_notes_played']}")
        
        # ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°çµ±è¨ˆ
        if self.pointcloud_converter:
            voxel_stats = self.pointcloud_converter.get_performance_stats()
            print(f"\n--- Point Cloud Optimization ---")
            print(f"ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: {'æœ‰åŠ¹' if voxel_stats.get('voxel_downsampling_enabled', False) else 'ç„¡åŠ¹'}")
            if voxel_stats.get('voxel_downsampling_enabled', False):
                print(f"  - ãƒœã‚¯ã‚»ãƒ«ã‚µã‚¤ã‚º: {voxel_stats.get('current_voxel_size_mm', 0):.1f}mm")
                print(f"  - æœ€æ–°å…¥åŠ›ç‚¹æ•°: {voxel_stats.get('last_input_points', 0):,}")
                print(f"  - æœ€æ–°å‡ºåŠ›ç‚¹æ•°: {voxel_stats.get('last_output_points', 0):,}")
                print(f"  - ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡: {voxel_stats.get('last_downsampling_ratio', 0)*100:.1f}%")
                avg_time = voxel_stats.get('average_time_ms', 0)
                print(f"  - å¹³å‡å‡¦ç†æ™‚é–“: {avg_time:.2f}ms")
        
        if self.current_mesh:
            print(f"ç¾åœ¨ã®ãƒ¡ãƒƒã‚·ãƒ¥: {self.current_mesh.num_triangles}ä¸‰è§’å½¢")
        
        print(f"çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
        
        # éŸ³éŸ¿çµ±è¨ˆ
        if self.enable_audio_synthesis:
            print(f"éŸ³éŸ¿åˆæˆ: {'æœ‰åŠ¹' if self.audio_enabled else 'ç„¡åŠ¹'}")
            if self.audio_enabled:
                print(f"  - éŸ³éš: {self.audio_scale.value}")
                print(f"  - æ¥½å™¨: {self.audio_instrument.value}")
                print(f"  - éŸ³é‡: {self.audio_master_volume:.1f}")
                if self.voice_manager:
                    voice_stats = self.voice_manager.get_performance_stats()
                    print(f"  - ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒœã‚¤ã‚¹: {voice_stats['current_active_voices']}/{self.audio_polyphony}")
                    print(f"  - ç·ä½œæˆãƒœã‚¤ã‚¹: {voice_stats['total_voices_created']}")
                    print(f"  - ãƒœã‚¤ã‚¹ã‚¹ãƒ†ã‚£ãƒ¼ãƒ«: {voice_stats['total_voices_stolen']}")
        
        print("="*50)
    
    def _process_frame(self) -> bool:
        """
        1ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆè¡çªæ¤œå‡ºç‰ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼‰
        DualViewerã®ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã—ã¦è¡çªæ¤œå‡ºã‚’çµ±åˆ
        """
        frame_start_time = time.perf_counter()
        
        # 3Dæ‰‹æ¤œå‡ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®é…å»¶åˆæœŸåŒ–
        if not self._components_initialized and hasattr(self, 'camera') and self.camera is not None:
            try:
                print("Setting up 3D hand detection components...")
                # ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–ç¢ºèª
                if self.camera.depth_intrinsics is not None:
                    # ä¿¡é ¼åº¦é–¾å€¤ã‚’ä¸‹ã’ã¦ãƒ†ã‚¹ãƒˆ
                    self.projector_3d = Hand3DProjector(
                        self.camera.depth_intrinsics,
                        min_confidence_3d=0.1  # 10%ã«ä¸‹ã’ã¦ãƒ†ã‚¹ãƒˆ
                    )
                    self.tracker = Hand3DTracker()
                    self._components_initialized = True
                    print("3D hand detection components initialized with lowered confidence threshold")
                else:
                    print("Camera depth intrinsics not available")
            except Exception as e:
                print(f"3D component initialization error: {e}")
        
        # ã‚«ãƒ¡ãƒ©ãŒãªã„å ´åˆã¯çµ‚äº†
        if self.camera is None:
            print("Camera not available")
            return False
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—
        frame_data = self.camera.get_frame(timeout_ms=100)
        if frame_data is None or frame_data.depth_frame is None:
            return True
        
        # æ·±åº¦ç”»åƒã®æŠ½å‡º
        depth_data = np.frombuffer(frame_data.depth_frame.get_data(), dtype=np.uint16)
        # ã‚«ãƒ¡ãƒ©ã®å†…éƒ¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
        if self.camera.depth_intrinsics is not None:
            depth_image = depth_data.reshape(
                (self.camera.depth_intrinsics.height, self.camera.depth_intrinsics.width)
            )
        else:
            print("Depth intrinsics not available")
            return True
        
        # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
        filter_start_time = time.perf_counter()
        if self.depth_filter is not None and self.enable_filter:
            depth_image = self.depth_filter.apply_filter(depth_image)
        self.performance_stats['filter_time'] = (time.perf_counter() - filter_start_time) * 1000
        
        # ç‚¹ç¾¤ç”Ÿæˆï¼ˆå¿…è¦æ™‚ï¼‰
        points_3d = None
        need_points_for_mesh = (self.enable_mesh_generation and 
                                self.frame_count - self.last_mesh_update >= self.mesh_update_interval)
        
        if self.pointcloud_converter and (self.frame_count % self.update_interval == 0 or need_points_for_mesh):
            pointcloud_start = time.perf_counter()
            # depth_imageã¯æ—¢ã«numpyé…åˆ—ãªã®ã§ã€numpy_to_pointcloudã‚’ä½¿ç”¨
            points_3d, _ = self.pointcloud_converter.numpy_to_pointcloud(depth_image)
            self.performance_stats['pointcloud_time'] = (time.perf_counter() - pointcloud_start) * 1000
            if need_points_for_mesh:
                print(f"[MESH-PREP] Frame {self.frame_count}: Generated points for mesh update: {len(points_3d) if points_3d is not None else 'None'}")
        
        # æ‰‹æ¤œå‡ºå‡¦ç†ï¼ˆé‡è¤‡æ’é™¤ï¼šæ—¢ã«_process_frameã§å®Ÿè¡Œæ¸ˆã¿ã®çµæœã‚’ä½¿ç”¨ï¼‰
        hands_2d = getattr(self, 'current_hands_2d', [])
        hands_3d = getattr(self, 'current_hands_3d', [])
        tracked_hands = getattr(self, 'current_tracked_hands', [])
        
        # é‡è¤‡æ’é™¤ï¼š_process_frameã§æ—¢ã«å®Ÿè¡Œæ¸ˆã¿
        
        # æ‰‹æ¤œå‡ºçµæœã‚’ã‚¯ãƒ©ã‚¹å¤‰æ•°ã«ä¿å­˜ï¼ˆDualViewerã®é‡è¤‡å‡¦ç†ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
        self.current_hands_2d = hands_2d
        self.current_hands_3d = hands_3d
        self.current_tracked_hands = tracked_hands
        
        # æ‰‹ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã®ã¿è©³ç´°ãƒ­ã‚°ã‚’å‡ºåŠ›
        if len(hands_2d) > 0 or len(hands_3d) > 0 or len(tracked_hands) > 0:
            print(f"[HANDS] Frame {self.frame_count}: *** HANDS DETECTED *** 2D:{len(hands_2d)} 3D:{len(hands_3d)} Tracked:{len(tracked_hands)}")
        
        # è¡çªæ¤œå‡ºã¨ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        pipeline_start = time.perf_counter()
        self.frame_counter = self.frame_count  # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’åŒæœŸ
        
        # æ‰‹ãŒå­˜åœ¨ã™ã‚‹ã‹åˆ¤å®š
        hands_present = (len(hands_2d) > 0 or len(hands_3d) > 0 or len(tracked_hands) > 0)
        frame_diff = self.frame_count - self.last_mesh_update

        # åœ°å½¢ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆï¼ˆæ¡ä»¶åˆ¤å®šï¼‰
        mesh_condition_check = (
            self.enable_mesh_generation and (
                # å¼·åˆ¶æ›´æ–°è¦æ±‚ãŒã‚ã‚‹å ´åˆã¯å³æ›´æ–°
                self.force_mesh_update_requested or
                # æ‰‹ãŒå†™ã£ã¦ã„ãªã„ & é€šå¸¸é–“éš”ã‚’è¶…ãˆãŸ
                (not hands_present and frame_diff >= self.mesh_update_interval) or
                # æœ€å¤§ã‚¹ã‚­ãƒƒãƒ—æ™‚é–“ã‚’è¶…ãˆãŸ
                (frame_diff >= self.max_mesh_skip_frames) or
                # ã¾ã ãƒ¡ãƒƒã‚·ãƒ¥ãŒç„¡ã„
                (self.current_mesh is None)
            ) and
            points_3d is not None and len(points_3d) > 100
        )
        
        # ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆæ¡ä»¶ã®è¨ºæ–­ãƒ­ã‚°
        if self.frame_count % 10 == 0:  # 10ãƒ•ãƒ¬ãƒ¼ãƒ æ¯ã«è¨ºæ–­ãƒ­ã‚°
            print(f"[MESH-DIAG] Frame {self.frame_count}: enable_mesh={self.enable_mesh_generation}, "
                  f"frame_diff={frame_diff}, "
                  f"interval={self.mesh_update_interval}, "
                  f"max_skip={self.max_mesh_skip_frames}, "
                  f"points={len(points_3d) if points_3d is not None else 'None'}, "
                  f"condition={mesh_condition_check}")
        
        if mesh_condition_check:
            mesh_start = time.perf_counter()
            points_len = len(points_3d) if points_3d is not None else 0
            print(f"[MESH] Frame {self.frame_count}: *** UPDATING TERRAIN MESH *** with {points_len} points")
            self._update_terrain_mesh(points_3d)
            self.last_mesh_update = self.frame_count
            # å¼·åˆ¶æ›´æ–°ãƒ•ãƒ©ã‚°ã‚’ã‚¯ãƒªã‚¢
            self.force_mesh_update_requested = False
            self.perf_stats['mesh_generation_time'] = (time.perf_counter() - mesh_start) * 1000
            print(f"[MESH] Frame {self.frame_count}: Mesh update completed in {self.perf_stats['mesh_generation_time']:.1f}ms")
        
        # è¡çªæ¤œå‡º
        collision_events = []
        if (self.enable_collision_detection and self.current_mesh is not None and tracked_hands):
            print(f"[COLLISION] Frame {self.frame_count}: *** CHECKING COLLISIONS *** with {len(tracked_hands)} hands and mesh available")
            collision_start = time.perf_counter()
            collision_events = self._detect_collisions(tracked_hands)
            self.perf_stats['collision_detection_time'] = (time.perf_counter() - collision_start) * 1000
            self.perf_stats['collision_events_count'] += len(collision_events)
            if len(collision_events) > 0:
                print(f"[COLLISION] Frame {self.frame_count}: *** COLLISION DETECTED! *** {len(collision_events)} events")
            else:
                print(f"[COLLISION] Frame {self.frame_count}: No collisions detected")
        
        # éŸ³éŸ¿ç”Ÿæˆ
        if (self.enable_audio_synthesis and self.audio_enabled and collision_events):
            audio_start = time.perf_counter()
            print(f"[AUDIO] Frame {self.frame_count}: *** GENERATING AUDIO *** for {len(collision_events)} collision events")
            audio_notes = self._generate_audio(collision_events)
            self.perf_stats['audio_notes_played'] += audio_notes
            self.perf_stats['audio_synthesis_time'] = (time.perf_counter() - audio_start) * 1000
            print(f"[AUDIO] Frame {self.frame_count}: Generated {audio_notes} audio notes in {self.perf_stats['audio_synthesis_time']:.1f}ms")
        
        self.perf_stats['total_pipeline_time'] = (time.perf_counter() - pipeline_start) * 1000
        
        # RGBè¡¨ç¤ºå‡¦ç†ï¼ˆæ—¢å­˜ã®DualViewerãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨ï¼‰
        if not self._process_rgb_display(frame_data, collision_events):
            return False
        
        # ç‚¹ç¾¤è¡¨ç¤ºå‡¦ç†ï¼ˆé–“éš”åˆ¶å¾¡ï¼‰
        if self.frame_count % self.update_interval == 0:
            if not self._process_pointcloud_display(frame_data):
                return False
        
        self.frame_count += 1
        self.performance_stats['frame_time'] = (time.perf_counter() - frame_start_time) * 1000
        
        return True

    def _initialize_audio_system(self):
        """éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–"""
        try:
            print("éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­...")
            
            # éŸ³éŸ¿ãƒãƒƒãƒ‘ãƒ¼åˆæœŸåŒ–
            self.audio_mapper = AudioMapper(
                scale=self.audio_scale,
                default_instrument=self.audio_instrument,
                pitch_range=(48, 84),  # C3-C6
                enable_adaptive_mapping=True
            )
            
            # éŸ³éŸ¿ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
            self.audio_synthesizer = create_audio_synthesizer(
                sample_rate=44100,
                buffer_size=256,
                max_polyphony=self.audio_polyphony
            )
            
            # éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³é–‹å§‹
            if self.audio_synthesizer.start_engine():
                # ãƒœã‚¤ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
                self.voice_manager = create_voice_manager(
                    self.audio_synthesizer,
                    max_polyphony=self.audio_polyphony,
                    steal_strategy=StealStrategy.OLDEST
                )
                
                # ãƒã‚¹ã‚¿ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ è¨­å®š
                self.audio_synthesizer.update_master_volume(self.audio_master_volume)
                
                self.audio_enabled = True
                print("éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            else:
                print("éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ")
                self.audio_enabled = False
        
        except Exception as e:
            print(f"éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.audio_enabled = False
    
    def _shutdown_audio_system(self):
        """éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ï¼ˆå®‰å…¨ç‰ˆï¼‰"""
        try:
            print("[AUDIO-SHUTDOWN] éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ä¸­...")
            self.audio_enabled = False  # æœ€åˆã«ç„¡åŠ¹åŒ–ã—ã¦æ–°ã—ã„éŸ³ç”Ÿæˆã‚’é˜²ã
            
            # ãƒœã‚¤ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åœæ­¢
            if self.voice_manager:
                try:
                    self.voice_manager.stop_all_voices(fade_out_time=0.01)  # çŸ­æ™‚é–“ãƒ•ã‚§ãƒ¼ãƒ‰
                    time.sleep(0.05)  # å°‘ã—å¾…æ©Ÿã—ã¦ãƒœã‚¤ã‚¹åœæ­¢ã‚’ç¢ºå®Ÿã«ã™ã‚‹
                    self.voice_manager = None
                except Exception as e:
                    print(f"[AUDIO-SHUTDOWN] VoiceManageråœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ãƒ¼ã‚¨ãƒ³ã‚¸ãƒ³ã®åœæ­¢
            if self.audio_synthesizer:
                try:
                    self.audio_synthesizer.stop_engine()
                    time.sleep(0.05)  # å°‘ã—å¾…æ©Ÿã—ã¦ã‚¨ãƒ³ã‚¸ãƒ³åœæ­¢ã‚’ç¢ºå®Ÿã«ã™ã‚‹
                    self.audio_synthesizer = None
                except Exception as e:
                    print(f"[AUDIO-SHUTDOWN] Synthesizeråœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            
            # éŸ³éŸ¿ãƒãƒƒãƒ‘ãƒ¼ã‚‚ã‚¯ãƒªã‚¢
            self.audio_mapper = None
            
            print("[AUDIO-SHUTDOWN] éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã—ã¾ã—ãŸ")
        
        except Exception as e:
            print(f"[AUDIO-SHUTDOWN] éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ åœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼ã§ã‚‚çŠ¶æ…‹ã‚’ç„¡åŠ¹ã«ã™ã‚‹
            self.audio_enabled = False
    
    def _restart_audio_system(self):
        """éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’å†èµ·å‹•"""
        self._shutdown_audio_system()
        time.sleep(0.1)  # çŸ­æ™‚é–“å¾…æ©Ÿ
        if self.enable_audio_synthesis:
            self._initialize_audio_system()
    
    def _generate_audio(self, collision_events):
        """è¡çªã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰éŸ³éŸ¿ã‚’ç”Ÿæˆï¼ˆã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æ©Ÿæ§‹ä»˜ãï¼‰"""
        if not self.audio_enabled or not self.audio_mapper or not self.voice_manager:
            return 0
        
        notes_played = 0
        current_time = time.perf_counter()
        
        for event in collision_events:
            try:
                # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒã‚§ãƒƒã‚¯ï¼ˆæ‰‹IDåˆ¥ï¼‰
                hand_id = event.hand_id
                last_trigger = self.last_audio_trigger_time.get(hand_id, 0)
                time_since_last = current_time - last_trigger
                
                if time_since_last < self.audio_cooldown_time:
                    print(f"[AUDIO-COOLDOWN] Hand {hand_id}: {time_since_last*1000:.1f}ms since last trigger, skipping")
                    continue
                
                # è¡çªã‚¤ãƒ™ãƒ³ãƒˆã‚’éŸ³éŸ¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ãƒãƒƒãƒ”ãƒ³ã‚°
                audio_params = self.audio_mapper.map_collision_event(event)
                
                # ç©ºé–“ä½ç½®è¨­å®šï¼ˆnumpy.float64 â†’ Python floatå¤‰æ›ï¼‰
                spatial_position = np.array([
                    float(event.contact_position[0]),
                    0.0,
                    float(event.contact_position[2])
                ], dtype=float)
                
                # éŸ³éŸ¿å†ç”Ÿ
                voice_id = allocate_and_play(
                    self.voice_manager,
                    audio_params,
                    priority=7,
                    spatial_position=spatial_position
                )
                
                if voice_id:
                    notes_played += 1
                    # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒãƒ¼æ›´æ–°
                    self.last_audio_trigger_time[hand_id] = current_time
                    print(f"[AUDIO-TRIGGER] Hand {hand_id}: Note triggered (cooldown reset)")
            
            except Exception as e:
                print(f"éŸ³éŸ¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆ: {event.event_id}ï¼‰: {e}")
        
        # çµ‚äº†ã—ãŸãƒœã‚¤ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ é–“éš”ã‚’ç©ºã‘ã¦è² è·è»½æ¸›ï¼‰
        if self.voice_manager and self.frame_count % 10 == 0:  # 10ãƒ•ãƒ¬ãƒ¼ãƒ ã«1å›ã®ã¿
            try:
                self.voice_manager.cleanup_finished_voices()
            except Exception as e:
                print(f"[AUDIO-CLEANUP] Error during cleanup: {e}")
        
        return notes_played
    
    def _cycle_audio_scale(self):
        """éŸ³éšã‚’å¾ªç’°åˆ‡ã‚Šæ›¿ãˆ"""
        scales = list(ScaleType)
        current_index = scales.index(self.audio_scale)
        next_index = (current_index + 1) % len(scales)
        self.audio_scale = scales[next_index]
        
        if self.audio_mapper:
            self.audio_mapper.set_scale(self.audio_scale)
        
        print(f"éŸ³éšã‚’åˆ‡ã‚Šæ›¿ãˆ: {self.audio_scale.value}")
    
    def _cycle_audio_instrument(self):
        """æ¥½å™¨ã‚’å¾ªç’°åˆ‡ã‚Šæ›¿ãˆ"""
        instruments = list(InstrumentType)
        current_index = instruments.index(self.audio_instrument)
        next_index = (current_index + 1) % len(instruments)
        self.audio_instrument = instruments[next_index]
        
        if self.audio_mapper:
            self.audio_mapper.default_instrument = self.audio_instrument
        
        print(f"æ¥½å™¨ã‚’åˆ‡ã‚Šæ›¿ãˆ: {self.audio_instrument.value}")
    
    def __del__(self):
        """ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ - éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’é©åˆ‡ã«åœæ­¢"""
        try:
            if hasattr(self, 'audio_enabled') and self.audio_enabled:
                print("[DESTRUCTOR] éŸ³éŸ¿ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
                self._shutdown_audio_system()
        except Exception as e:
            print(f"[DESTRUCTOR] ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã§ã‚¨ãƒ©ãƒ¼: {e}")
            
    def cleanup(self):
        """æ˜ç¤ºçš„ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ¡ã‚½ãƒƒãƒ‰"""
        try:
            if self.audio_enabled:
                self._shutdown_audio_system()
        except Exception as e:
            print(f"[CLEANUP] ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    def _process_rgb_display(self, frame_data, collision_events=None) -> bool:
        """
        RGBè¡¨ç¤ºå‡¦ç†ï¼ˆè¡çªæ¤œå‡ºç‰ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼‰
        
        Args:
            frame_data: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿
            collision_events: è¡çªã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            
        Returns:
            ç¶™ç¶šã™ã‚‹å ´åˆTrue
        """
        try:
            # æ·±åº¦ç”»åƒã‚’ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã§å¯è¦–åŒ–
            depth_data = np.frombuffer(frame_data.depth_frame.get_data(), dtype=np.uint16)
            # ã‚«ãƒ¡ãƒ©ã®å†…éƒ¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
            if self.camera.depth_intrinsics is not None:
                depth_image = depth_data.reshape(
                    (self.camera.depth_intrinsics.height, self.camera.depth_intrinsics.width)
                )
            else:
                print("Depth intrinsics not available for RGB display")
                return True
            
            # æ·±åº¦ç”»åƒã‚’è¡¨ç¤ºç”¨ã«æ­£è¦åŒ–
            depth_normalized = cv2.normalize(depth_image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
            depth_colored = cv2.applyColorMap(depth_normalized, cv2.COLORMAP_JET)
            
            # æ‰‹æ¤œå‡ºå‡¦ç†ï¼ˆå®Ÿéš›ã«æ‰‹æ¤œå‡ºã‚’å®Ÿè¡Œï¼‰
            # æ‰‹æ¤œå‡ºé–‹å§‹æ™‚é–“ã‚’è¨˜éŒ²
            hand_start_time = time.perf_counter()
            hands_2d, hands_3d, tracked_hands = [], [], []
            
            # å®Ÿéš›ã«æ‰‹æ¤œå‡ºã‚’å®Ÿè¡Œ
            if self.enable_hand_detection and self.hands_2d is not None:
                print(f"[HAND-DEBUG] Frame {self.frame_count}: Starting hand detection...")
                hands_2d, hands_3d, tracked_hands = self._process_hand_detection(depth_image)
                print(f"[HAND-DEBUG] Frame {self.frame_count}: Hand detection completed - 2D:{len(hands_2d)}, 3D:{len(hands_3d)}, Tracked:{len(tracked_hands)}")
                
                # ãƒ‡ãƒãƒƒã‚°: æ‰‹æ¤œå‡ºã®è©³ç´°æƒ…å ±
                for i, hand in enumerate(hands_2d):
                    print(f"[HAND-DEBUG] Hand {i}: confidence={hand.confidence:.3f}, handedness={hand.handedness.value}")
            else:
                print(f"[HAND-DEBUG] Frame {self.frame_count}: Hand detection disabled or not initialized (enabled={self.enable_hand_detection}, hands_2d={self.hands_2d is not None})")
            
            # 3DæŠ•å½±ã¨ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã¯_process_hand_detectionå†…ã§å®Ÿè¡Œæ¸ˆã¿
            # çµæœã‚’ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ç”¨ã«ä¿å­˜
            self.current_hands_2d = hands_2d
            self.current_hands_3d = hands_3d
            self.current_tracked_hands = tracked_hands
            
            self.performance_stats['hand_detection_time'] = (time.perf_counter() - hand_start_time) * 1000
            print(f"[DEBUG] Frame {self.frame_count}: Detected {len(hands_2d)} hands in 2D, {len(hands_3d)} in 3D, {len(tracked_hands)} tracked")
        
            # ã‚«ãƒ©ãƒ¼ç”»åƒãŒã‚ã‚Œã°è¡¨ç¤º
            display_images = []
            
            # æ·±åº¦ç”»åƒï¼ˆç–‘ä¼¼ã‚«ãƒ©ãƒ¼ï¼‰
            depth_resized = cv2.resize(depth_colored, self.rgb_window_size)
            cv2.putText(depth_resized, f"Depth (Frame: {self.frame_count})", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            display_images.append(depth_resized)
            
            # RGBç”»åƒ
            color_bgr = None
            if frame_data.color_frame is not None and self.camera.has_color:
                color_data = np.frombuffer(frame_data.color_frame.get_data(), dtype=np.uint8)
                color_format = frame_data.color_frame.get_format()
                
                # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¿œã˜ãŸå¤‰æ›ï¼ˆDualViewerã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
                try:
                    from pyorbbecsdk import OBFormat
                except ImportError:
                    pass  # Use imported OBFormat from src.types
                
                color_image = None
                if color_format == OBFormat.RGB:
                    # RGBå½¢å¼ã®å ´åˆã€ã‚«ãƒ©ãƒ¼ç”»åƒã®å®Ÿéš›ã®ã‚µã‚¤ã‚ºã‚’å–å¾—
                    total_pixels = len(color_data) // 3
                    # 1280x720 æƒ³å®šã§ãƒªã‚·ã‚§ã‚¤ãƒ—
                    color_image = color_data.reshape((720, 1280, 3))
                elif color_format == OBFormat.BGR:
                    total_pixels = len(color_data) // 3
                    color_image = color_data.reshape((720, 1280, 3))
                    color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)
                elif color_format == OBFormat.MJPG:
                    color_image = cv2.imdecode(color_data, cv2.IMREAD_COLOR)
                    if color_image is not None:
                        color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)
                
                if color_image is not None:
                    color_resized = cv2.resize(color_image, self.rgb_window_size)
                    color_bgr = cv2.cvtColor(color_resized, cv2.COLOR_RGB2BGR)
                    
                    # æ‰‹æ¤œå‡ºçµæœã‚’æç”»
                    if self.enable_hand_detection and hands_2d:
                        color_bgr = self._draw_hand_detections(color_bgr, hands_2d, hands_3d, tracked_hands)
                    
                    # è¡çªæ¤œå‡ºæƒ…å ±ã‚’æç”»
                    if collision_events:
                        self._draw_collision_info(color_bgr, collision_events)
                    
                    cv2.putText(color_bgr, f"RGB (FPS: {self.performance_stats['fps']:.1f})", 
                               (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                    display_images.append(color_bgr)
            
            # ç”»åƒã‚’æ¨ªã«ä¸¦ã¹ã¦è¡¨ç¤º
            if len(display_images) > 1:
                combined_image = np.hstack(display_images)
            else:
                combined_image = display_images[0]
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
            self._draw_performance_overlay(combined_image)
            
            # è¡çªæ¤œå‡ºãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’è¿½åŠ æç”»
            if hasattr(self, 'perf_stats'):
                self._draw_collision_performance_info(combined_image, collision_events)
            
            cv2.imshow("Geocussion-SP Input Viewer", combined_image)
            
            # ã‚­ãƒ¼å…¥åŠ›å‡¦ç†ï¼ˆDualViewerã®åŸºæœ¬æ©Ÿèƒ½ + è¡çªæ¤œå‡ºæ©Ÿèƒ½ï¼‰
            key = cv2.waitKey(1) & 0xFF
            
            # æ—¢å­˜ã®ã‚­ãƒ¼å‡¦ç†
            if key == ord('q') or key == 27:  # Q or ESC
                return False
            elif key == ord('f'):  # Toggle filter
                self.enable_filter = not self.enable_filter
                print(f"Depth filter: {'Enabled' if self.enable_filter else 'Disabled'}")
            elif key == ord('r') and self.depth_filter is not None:  # Reset filter
                self.depth_filter.reset_temporal_history()
                print("Filter history reset")
            elif key == ord('h'):  # Toggle hand detection
                self.enable_hand_detection = not self.enable_hand_detection
                print(f"Hand detection: {'Enabled' if self.enable_hand_detection else 'Disabled'}")
            elif key == ord('t') and self.enable_hand_detection:  # Toggle tracking
                self.enable_tracking = not self.enable_tracking
                print(f"Hand tracking: {'Enabled' if self.enable_tracking else 'Disabled'}")
            elif key == ord('y') and self.tracker is not None:  # Reset tracker
                self.tracker.reset()
                print("Hand tracker reset")
            
            # è¡çªæ¤œå‡ºã®ã‚­ãƒ¼å‡¦ç†
            else:
                # è¡çªæ¤œå‡ºã®ã‚­ãƒ¼å‡¦ç†ã‚’ç›´æ¥å®Ÿè£…
                if key == ord('m') or key == ord('M'):
                    self.enable_mesh_generation = not self.enable_mesh_generation
                    status = "æœ‰åŠ¹" if self.enable_mesh_generation else "ç„¡åŠ¹"
                    print(f"ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ: {status}")
                elif key == ord('c') or key == ord('C'):
                    self.enable_collision_detection = not self.enable_collision_detection
                    status = "æœ‰åŠ¹" if self.enable_collision_detection else "ç„¡åŠ¹"
                    print(f"è¡çªæ¤œå‡º: {status}")
                elif key == ord('v') or key == ord('V'):
                    self.enable_collision_visualization = not self.enable_collision_visualization
                    status = "æœ‰åŠ¹" if self.enable_collision_visualization else "ç„¡åŠ¹"
                    print(f"è¡çªå¯è¦–åŒ–: {status}")
                elif key == ord('n') or key == ord('N'):
                    print("ãƒ¡ãƒƒã‚·ãƒ¥ã‚’å¼·åˆ¶æ›´æ–°ä¸­...")
                    self._force_mesh_update()
                elif key == ord('+') or key == ord('='):
                    self.sphere_radius = min(self.sphere_radius + 0.01, 0.2)
                    print(f"çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
                elif key == ord('-') or key == ord('_'):
                    self.sphere_radius = max(self.sphere_radius - 0.01, 0.01)
                    print(f"çƒåŠå¾„: {self.sphere_radius*100:.1f}cm")
                elif key == ord('p') or key == ord('P'):
                    self._print_performance_stats()
            
            return True
            
        except Exception as e:
            print(f"RGB display error: {e}")
            return True

    def _draw_collision_info(self, image: np.ndarray, collision_events: list) -> None:
        """è¡çªæƒ…å ±ã‚’RGBç”»åƒã«æç”»"""
        if not collision_events:
            return
            
        # è¡çªã‚¤ãƒ™ãƒ³ãƒˆè¡¨ç¤º
        cv2.putText(image, f"COLLISION DETECTED! ({len(collision_events)} events)", 
                   (10, image.shape[0] - 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)
        
        # éŸ³éŸ¿å†ç”Ÿè¡¨ç¤º
        if self.enable_audio_synthesis and self.audio_enabled:
            cv2.putText(image, f"PLAYING AUDIO ({self.audio_instrument.value})", 
                       (10, image.shape[0] - 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
    
    def _draw_collision_performance_info(self, image: np.ndarray, collision_events: list) -> None:
        """è¡çªæ¤œå‡ºãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’æç”»"""
        if not hasattr(self, 'perf_stats'):
            return
            
        # å³å´ã«è¡çªæ¤œå‡ºæƒ…å ±ã‚’æç”»
        info_lines = [
            f"Mesh: {self.perf_stats.get('mesh_generation_time', 0):.1f}ms",
            f"Collision: {self.perf_stats.get('collision_detection_time', 0):.1f}ms",
            f"Audio: {self.perf_stats.get('audio_synthesis_time', 0):.1f}ms",
            f"Events: {len(collision_events)}",
            f"Sphere R: {self.sphere_radius*100:.1f}cm"
        ]
        
        # ãƒœã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æƒ…å ±
        if self.pointcloud_converter:
            voxel_stats = self.pointcloud_converter.get_performance_stats()
            if voxel_stats.get('voxel_downsampling_enabled', False):
                ratio = voxel_stats.get('last_downsampling_ratio', 0)
                voxel_size = voxel_stats.get('current_voxel_size_mm', 0)
                info_lines.append(f"Voxel: {ratio*100:.0f}% @ {voxel_size:.1f}mm")
            else:
                info_lines.append("Voxel: OFF")
        
        if self.current_mesh:
            info_lines.append(f"Triangles: {self.current_mesh.num_triangles}")
        
        if self.current_collision_points:
            info_lines.append(f"Contacts: {len(self.current_collision_points)}")
        
        # å³å´ã«æç”»
        x_offset = image.shape[1] - 200
        y_offset = 30
        for i, line in enumerate(info_lines):
            cv2.putText(image, line, (x_offset, y_offset + i * 25), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)

    def run(self):
        """ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚’å®Ÿè¡Œ"""
        # è¦ªã‚¯ãƒ©ã‚¹ã®run()ã‚’å‘¼ã³å‡ºã—
        super().run()


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="Geocussion-SP å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆãƒ‡ãƒ¢ï¼ˆComplete Pipelineï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
    python demo_collision_detection.py                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
    python demo_collision_detection.py --no-collision     # è¡çªæ¤œå‡ºç„¡åŠ¹
    python demo_collision_detection.py --no-mesh          # ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆç„¡åŠ¹
    python demo_collision_detection.py --no-audio         # éŸ³éŸ¿åˆæˆç„¡åŠ¹
    python demo_collision_detection.py --sphere-radius 0.08 # çƒåŠå¾„8cm
    python demo_collision_detection.py --audio-instrument BELL # ãƒ™ãƒ«æ¥½å™¨

æ“ä½œæ–¹æ³•:
    RGB Window:
        Q/ESC: çµ‚äº†
        F: æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿ ON/OFF
        H: æ‰‹æ¤œå‡º ON/OFF
        T: ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚° ON/OFF
        
        M: ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ ON/OFF
        C: è¡çªæ¤œå‡º ON/OFF
        V: è¡çªå¯è¦–åŒ– ON/OFF
        N: ãƒ¡ãƒƒã‚·ãƒ¥å¼·åˆ¶æ›´æ–°
        +/-: çƒåŠå¾„èª¿æ•´
        P: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆè¡¨ç¤º
        
        A: éŸ³éŸ¿åˆæˆ ON/OFF
        S: éŸ³éšåˆ‡ã‚Šæ›¿ãˆ
        I: æ¥½å™¨åˆ‡ã‚Šæ›¿ãˆ
        1/2: éŸ³é‡èª¿æ•´
        R: éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³å†èµ·å‹•
        Q: å…¨éŸ³å£°åœæ­¢
    
    3D Viewer:
        ãƒã‚¦ã‚¹: å›è»¢/ãƒ‘ãƒ³/ã‚ºãƒ¼ãƒ 
        R: è¦–ç‚¹ãƒªã‚»ãƒƒãƒˆ
        """
    )
    
    # åŸºæœ¬è¨­å®š
    parser.add_argument('--no-filter', action='store_true', help='æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿ã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--no-hand-detection', action='store_true', help='æ‰‹æ¤œå‡ºã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--no-tracking', action='store_true', help='ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--gpu-mediapipe', action='store_true', help='MediaPipeã§GPUã‚’ä½¿ç”¨')
    
    # è¡çªæ¤œå‡ºè¨­å®š
    parser.add_argument('--no-mesh', action='store_true', help='ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--no-collision', action='store_true', help='è¡çªæ¤œå‡ºã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--no-collision-viz', action='store_true', help='è¡çªå¯è¦–åŒ–ã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--mesh-interval', type=int, default=10, help='ãƒ¡ãƒƒã‚·ãƒ¥æ›´æ–°é–“éš”ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼‰')
    parser.add_argument('--sphere-radius', type=float, default=0.05, help='è¡çªæ¤œå‡ºçƒã®åŠå¾„ï¼ˆãƒ¡ãƒ¼ãƒˆãƒ«ï¼‰')
    parser.add_argument('--max-mesh-skip', type=int, default=60, help='æ‰‹ãŒå†™ã£ã¦ã„ã‚‹å ´åˆã§ã‚‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°çµŒéã§å¼·åˆ¶æ›´æ–°')
    
    # éŸ³éŸ¿ç”Ÿæˆè¨­å®š
    parser.add_argument('--no-audio', action='store_true', help='éŸ³éŸ¿åˆæˆã‚’ç„¡åŠ¹ã«ã™ã‚‹')
    parser.add_argument('--audio-scale', type=str, default='PENTATONIC', 
                       choices=['PENTATONIC', 'MAJOR', 'MINOR', 'DORIAN', 'MIXOLYDIAN', 'CHROMATIC', 'BLUES'],
                       help='éŸ³éšã®ç¨®é¡')
    parser.add_argument('--audio-instrument', type=str, default='MARIMBA',
                       choices=['MARIMBA', 'SYNTH_PAD', 'BELL', 'PLUCK', 'BASS', 'LEAD', 'PERCUSSION', 'AMBIENT'],
                       help='æ¥½å™¨ã®ç¨®é¡')
    parser.add_argument('--audio-polyphony', type=int, default=16, help='æœ€å¤§åŒæ™‚ç™ºéŸ³æ•°')
    parser.add_argument('--audio-volume', type=float, default=0.7, help='ãƒã‚¹ã‚¿ãƒ¼éŸ³é‡ (0.0-1.0)')
    
    # æ‰‹æ¤œå‡ºè¨­å®š
    parser.add_argument('--min-confidence', type=float, default=0.7, help='æœ€å°æ¤œå‡ºä¿¡é ¼åº¦ (0.0-1.0)')
    
    # è¡¨ç¤ºè¨­å®š
    parser.add_argument('--update-interval', type=int, default=3, help='ç‚¹ç¾¤æ›´æ–°é–“éš”ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼‰')
    parser.add_argument('--point-size', type=float, default=2.0, help='ç‚¹ç¾¤ã®ç‚¹ã‚µã‚¤ã‚º')
    parser.add_argument('--high-resolution', action='store_true', help='é«˜è§£åƒåº¦è¡¨ç¤º (1280x720)')
    
    # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
    parser.add_argument('--window-width', type=int, default=640, help='RGBã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®å¹…')
    parser.add_argument('--window-height', type=int, default=480, help='RGBã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®é«˜ã•')
    
    # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰
    parser.add_argument('--test', action='store_true', help='ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ')
    
    args = parser.parse_args()
    
    # è¨­å®šå€¤æ¤œè¨¼
    if args.min_confidence < 0.0 or args.min_confidence > 1.0:
        print("Error: --min-confidence must be between 0.0 and 1.0")
        return 1
    
    if args.sphere_radius <= 0.0 or args.sphere_radius > 0.5:
        print("Error: --sphere-radius must be between 0.0 and 0.5")
        return 1
    
    if args.audio_polyphony < 1 or args.audio_polyphony > 64:
        print("Error: --audio-polyphony must be between 1 and 64")
        return 1
    
    if args.audio_volume < 0.0 or args.audio_volume > 1.0:
        print("Error: --audio-volume must be between 0.0 and 1.0")
        return 1
    
    # éŸ³éšã¨æ¥½å™¨ã®åˆ—æŒ™å€¤å¤‰æ›
    try:
        audio_scale = ScaleType[args.audio_scale]
        audio_instrument = InstrumentType[args.audio_instrument]
    except KeyError as e:
        print(f"Error: Invalid audio parameter: {e}")
        return 1
    
    # æƒ…å ±è¡¨ç¤º
    print("=" * 70)
    print("Geocussion-SP å…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆãƒ‡ãƒ¢ï¼ˆComplete Pipelineï¼‰")
    print("=" * 70)
    print(f"æ·±åº¦ãƒ•ã‚£ãƒ«ã‚¿: {'ç„¡åŠ¹' if args.no_filter else 'æœ‰åŠ¹'}")
    print(f"æ‰‹æ¤œå‡º: {'ç„¡åŠ¹' if args.no_hand_detection else 'æœ‰åŠ¹'}")
    print(f"ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆ: {'ç„¡åŠ¹' if args.no_mesh else 'æœ‰åŠ¹'}")
    print(f"è¡çªæ¤œå‡º: {'ç„¡åŠ¹' if args.no_collision else 'æœ‰åŠ¹'}")
    if not args.no_collision:
        print(f"  - çƒåŠå¾„: {args.sphere_radius*100:.1f}cm")
        print(f"  - å¯è¦–åŒ–: {'ç„¡åŠ¹' if args.no_collision_viz else 'æœ‰åŠ¹'}")
    print(f"éŸ³éŸ¿åˆæˆ: {'ç„¡åŠ¹' if args.no_audio else 'æœ‰åŠ¹'}")
    if not args.no_audio:
        print(f"  - éŸ³éš: {audio_scale.value}")
        print(f"  - æ¥½å™¨: {audio_instrument.value}")
        print(f"  - ãƒãƒªãƒ•ã‚©ãƒ‹ãƒ¼: {args.audio_polyphony}")
        print(f"  - éŸ³é‡: {args.audio_volume:.1f}")
    print("=" * 70)
    
    # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰
    if args.test:
        run_preprocessing_optimization_test()
        return 0
    
    # CollisionDetectionViewerå®Ÿè¡Œ
    try:
        viewer = FullPipelineViewer(
            enable_filter=not args.no_filter,
            enable_hand_detection=not args.no_hand_detection,
                enable_tracking=not args.no_tracking,
                enable_mesh_generation=not args.no_mesh,
                enable_collision_detection=not args.no_collision,
                enable_collision_visualization=not args.no_collision_viz,
                enable_audio_synthesis=not args.no_audio,
                update_interval=args.update_interval,
                point_size=args.point_size,
                rgb_window_size=(args.window_width, args.window_height),
                min_detection_confidence=args.min_confidence,
                use_gpu_mediapipe=args.gpu_mediapipe,
                mesh_update_interval=args.mesh_interval,
                sphere_radius=args.sphere_radius,
                audio_scale=audio_scale,
                audio_instrument=audio_instrument,
                audio_polyphony=args.audio_polyphony,
            audio_master_volume=args.audio_volume,
            max_mesh_skip_frames=args.max_mesh_skip
        )
        
        print("\nå…¨ãƒ•ã‚§ãƒ¼ã‚ºçµ±åˆãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚’é–‹å§‹ã—ã¾ã™...")
        print("=" * 70)
        
        print("ã‚«ãƒ¡ãƒ©ã‚’åˆæœŸåŒ–ä¸­...")
        # ã‚«ãƒ¡ãƒ©ã‚’424x240ã®ä½è§£åƒåº¦ã§åˆæœŸåŒ–ï¼ˆFPSå‘ä¸Šã®ãŸã‚ï¼‰
        viewer.camera = OrbbecCamera(
            enable_color=True
        )
        
        # DualViewerã®åˆæœŸåŒ–ã‚’å®Ÿè¡Œ
        if not viewer.initialize():
            print("Failed to initialize dual viewer")
            return 1
        
        viewer.run()
        
        print("\nãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ãŒæ­£å¸¸ã«çµ‚äº†ã—ã¾ã—ãŸ")
        return 0
        
    except KeyboardInterrupt:
        print("\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        return 0
    except Exception as e:
        print(f"\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 